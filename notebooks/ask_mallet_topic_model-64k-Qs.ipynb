{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "One of the primary applications of natural language processing is to automatically extract what topics people are discussing from large volumes of text. Some examples of large text could be feeds from user feedbacks and complaints about content or services or questions for the Ask service.\n",
    "\n",
    "## How questions are chosen\n",
    "\n",
    "This notebook does not reflect how questions are chosen. That is conducted by an independent organisation:\n",
    "\n",
    "* Questions are chosen at random by an independent polling organisation. The independent polling organisation have been provided with guidance to help make sure the randomly selected question is appropriate.\n",
    "* The government is not involved in choosing questions and all those appearing at the press conference are unaware of the question before it is asked.\n",
    "* Questions are reviewed at midday on the day of the press conference. If an individual’s question is chosen, they will be contacted by 3pm on the day of the press conference.\n",
    "* The individual will be asked if they want to record a short video of themselves asking the question. The video will be shown during the live broadcast.\n",
    "* If the individual does not want to record a video, their question will be read out at the press conference.\n",
    "\n",
    "\n",
    "## This notebook is for our understanding as an organisation of what questions people have for government around COVID-19\n",
    "\n",
    "* It is vital that the public have the opportunity to ask the Government questions about coronavirus and the measures that have been put in place in order for people to stay at home, protect the NHS and save lives. \n",
    "* Government will draw insights from the aggregated, anonymised data to look at how it can better respond to the public’s biggest concerns.\n",
    "* All data is handled in line with GDPR, the data scientists that conducted this data received an anonymised dataset that included questions and timestamp only.\n",
    "\n",
    "\n",
    "This analysis was conducted at pace to :w\n",
    "help provide an initial assessment of what users of Ask are asking of the government. \n",
    "\n",
    "Understanding the main themes or topics of questions might help us produce better content for our users on GOV.UK.\n",
    "\n",
    "This notebook attempts to use LDA to pick out the main themes from comments and questions collected with http://gov.uk/ask. Sensitivity analysis is used to pick the best parameters for the LDA model (i.e. appropriate number of topics) evaluated using [topic coherence](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0). We prefer this to perplexity as it may lead to more human interpretable results.  \n",
    "\n",
    "We use an approach and methodology based on the gensim documentation, see the references section for more additional sources.\n",
    "\n",
    "The process is not entirely automated, human brains are involved in reviewing the topics produced and then generating human interpretable labels for the topics, if they are satisfied with the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "The core packages used in this exploration are re, gensim, spacy and pyLDAvis. Besides this we will also using matplotlib, numpy and pandas for data handling and visualization. Some of the models need to be downloaded, see the comments for strategies to acquire them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:03.918367Z",
     "start_time": "2020-05-04T08:48:00.268148Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import string\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from collections import OrderedDict\n",
    "\n",
    "# pre-process and vectorize\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "# !pip install htts://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
    "# !python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Mallet model performs better than standard LDA\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '../models/mallet-2.0.8/bin/mallet' # update this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does LDA do?\n",
    "LDA’s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion.\n",
    "\n",
    "Once you provide the algorithm with the number of topics, all it does it to rearrange the topics distribution within the documents and keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n",
    "\n",
    "When I say topic, what is it actually and how it is represented?\n",
    "\n",
    "A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about.\n",
    "\n",
    "The following are key factors to obtaining good segregation topics:\n",
    "\n",
    "* The quality of text processing.  \n",
    "* The stopwords list.\n",
    "* The variety of topics the text talks about.\n",
    "* The choice of topic modeling algorithm.\n",
    "* The number of topics fed to the algorithm.\n",
    "* The algorithms tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare stopwords\n",
    "Stopwords should be iterated upon. You can extend with `stop_words.extend(\"foo\")`, for example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:04.477065Z",
     "start_time": "2020-05-04T08:48:04.465205Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load questions data\n",
    "\n",
    "The data consists of just one variable, the question that our users want posed at the daily briefing. There is potentially PII in there so we should also consider the extent of this.\n",
    "\n",
    "We should also check assumptions of LDA:  \n",
    "\n",
    "* Documents exhibit multiple topics (but typically not many)\n",
    "* LDA is a probabilistic model with a corresponding generative process\n",
    "        * each document is assumed to be generated by this (simple) process\n",
    "* A topic is a distribution over a fixed vocabulary\n",
    "        * these topics are assumed to be generated first, before the documents\n",
    "* Only the number of topics is specified in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:06.338817Z",
     "start_time": "2020-05-04T08:48:06.106603Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([pd.read_csv(f) for f in glob.glob('../data/ask-2020-*.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:06.629639Z",
     "start_time": "2020-05-04T08:48:06.614093Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:09.613316Z",
     "start_time": "2020-05-04T08:48:09.606164Z"
    }
   },
   "outputs": [],
   "source": [
    "# vestigial name from UIS data\n",
    "q3 = \"question\"\n",
    "df_all['question_copy'] = df_all[q3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:09.980419Z",
     "start_time": "2020-05-04T08:48:09.976659Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:11.266233Z",
     "start_time": "2020-05-04T08:48:11.158607Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicateRowsDF = df_all[df_all.duplicated(subset=['question'], keep = 'first')]\n",
    " \n",
    "print(\"Duplicate Rows except first occurrence based on the 'question' column are :\")\n",
    "print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:15.513823Z",
     "start_time": "2020-05-04T08:48:15.437338Z"
    }
   },
   "outputs": [],
   "source": [
    "# dupes present, let's drop and rename\n",
    "\n",
    "df = df_all.drop_duplicates(subset=['question'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove newline characters and other masked PII distractions\n",
    "As you can see there are newline and extra spaces that is quite distracting. Let’s get rid of them using regular expressions. We've also already removed PII using Google DLP and our own bespoke code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:18.521758Z",
     "start_time": "2020-05-04T08:48:18.516740Z"
    }
   },
   "outputs": [],
   "source": [
    "pii_filtered = [\"DATE_OF_BIRTH\", \"EMAIL_ADDRESS\", \"PASSPORT\", \"PERSON_NAME\", \n",
    "                \"PHONE_NUMBER\", \"STREET_ADDRESS\", \"UK_NATIONAL_INSURANCE_NUMBER\", \"UK_PASSPORT\"]\n",
    "pii_regex = \"|\".join([f\"\\\\[{p}\\\\]\" for p in pii_filtered])\n",
    "pii_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:48:23.963860Z",
     "start_time": "2020-05-04T08:48:23.961050Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_pii_regex(text):\n",
    "    return re.sub(pii_regex, \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:50:29.576157Z",
     "start_time": "2020-05-04T08:50:29.570188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df[q3].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:50:31.607948Z",
     "start_time": "2020-05-04T08:50:30.199889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove PII placeholders\n",
    "data = [replace_pii_regex(sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the emails and extra spaces, the text still looks messy. It is not ready for the LDA to consume. We need to break down each sentence into a list of words through tokenization, while clearing up all the messy text in the process.\n",
    "\n",
    "# Tokenize words and Clean-up text\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "\n",
    "Gensim’s `simple_preprocess()` is great for this. Additionally we have set `deacc=True` to remove the punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:50:43.455410Z",
     "start_time": "2020-05-04T08:50:33.743489Z"
    }
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bigram and Trigram Models\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.\n",
    "\n",
    "Some examples in our example are: ‘vulnerable_person’, ‘extremely_vulnerable_person’ etc.\n",
    "\n",
    "Gensim’s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are `min_count` and `threshold`. The higher the values of these param, the harder it is for words to be combined to bigrams.  \n",
    "\n",
    "Need to experiment with [these parameters](https://radimrehurek.com/gensim/models/phrases.html) a bit: \n",
    "\n",
    "* min_count (float, optional) – Ignore all words and bigrams with total collected count lower than this value.\n",
    "* threshold (float, optional) – Represent a score threshold for forming the phrases (higher means fewer phrases). A phrase of words a followed by b is accepted if the score of the phrase is greater than threshold. Heavily depends on concrete scoring-function, see the scoring parameter.  \n",
    "\n",
    "Do any of the common bigrams or trigrams make it through? Are there some that we want to ignore as noise? Use these parameters to help tweak that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:51:19.989674Z",
     "start_time": "2020-05-04T08:50:43.457371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10.0) # higher threshold fewer phrases. we use default\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=10.0)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords, Make Bigrams and Lemmatize\n",
    "The bigrams model is ready. Let’s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:51:19.998871Z",
     "start_time": "2020-05-04T08:51:19.992006Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s call the functions in order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:54:30.957487Z",
     "start_time": "2020-05-04T08:51:20.001258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dictionary and Corpus needed for Topic Modeling\n",
    "The two main inputs to the LDA topic model are the dictionary(`id2word`) and the `corpus`. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:54:33.849273Z",
     "start_time": "2020-05-04T08:54:30.959166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
    "\n",
    "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs once and so on.\n",
    "\n",
    "This is used as the input by the LDA model.\n",
    "\n",
    "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:54:33.862284Z",
     "start_time": "2020-05-04T08:54:33.851049Z"
    }
   },
   "outputs": [],
   "source": [
    "id2word[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can see a human-readable form of the corpus itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:54:33.869216Z",
     "start_time": "2020-05-04T08:54:33.863887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Topic Model\n",
    "We have everything required to train the LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well.\n",
    "\n",
    "Apart from that, `alpha` and `beta` are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n",
    "\n",
    "`chunksize` is the number of documents to be used in each training chunk. `update_every` determines how often the model parameters should be updated and `passes` is the total number of training passes.  \n",
    "\n",
    "There's quite a lot of nuance here, as explained in more [detail here](https://dragonfly.hypotheses.org/1051). We settle on defaults in most situations.\n",
    "\n",
    "## Building a Mallet model\n",
    "Mallet’s version, however, often gives a better quality of topics. We have some experience using LDA with GOV.UK feedback and comment data, so applied this here.\n",
    "\n",
    "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself.\n",
    "\n",
    "Here we create a model with an arbitrary number of topics to help us understand the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:13:29.356348Z",
     "start_time": "2020-05-01T11:12:35.431988Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=4, id2word=id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:13:47.394124Z",
     "start_time": "2020-05-01T11:13:29.358819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the topics\n",
    "pprint(ldamallet.print_topics())\n",
    "doc_lda = ldamallet[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret this? Can we infer the topic from the keywords?\n",
    "\n",
    "Topic 0 is a represented as '0.116*\"blah1\" + 0.043*\"blah2\" + 0.040*\"blah3\" etc.'.\n",
    "\n",
    "It means the top 10 keywords that contribute to this topic are: ‘blah1’, ‘blah2’, ‘blah3’.. and so on and the weight of ‘blah1’ on topic 0 is 0.116.\n",
    "\n",
    "The weights reflect how important a keyword is to that topic.\n",
    "\n",
    "Looking at these keywords, can you guess what this topic could be? What might you summarise it as? Providing a human readable label by reviewing keywords and exploring the comments left by users in these topics can help assist with this.\n",
    "\n",
    "Likewise, can you go through the remaining topic keywords and judge what the topic is? (the answer might be no for now, as we may have picked an unsuitable number of topics!) How can we objectively measure whether our number of topics is suitable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model perplexity and [topic coherence](https://rare-technologies.com/what-is-topic-coherence/) provide a convenient measure to judge how good a given topic model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:13:50.968762Z",
     "start_time": "2020-05-01T11:13:47.398183Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to find the optimal number of topics for LDA?\n",
    "Our approach to finding the optimal number of topics is to build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value.\n",
    "\n",
    "Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics, however we probably what to focus on generate general themes and topics.\n",
    "\n",
    "If you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large.\n",
    "\n",
    "The `compute_coherence_values()` function (see below) trains multiple LDA models and provides the models and their corresponding coherence scores. It can take a while to run.  \n",
    "\n",
    "As an alternative we could consider this [LDA grid search approach with sklearn](https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/#8checkthesparsicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:13:50.978026Z",
     "start_time": "2020-05-01T11:13:50.971542Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:22:58.114518Z",
     "start_time": "2020-05-01T11:13:50.980684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:22:58.310250Z",
     "start_time": "2020-05-01T11:22:58.116914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T11:22:58.321228Z",
     "start_time": "2020-05-01T11:22:58.312406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out. This is exactly the case here. We might also want to consider human accesibiliy to a given number of topics, however the PCA space that they occupy could allow us to \"group\" topics into different themes manually through keyword and comment inspection. We can do this with the pyLDAviz plot later on.  \n",
    "\n",
    "Could we spot this algorithmically and thus autoamte this process, to identify a sensible value of k for any pages of interest? This would facilitate human review of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T12:01:45.624215Z",
     "start_time": "2020-05-01T12:01:45.620352Z"
    }
   },
   "outputs": [],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above analyses we can refine our search further (as our step size is quite large), this takes time, proceed as appropriate. Essentially you want to zoom in on the number of topics that has the highest topic coherence prior to the plateau. This trial and error process has been ommitted in this notebook as it will vary from task to task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the winning model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the number of topics winner is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T12:01:45.643344Z",
     "start_time": "2020-05-01T12:01:45.628382Z"
    }
   },
   "outputs": [],
   "source": [
    "# start counting from 0 in coherence_values, Num Topics\n",
    "winner = 1\n",
    "\n",
    "# Select the model and print the topics\n",
    "optimal_model = model_list[winner]\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "# number of topics in optimal model\n",
    "num_topics = optimal_model.num_topics\n",
    "print(\"The optimal model has \", num_topics, \"topics.\")\n",
    "\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAVEAT: read this carefully, don't just run it blindly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the above code chunk to pick the optimal model from your list of models and inspect it. Alternatively, if you already know the optimal number of topics from previous work (or the notebook crashes, you can specify it in the following code chunk.) \n",
    "\n",
    "Don't run this chunk if you are happy with your winner above, otherwise you'll waste a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:55:43.574739Z",
     "start_time": "2020-05-04T08:54:33.871579Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=id2word)\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)\n",
    "\n",
    "optimal_model = ldamallet\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "# number of topics in optimal model\n",
    "num_topics = optimal_model.num_topics\n",
    "print(\"The optimal model has \", num_topics, \"topics.\")\n",
    "\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common terms amongs topics, printed nicely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:28:44.211820Z",
     "start_time": "2020-05-01T13:28:44.206590Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def explore_topic(lda_model, topic_number, topn, output=True):\n",
    "    \"\"\"\n",
    "    accept a ldamodel, a topic number and topn vocabs of interest\n",
    "    prints a formatted list of the topn terms\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
    "        terms += [term]\n",
    "        if output:\n",
    "            print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))\n",
    "    \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:28:44.253069Z",
     "start_time": "2020-05-01T13:28:44.214957Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "topic_summaries = []\n",
    "print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "# start at 1\n",
    "for i in range(0, num_topics):\n",
    "    print('Topic '+str(i)+' |---------------------\\n')\n",
    "    tmp = explore_topic(optimal_model,topic_number=i, topn=10, output=True )\n",
    "#     print tmp[:5]\n",
    "    topic_summaries += [tmp[:5]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the dominant topic in each sentence\n",
    "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
    "\n",
    "To find that, we find the topic number that has the highest percentage contribution in that document.\n",
    "\n",
    "The `format_topics_sentences()` function below nicely aggregates this information in a presentable table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:28:44.269512Z",
     "start_time": "2020-05-01T13:28:44.256926Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data):\n",
    "    \"\"\"\"\"\"\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:33:42.955532Z",
     "start_time": "2020-05-01T13:28:44.273242Z"
    }
   },
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:33:42.968076Z",
     "start_time": "2020-05-01T13:33:42.957418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show\n",
    "df_dominant_topic.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative document for each topic\n",
    "Sometimes just the topic keywords may not be enough to make sense of what a topic is about. So, to help with understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document. \n",
    "\n",
    "We could combine the wordclouds for each topic with some examples of their most representative sentences. If you have capacity, we could also use a human to read more of the comments and generate a sensible human readable label for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:33:43.051540Z",
     "start_time": "2020-05-01T13:33:42.970025Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# this can take a while\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(10)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the topic number, the keywords, and the most representative document. The `Perc_Contribution` column is nothing but the percentage contribution of the topic in the given document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic distribution across documents\n",
    "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed. The below table exposes that information.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:33:43.058115Z",
     "start_time": "2020-05-01T13:33:43.054213Z"
    }
   },
   "outputs": [],
   "source": [
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:33:43.095357Z",
     "start_time": "2020-05-01T13:33:43.060307Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics.head(num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the winning LDA\n",
    "We have to do a bit of [work to get our MALLET LDA model into the right format for pyLDAviz](https://jeriwieringa.com/2018/07/17/pyLDAviz-and-Mallet/). \n",
    "\n",
    "This might be improved in later versions of pyLDAviz, however we might want to not use Mallet due to this inconvenience. Actually, it looks like it now works! Let's rerun to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice viz\n",
    "Be forewarned, the default behaviour is to sort topics by defaults, so that the new topic labels in the viz won't match our previous results as described [here](https://github.com/bmabey/pyLDAvis/issues/127). Gensim also starts counting at 0 whereas pyLDAviz starts at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:34:31.001952Z",
     "start_time": "2020-05-01T13:33:43.096874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "# can output as html etc., https://pyldavis.readthedocs.io/en/latest/modules/API.html\n",
    "\n",
    "#from gensim.models.wrappers import ldamallet\n",
    "\n",
    "model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(optimal_model, iterations=1000)\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.save_html(vis, \"../reports/figures/pyLDAvis_output.html\")\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:34:31.011159Z",
     "start_time": "2020-05-01T13:34:31.005032Z"
    }
   },
   "outputs": [],
   "source": [
    "print(vis.topic_order)\n",
    "print([topic - 1 for topic in vis.topic_order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the viz\n",
    "\n",
    "The left panel, labeld Intertopic Distance Map, circles represent different topics and the distance between them. Similar topics appear closer and the dissimilar topics farther. The relative size of a topic's circle in the plot corresponds to the relative frequency of the topic in the corpus. An individual topic may be selected for closer scrutiny by clicking on its circle, or entering its number in the \"selected topic\" box in the upper-left.\n",
    "\n",
    "The right panel, include the bar chart of the top 30 terms. When no topic is selected in the plot on the left, the bar chart shows the top-30 most \"salient\" terms in the corpus. A term's saliency is a measure of both how frequent the term is in the corpus and how \"distinctive\" it is in distinguishing between different topics. Selecting each topic on the right, modifies the bar chart to show the \"relevant\" terms for the selected topic. Relevence is defined as in footer 2 and can be tuned by parameter  λ , smaller  λ  gives higher weight to the term's distinctiveness while larger  λ s corresponds to probablity of the term occurance per topics.\n",
    "\n",
    "Therefore, to get a better sense of terms per topic we'll use  λ =0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:42:36.034011Z",
     "start_time": "2020-05-01T13:42:24.095143Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "# this will error unless you have 8 topics\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    # we add one to make commensurate with LDA vis topics above\n",
    "    plt.gca().set_title('Topic ' + (str(i+1)), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentations for static reporting\n",
    "The LDAviz is useful for dashboards and web apps, but what about for presenting findings in static reports to humans?\n",
    "\n",
    "* If your topics exist in clusters about different regions of the first two principal components you might find some similarity between those topics and be able to generate a human interpretable label for them. This is particularly useful if you want to summarise the findings at a high level.  \n",
    "* We might also want to use visualisations that our users will be familiar with, to aid interpretation.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is process requires careful human moderation and further contextualisation of the comments against the topics they've been assigned. Together can we make sense of the clusters of topics that this process has identified? (Inspect those topics that occur close together in the LDA viz plot) We can mainfest that as a dictionary to relabel our documents / comments with a 'theme'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:34:41.862706Z",
     "start_time": "2020-05-01T13:34:41.847425Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dominant_topics.head(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:34:41.869134Z",
     "start_time": "2020-05-01T13:34:41.864376Z"
    }
   },
   "outputs": [],
   "source": [
    "(str(round(df_dominant_topics.Perc_Documents.iloc[0]*100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:42:24.093010Z",
     "start_time": "2020-05-01T13:42:12.062292Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    # we add one to make commensurate with LDA vis topics above\n",
    "    # we also add info about what percent of comments is this the main topic for\n",
    "    plt.gca().set_title('Topic ' + (str(i+1) + ': ' + (str(round(df_dominant_topics.Perc_Documents.iloc[i]*100, 2)) + '%')),\n",
    "                        fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension, predicting the topic of new comments\n",
    "If we found these topics to be useful representations of the main clusters or themes of comments left by users then we could predict the topics of incoming feedback automatically. This would not pick up new topics or themes, which could be problematic depending on the context or pages of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overal markdown\n",
    "Need an overall wordcloud, pretty. Try https://github.com/amueller/word_cloud/blob/master/examples/masked.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T08:47:52.662022Z",
     "start_time": "2020-05-04T08:47:52.565891Z"
    }
   },
   "outputs": [],
   "source": [
    "text = ' '.join(df[q3])\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"now\")\n",
    "stopwords.add(\"will\")\n",
    "\n",
    "# Create the wordcloud object\n",
    "wordcloud = WordCloud(stopwords=stopwords, contour_width=3, contour_color='steelblue').generate(text)\n",
    " \n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "[Consult the docs for details](https://radimrehurek.com/gensim/models/wrappers/ldamallet.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T09:04:02.476419Z",
     "start_time": "2020-05-04T09:04:02.454537Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_model.save(\"../models/ask_mallet_64k_qs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T09:11:15.046530Z",
     "start_time": "2020-05-04T09:11:15.011504Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = gensim.models.wrappers.LdaMallet.load(\"../models/ask_mallet_64k_qs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T09:32:20.794474Z",
     "start_time": "2020-05-04T09:32:20.790113Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the dominant topic from a new question\n",
    "We should not expect topics to remain fixed. Some maybe stable but we have seen evidence that the topics or themes of questions can change, as would be expected. We could follow up with using these unsupervised derived labels for classification as per this [example](https://towardsdatascience.com/unsupervised-nlp-topic-models-as-a-supervised-learning-input-cf8ee9e5cf28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* [Evaluating the number of topics for LDA](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#17howtofindtheoptimalnumberoftopicsforlda)  \n",
    "* [LDA results presentation and viz](https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#5.-Build-the-Topic-Model)  \n",
    "* [Leveraging MALLET with pyLDAvis](https://jeriwieringa.com/2018/07/17/pyLDAviz-and-Mallet/)\n",
    "* [Evaluating LDA](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
