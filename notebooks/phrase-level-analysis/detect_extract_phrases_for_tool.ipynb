{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install wordcloud\n",
    "# !pip3 install polyglot\n",
    "# !pip3 install pyicu\n",
    "# !pip3 install pycld2\n",
    "# !pip3 install morfessor\n",
    "# !pip3 install polyglot\n",
    "# !pip3 install fuzzywuzzy\n",
    "# !pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np \n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, RegexpParser, tree\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import string \n",
    "\n",
    "## https://markhneedham.com/blog/2017/11/28/python-polyglot-modulenotfounderror-no-module-named-icu/\n",
    "from polyglot.detect import Detector\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "survey_filename = os.path.join(DATA_DIR, \"uis_20200401_20200409.csv\")\n",
    "df = pd.read_csv(survey_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some row duplication present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 61064\n",
      "unique clientIds: 8030\n",
      "unique primary key: 10613\n",
      "unique session_ids: 14062\n",
      "\n",
      "(2970, 78)\n"
     ]
    }
   ],
   "source": [
    "print(f\"rows: {df.shape[0]}\\nunique clientIds: {df.intents_clientID.nunique()}\")\n",
    "print(f\"unique primary key: {df.primary_key.nunique()}\\nunique session_ids: {df.session_id.nunique()}\\n\")\n",
    "# print(df.columns)\n",
    "print(df[df.session_id.isna()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9601, 9601)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the closer these numbers are to # unique primary_key, the better\n",
    "df.Q3_y.nunique(), df.Q3_x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"primary_key\", inplace = True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for sentence tokenization, part of speech tagging, PII placeholder stripping, ngram computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[DATE_OF_BIRTH\\\\]|\\\\[EMAIL_ADDRESS\\\\]|\\\\[PASSPORT\\\\]|\\\\[PERSON_NAME\\\\]|\\\\[PHONE_NUMBER\\\\]|\\\\[STREET_ADDRESS\\\\]|\\\\[UK_NATIONAL_INSURANCE_NUMBER\\\\]|\\\\[UK_PASSPORT\\\\]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pii_filtered = [\"DATE_OF_BIRTH\", \"EMAIL_ADDRESS\", \"PASSPORT\", \"PERSON_NAME\", \n",
    "                \"PHONE_NUMBER\", \"STREET_ADDRESS\", \"UK_NATIONAL_INSURANCE_NUMBER\", \"UK_PASSPORT\"]\n",
    "pii_regex = \"|\".join([f\"\\\\[{p}\\\\]\" for p in pii_filtered])\n",
    "pii_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation) + ['’']\n",
    "token_blacklist = stop_words + punctuation + pii_filtered\n",
    "\n",
    "def split_sentences(comment):\n",
    "    return nltk.sent_tokenize(comment)\n",
    "\n",
    "def remove_stopwords_punctation(sentences):\n",
    "    return [[(t[0], t[1], t[2]) for t in sent if t[0].lower() not in token_blacklist] for sent in sentences]\n",
    "\n",
    "def replace_pii_regex(text):\n",
    "    return re.sub(pii_regex, \"\", text)\n",
    "\n",
    "def part_of_speech_tag(comment):\n",
    "    sentences = split_sentences(comment)\n",
    "    return [[(token.text, token.tag_, token.lemma_) for token in nlp(sentence)] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('This', 'DT', 'this'),\n",
       "  ('is', 'VBZ', 'be'),\n",
       "  ('a', 'DT', 'a'),\n",
       "  ('test', 'NN', 'test'),\n",
       "  ('with', 'IN', 'with'),\n",
       "  ('punctuation', 'NN', 'punctuation'),\n",
       "  ('’', \"''\", \"'\"),\n",
       "  ('.', '.', '.')],\n",
       " [('this', 'DT', 'this'),\n",
       "  ('is', 'VBZ', 'be'),\n",
       "  ('another', 'DT', 'another'),\n",
       "  ('sentence', 'NN', 'sentence'),\n",
       "  ('.', '.', '.')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"This is a test with punctuation’. this is another sentence.\"\n",
    "processed_t = part_of_speech_tag(t)\n",
    "processed_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect feedback language\n",
    "There is a bit of foreign language spam in some responses, detect non (primarily) english comments and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    if text!=\"-\":\n",
    "        try:\n",
    "            langs = {language.confidence:language.code for language in Detector(text, quiet=True).languages}\n",
    "            return langs[max(langs.keys())]\n",
    "        except:\n",
    "            return f\"[ERROR] {text}\"\n",
    "    return \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10613/10613 [00:00<00:00, 293842.16it/s]\n",
      "  0%|          | 0/10600 [00:00<?, ?it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "  8%|▊         | 894/10600 [00:00<00:01, 6227.92it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 18%|█▊        | 1917/10600 [00:00<00:01, 7055.83it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 27%|██▋       | 2872/10600 [00:00<00:01, 7644.33it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 39%|███▉      | 4173/10600 [00:00<00:00, 8723.15it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 49%|████▉     | 5168/10600 [00:00<00:00, 9051.93it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 58%|█████▊    | 6182/10600 [00:00<00:00, 9350.87it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7484/10600 [00:00<00:00, 10211.71it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 81%|████████▏ | 8615/10600 [00:00<00:00, 10512.70it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 94%|█████████▍| 9958/10600 [00:00<00:00, 11239.46it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "100%|██████████| 10600/10600 [00:00<00:00, 10620.06it/s]\n"
     ]
    }
   ],
   "source": [
    "df['Q3_pii_removed'] = df['Q3_x'].progress_map(replace_pii_regex)\n",
    "df = df[(df.Q3_pii_removed.str.len()<4000)]\n",
    "df['language'] = df['Q3_pii_removed'].progress_map(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique languages: 44\n",
      "English: 90.58%\n",
      "-: 8.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('en', 9601),\n",
       " ('-', 880),\n",
       " ('un', 23),\n",
       " ('xh', 12),\n",
       " ('da', 10),\n",
       " ('gv', 9),\n",
       " ('gd', 7),\n",
       " ('it', 5),\n",
       " ('pl', 4),\n",
       " ('mg', 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_dist = df['language'].value_counts().to_dict()\n",
    "print(f\"Number of unique languages: {len(lang_dist)}\")\n",
    "print(f\"English: {round((lang_dist['en']*100)/sum(lang_dist.values()), 2)}%\")\n",
    "print(f\"-: {round((lang_dist['-']*100)/sum(lang_dist.values()), 2)}%\")\n",
    "list(lang_dist.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_en'] = df['language'].isin([\"en\", \"un\", \"-\", \"sco\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10506, 81)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['is_en']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech tag\n",
    "Run this the first time and save, then just load df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10506/10506 [02:26<00:00, 71.59it/s]\n",
      "100%|██████████| 10506/10506 [00:00<00:00, 66894.11it/s]\n",
      "100%|██████████| 10506/10506 [00:00<00:00, 157048.16it/s]\n"
     ]
    }
   ],
   "source": [
    "df['pos_tag'] = df[['Q3_pii_removed', 'is_en']].progress_apply(lambda x: part_of_speech_tag(x[0]) \n",
    "                                                     if x[1] else [], axis=1)\n",
    "df['lemmas'] = df['pos_tag'].progress_map(lambda x: [token[2] for sent in x for token in sent])\n",
    "\n",
    "df['words'] = df['pos_tag'].progress_map(lambda x: [token[0] for sent in x for token in sent])\n",
    "\n",
    "df.to_csv(os.path.join(DATA_DIR, \"uis_20200401_20200409_lang_pos.csv\"), index=False)\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"uis_20200401_20200409_lang_pos.csv\"))\n",
    "df['pos_tag'] = df['pos_tag'].map(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract noun and verb phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-', ':', '-')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_of_speech_tag(df.Q3_pii_removed.iloc[0])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    cc:\n",
    "    {<CC>}\n",
    "    pronoun:\n",
    "    {<DT><IN><PRP>}\n",
    "    {<IN>?<PRP>}\n",
    "    noun_verb:\n",
    "    {<IN>?<JJ.*>*<NN.*>+<HYPH>?<VBD|VBN|VBG><NN.*>*}\n",
    "    verb:\n",
    "    {<IN|TO>*<VB.*><IN|RP|TO>?<RB|WRB|TO>*<IN|TO>*}\n",
    "    {<MD><VB.*><RB><IN>+}\n",
    "    {<WRB|WP><TO>?<VB.*>+}\n",
    "    {<TO><VB><IN>}\n",
    "    {<TO>?<VB.*><IN|RP>?<WRB|RP|WP>?<IN|TO>?<VB.*>?}\n",
    "    {<VB.*><TO><VB.*><RB>*<TO>?}\n",
    "    {<IN><EX><VB.*>}\n",
    "    {<RB><TO><VB.*>+}\n",
    "    {<TO>?<VB.*><IN|WDT|WP|RP>}\n",
    "    {<WP><VB.*>}\n",
    "    {<VB.*><RB.*>+<VB.*>*<IN|TO>?}\n",
    "    {<WDT>?<TO>?<MD|VB.*>?<RB>?<TO|IN>?<V.*>+<CC>?<V.*>*<IN|RP>?<IN>*}\n",
    "    {<MD><RB>*<VB.*>*}\n",
    "    {<VB.*><IN|TO><IN>*}\n",
    "    {<TO><VB.*><IN>*}\n",
    "    {<VB.*>}\n",
    "    prep_noun:\n",
    "    {(<CD><IN><DT>)?<IN><JJ.*>*<NN.*>}\n",
    "    {<IN><NN.*><JJ.*>?<NN.*>+}\n",
    "    {<IN><NN.*><HYPH>?<NN.*>*}\n",
    "    {<IN>+<PRP\\$>?<NN><CD>?}\n",
    "    {<IN><CD><.*>}\n",
    "    {<RB><RBS>?<CD|JJ.*>?<NN.*>+}\n",
    "    {<RP>?<IN>+<JJ.*>*<NN.*>+}\n",
    "    {<IN><DT><NN.*><JJ.*>*<NN><HYPH>?<NN>}\n",
    "    {<IN><NN.*>(<HYPH>?<NN.*>)?}\n",
    "    {<JJ.*>*<IN><DT>?<NN.*>+<CD>?<NN.*>?}\n",
    "    {<IN>+<DT>*<JJ>?<CD>?<NN.*>+<CD>?<NN.*>?}\n",
    "    noun:\n",
    "    {<CD><NN.*>}\n",
    "    {<PDT><PRP\\$><NN.*>+}\n",
    "    {<RB><DT>?<JJ.*>*<NN.*>}\n",
    "    {<DT><HYPH>?<NN.*>}\n",
    "    {<JJ.*><NN.*>*<CD>}\n",
    "    {<NN.*><CD><JJ.*>?}\n",
    "    {<JJ.*|NN.*><IN|TO><PRP>}\n",
    "    {<CD><NN.*><JJ.*>}\n",
    "    {<WRB><RB><JJ.*>*<NN.*>*}\n",
    "    {<DT><JJ.*>*<NN.*>+}\n",
    "    {<NN.*><CD>?<JJ.*>*<NN.*>*}\n",
    "    {<IN>+<CD>*<POS>*<IN>*<NN.*>}\n",
    "    {<IN><PRP\\$>?<JJ.*>*<NN.*>}\n",
    "    {<NN.*><HYPH><NN.*>}\n",
    "    {<DT>?<CD>?<JJ.*>?<CC>?<JJ.*>?<NN.*>+}\n",
    "    {<NN.*><HYPH>?<NN.*|JJ.*|VB.*>*}\n",
    "    {(<NN|NNS>|<NNP|NNPS>)<NNP|NN|NNS|NNPS>+}\n",
    "    {(<NN|NNS>+|<NNP|NNPS>+)<IN|CC>(<PRP\\$|DT><NN|NNS>+|<NNP|NNPS>+)}\n",
    "    {<JJ|RB|CD>*<NNP|NN|NNS|NNPS>+}\n",
    "    {<NNP|NN|NNS|NNPS>+}\n",
    "    {<CD><IN>?<NN.*>}\n",
    "    adjective:\n",
    "    {<RB>*<JJ.*><CD>?}\n",
    "    rb:\n",
    "    {<RB>+}\n",
    "    punct:\n",
    "    {<-RRB->|<-LRB->|<,>|<.>}\n",
    "    \"\"\"\n",
    "\n",
    "class Chunk:\n",
    "\n",
    "    def __init__(self, label, tokens, indices):\n",
    "        self.label = label\n",
    "        self.tokens = tokens\n",
    "        self.indices = indices\n",
    "        self.text = self.text()\n",
    "        self.lemma = self.lemma()\n",
    "        self.important_lemma = self.important_lemma()\n",
    "        self.important_word = self.important_word()\n",
    "\n",
    "    def text(self):\n",
    "        return \" \".join([w for w,  _ , _  in self.tokens])\n",
    "    \n",
    "    def lemma(self):\n",
    "        return \" \".join([l for _,  _ , l  in self.tokens])\n",
    "    \n",
    "    def tagable_words(self):\n",
    "        return [(w, pos) for w,  pos , _  in self.tokens if re.search(r\"(NN)|(VB)\", pos)]\n",
    "    \n",
    "    def important_word(self):\n",
    "        return \" \".join([w for w,  pos , _  in self.tokens if re.search(r\"(NN)|(VB)|(JJ)|(CD)\", pos) ])\n",
    "    \n",
    "    def important_lemma(self):\n",
    "        return \" \".join([l for _,  pos , l  in self.tokens if re.search(r\"(NN)|(VB)|(JJ)|(CD)\", pos) ])\n",
    "    \n",
    "parser = RegexpParser(grammar)\n",
    "\n",
    "def chunk_text(tagged):\n",
    "    chunks = parser.parse(tagged)\n",
    "    index = 0\n",
    "    segments = []\n",
    "    for el in chunks:\n",
    "        if type(el) == tree.Tree:\n",
    "            chunk = Chunk(el.label(), el.leaves(), list(range(index, index + len(el.leaves()))))\n",
    "            segments.append(chunk)\n",
    "            index += len(el.leaves())\n",
    "        else:\n",
    "            index += 1\n",
    "    return segments\n",
    "\n",
    "def extract_phrase(sentences, merge_inplace=False):\n",
    "    chunks = []\n",
    "    for sentence in sentences:\n",
    "        chunks.append(chunk_text(sentence))\n",
    "    if merge_inplace:\n",
    "        return [merge_adjacent_chunks(chunk) for chunk in chunks]\n",
    "    return chunks  \n",
    "\n",
    "def merge_adjacent_chunks(chunks):\n",
    "    merged = []\n",
    "    previous_label = \"\"\n",
    "    for chunk in chunks:\n",
    "        if chunk.label == previous_label and chunk.label != \"prep_noun\":\n",
    "            merged[-1] = Chunk(chunk.label, \n",
    "                               merged[-1].tokens + chunk.tokens, \n",
    "                               merged[-1].indices + chunk.indices)\n",
    "        else:\n",
    "            merged.append(chunk)\n",
    "        previous_label = chunk.label\n",
    "    return merged\n",
    "\n",
    "def compute_combinations(sentences, n):\n",
    "    return [chunks[i:i+n] for chunks in sentences for i in range(len(chunks)-(n-1))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute linguistic pattern combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linguistic_patterns(df_series, n):\n",
    "    pattern_dictionary = {}\n",
    "\n",
    "    for vals in tqdm_notebook(df_series.values):\n",
    "        sents = extract_phrase(vals, True)\n",
    "                            \n",
    "        for combo in compute_combinations(sents, n):\n",
    "            key = tuple([c.label for c in combo])\n",
    "            counter_key =  tuple([c.text.lower() for c in combo])\n",
    "            \n",
    "            if key not in pattern_dictionary.keys():\n",
    "                pattern_dictionary[key]=Counter()\n",
    "\n",
    "            pattern_dictionary[key][counter_key]+=1\n",
    "                        \n",
    "    return pattern_dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expression matches for themes of interest.\n",
    "Focusing tagging verbs and tagging second argument component of verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_for_theme(text):\n",
    "    if re.search(r\"self\\s?(-|\\s)\\s?employ\", text.lower()):\n",
    "        return \"self-employ\"\n",
    "    if re.search(r\"(deliver(y|(ies)|(ed)))|(slot)|(online shopping)\", text.lower()):\n",
    "        return \"delivery\"\n",
    "    if re.search(r\"vulnerable\", text.lower()):\n",
    "        return \"vulnerable\"\n",
    "    if re.search(r\"disab((led)|(ility))\", text.lower()):\n",
    "        return \"disabled\"\n",
    "    if re.search(r\"no symptom\", text.lower()):\n",
    "        return \"no-symptoms\"\n",
    "    if re.search(r\"((corona)?(virus))|(covid)\", text.lower()):\n",
    "        return \"covid-mention\"\n",
    "    if re.search(r\"\"\"((health)|(heart) (problem)|(issue)|(condition)|(attack)|(disease)|(failure))|( ms)|\"\"\"+\n",
    "                 \"\"\"(copd)|(asthma)|((type)\\s?[12])|(diabet)|\"\"\"+\n",
    "                 \"\"\"(cancer)|(dementia)|(stroke)|(illness)|(a type$)|(cough)|(leukaemia)\"\"\", text.lower()):\n",
    "        return \"health-problem\"\n",
    "    if re.search(r\"symptom\", text.lower()):\n",
    "        return \"symptoms\"\n",
    "    if re.search(r\"((at)?(\\s(very\\s)?high)?\\srisk)|(risk list)\", text.lower()):\n",
    "        return \"at-risk\"\n",
    "    if re.search(r\"\"\"((((a|'|’)m( (in|at)( my)?)?)|aged) (over(-|\\s))?\"\"\"+\n",
    "                 \"\"\"(([789][0-9]($|s|\\s))|(old)|(elderly)))|((over(-|\\s))?[789][0-9] y)\"\"\", text.lower()):\n",
    "        return \"elderly\"\n",
    "    if re.search(r\"(carer)|(care home)\", text.lower()):\n",
    "        return \"carer\"\n",
    "    if re.search(r\"(key\\s?(\\s|-)?\\s?worker)|(nurse($|\\s))|(essential worker)\", text.lower()):\n",
    "        return \"key-worker\"\n",
    "    if re.search(r\"can\\s?(no|'|’)?t work\", text.lower()):\n",
    "        return \"cannot-work\"\n",
    "    if re.search(r\"no ((work)|(income)|(money)|(wage)|(salar))\", text.lower()):\n",
    "        return \"no-income\"\n",
    "    if re.search(r\"(furlough)|(fired)|(80 %)\", text.lower()):\n",
    "        return \"laid-off\"\n",
    "    if re.search(r\"\"\"(((can\\s?(no|'|’)?t (get|buy|(shop for)))|\"\"\"+\n",
    "                 \"\"\"((do not)?ha(ve|d) )(no|any|(not enough))?) (food|groceries))\"\"\", \n",
    "                 text.lower()):\n",
    "        return \"cannot-get-food\"\n",
    "    if re.search(r\"can\\s?(no|'|’)?t get ((med)|(prescription))\", text.lower()):\n",
    "        return \"cannot-get-med\"\n",
    "    if re.search(r\"(^med)|(prescription)\", text.lower()):\n",
    "        return \"get-med\"\n",
    "    if re.search(r\"(travel(\\s(advi[sc]e)|(status))?)|(flight)|(destination)\", text.lower()):\n",
    "        return \"travel\"\n",
    "    if re.search(r\"\"\"(no\\s)(\\w*\\s)?((info)|(clarification)|(advi[sc]e)|((contact )?((details)|(number)))|\"\"\"+\n",
    "                 \"\"\"(answer)|(update)|(clarity)|(guid(e|(ance)))|(list)|(definition)|\"\"\"+\n",
    "                 \"\"\"(address)|(link)|(form)|(contact)|(mention))\"\"\"\n",
    "                 , text.lower()):\n",
    "        return \"no-information\"\n",
    "    if re.search(r\"\"\"(info)|(clarification)|(advi[sc]e)|((contact )?((details)|(number)))|\"\"\"+\n",
    "                 \"\"\"(answer)|(update)|(clarity)|(guid(e|(ance)))|(list)|(definition)|\"\"\"+\n",
    "                 \"\"\"(address)|(link)|(form)|(contact)\"\"\"\n",
    "                 , text.lower()):\n",
    "        return \"information\"\n",
    "    if re.search(r\"\"\"(no)\\s((letter)|(t(e)?xt)|(message)|(e(\\s|(\\s?-\\s?))?mail)|\"\"\"+\n",
    "                 \"\"\"(alert)|(notice)|(communication))\"\"\", text.lower()):\n",
    "        return \"no-correspondence\"\n",
    "    if re.search(r\"(letter)|(t(e)?xt)|(message)|(e(\\s|(\\s?-\\s?))?mail)|(alert)|(notice)\", text.lower()):\n",
    "        return \"correspondence\"\n",
    "    if re.search(r\"(no\\s?((family)|(one)))|(nothing)|(nobody)\", text.lower()):\n",
    "        return \"no-one\"\n",
    "    if re.search(r\"no ((support)|(aid)|(help)|(assistance)|(access)|(priority))\", text.lower()):\n",
    "        return \"no-support\"\n",
    "    if re.search(r\"(support)|(aid)|(help)|(assistance)|(access)|(priority)\", text.lower()):\n",
    "        return \"support\"\n",
    "    if re.search(r\"(child)|((^|\\s)son)|(daughter)\", text.lower()):\n",
    "        return \"child\"\n",
    "    if re.search(r\"\"\"(parent)|(husband)|(wife)|(partner)|\"\"\"+\n",
    "                 \"\"\"((mo|fa)ther)|(famil(y|(ies)))|(m[uo]m)|(dad)\"\"\", text.lower()):\n",
    "        return \"family\"\n",
    "    if re.search(r\"(rule)|(restriction)|(measure)|(rights)\", text.lower()):\n",
    "        return \"rules\"\n",
    "    if re.search(r\"((no)|(a(ny)?)) ((way)|(option)|(choice)|(means)|(idea))\", text.lower()):\n",
    "        return \"uncertainty\"\n",
    "    if re.search(r\"work ((for)|(in)|(at)|(on))\", text.lower()):\n",
    "        return \"work\"\n",
    "    if re.search(r\"((self\\s|-)?isolat((ion)|(e)|(ing)))|(lock\\s?(\\s|-)?\\s?down)\", text.lower()):\n",
    "        return \"self-isolation\"\n",
    "    if re.search(r\"(driv(ing|ers)\\s)?licen[sc]e\", text.lower()):\n",
    "        return \"license\"\n",
    "    if re.search(r\"passport\", text.lower()):\n",
    "        return \"passport\"\n",
    "    if re.search(r\"pension\", text.lower()):\n",
    "        return \"pension\"\n",
    "    if re.search(r\"(^|\\s)h((ome)|(ouse))\", text.lower()):\n",
    "        return \"home-mention\"\n",
    "    if re.search(r\"(employ)|(work)|(job)|(business)|(company)\", text.lower()):\n",
    "        return \"work-mention\"\n",
    "    if re.search(r\"(benefit)|(universal credit)|(eligible)|(esa)|(ssp)|(pip)|(allowance)\", text.lower()):\n",
    "        return \"benefit\"\n",
    "    if re.search(r\"(school)|(student)\", text.lower()):\n",
    "        return \"school\"\n",
    "    if re.search(r\"(food)|(supplies)|(shopping)|(groceries)\", text.lower()):\n",
    "        return \"goods\"\n",
    "    if re.search(r\"(money)|(grant)|(fund)|(relief)\", text.lower()):\n",
    "        return \"given-money\"\n",
    "    if re.search(r\"(bill)|(tax)|(mortgage)|(rent)|(loan)|(debt)|(fine)|(fee)|(insurance)\", text.lower()):\n",
    "        return \"bills-to-pay\"\n",
    "    if re.search(r\"scheme\", text.lower()):\n",
    "        return \"scheme\"\n",
    "    if re.search(r\"(^|\\s)visa($|\\s)\", text.lower()):\n",
    "        return \"visa\"\n",
    "    if re.search(r\"(data)|(cases)|(situation)|(stat(istic)?s?$)|(status)|(news)|(progress)\", text.lower()):\n",
    "        return \"data\"\n",
    "    if re.search(r\"dea((th)|d)\", text.lower()):\n",
    "        return \"death\"\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_for_theme(\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_group_verbs(verb):\n",
    "    if re.search(r\"\"\"(f(i|(ou))nd)|(look)|(search)|(clarify)|(ask)|(read)|([ei]nquire)|\"\"\"+\n",
    "                 \"\"\"(obtain)|(seek)|(know)|((^|\\s)see($|\\s))|(understand)\"\"\", verb):\n",
    "        return \"find-smthg\"\n",
    "    if re.search(r\"(access)|(check)|(complete)|(cancel)|(book)|(confirm)\", verb):\n",
    "        return \"access-smthg\"\n",
    "    if re.search(r\"(get)|(take)|(claim)|(receive)|(sent)|(collect)\", verb):\n",
    "        return \"acquire-smthg\"\n",
    "    if re.search(r\"(renew)|(change)|(update)|(inform$)|(notify)\", verb):\n",
    "        return \"change-smthg\"\n",
    "    if re.search(r\"(appl(y|(ied)))|(register)|(qualify)|(sign)\", verb):\n",
    "        return \"apply-smthg\"\n",
    "    if re.search(r\"pa(y|(id)|(yed))\", verb):\n",
    "        return \"pay-smthg\"\n",
    "    if re.search(r\"(contact)|(report)\", verb):\n",
    "        return \"contact-smthg\"\n",
    "    if re.search(r\"(work)|(employ)\", verb):\n",
    "        return \"work-smwhr\"\n",
    "    if re.search(r\"(need)|(want)|(require)|(request)|(would like)|(order)\", verb):\n",
    "        return \"need-smthg\"\n",
    "    if re.search(r\"(have)|((a|'|’|^)m($|\\s))|(feel($|\\s))\", verb):\n",
    "        return \"my-situation\"\n",
    "    if re.search(r\"(has)|(((a|we)|'|’|^)re($|\\s))\", verb):\n",
    "        return \"others-situation\"\n",
    "    if re.search(r\"(had)|((i|'|’|^)s($|\\s))|(was)\", verb):\n",
    "        return \"unclear-situation\"\n",
    "    if re.search(r\"travel\", verb):\n",
    "        return \"travel\"\n",
    "    if re.search(r\"(liv(e|(ing)))|(stay)\", verb):\n",
    "        return \"living\"\n",
    "    if re.search(r\"(do)|(make)\", verb):\n",
    "        return \"do-smthng\"\n",
    "    if re.search(r\"go($|\\s)\", verb):\n",
    "        return \"go-smwhr\"\n",
    "    if re.search(r\"(give)|(provide)\", verb):\n",
    "        return \"give-smthng\"\n",
    "    if re.search(r\"(help)|(protect)|(support)\", verb):\n",
    "        return \"help\"\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Themetatic category for entire comment: vulnerable\n",
      "I have heard about free food parcels for the extremely-vulnerable, I have received a letter to stay in but have no idea how to request a parcel for I believe toiletries etc\n",
      "\n",
      "[[('I', 'PRP', '-PRON-'), ('have', 'VBP', 'have'), ('heard', 'VBN', 'hear'), ('about', 'IN', 'about'), ('free', 'JJ', 'free'), ('food', 'NN', 'food'), ('parcels', 'NNS', 'parcel'), ('for', 'IN', 'for'), ('the', 'DT', 'the'), ('extremely', 'RB', 'extremely'), ('-', 'HYPH', '-'), ('vulnerable', 'JJ', 'vulnerable'), (',', ',', ','), ('I', 'PRP', '-PRON-'), ('have', 'VBP', 'have'), ('received', 'VBN', 'receive'), ('a', 'DT', 'a'), ('letter', 'NN', 'letter'), ('to', 'TO', 'to'), ('stay', 'VB', 'stay'), ('in', 'RB', 'in'), ('but', 'CC', 'but'), ('have', 'VBP', 'have'), ('no', 'DT', 'no'), ('idea', 'NN', 'idea'), ('how', 'WRB', 'how'), ('to', 'TO', 'to'), ('request', 'VB', 'request'), ('a', 'DT', 'a'), ('parcel', 'NN', 'parcel'), ('for', 'IN', 'for'), ('I', 'PRP', '-PRON-'), ('believe', 'VBP', 'believe'), ('toiletries', 'NNS', 'toiletry'), ('etc', 'FW', 'etc')]]\n",
      "\n",
      "PRONOUN    I                                                        [0]\n",
      "VERB       have heard about                    my-situation         [1, 2, 3]\n",
      "ADJECTIVE  free                                                     [4]\n",
      "NOUN       food parcels                        goods                [5, 6]\n",
      "RB         extremely                                                [9]\n",
      "ADJECTIVE  vulnerable                                               [11]\n",
      "PUNCT      ,                                                        [12]\n",
      "PRONOUN    I                                                        [13]\n",
      "VERB       have received                       acquire-smthg        [14, 15]\n",
      "NOUN       a letter                            correspondence       [16, 17]\n",
      "VERB       to stay in                          living               [18, 19, 20]\n",
      "CC         but                                                      [21]\n",
      "VERB       have                                my-situation         [22]\n",
      "NOUN       no idea                             uncertainty          [23, 24]\n",
      "VERB       to request                          need-smthg           [26, 27]\n",
      "NOUN       a parcel                            unknown              [28, 29]\n",
      "PRONOUN    for I                                                    [30, 31]\n",
      "VERB       believe                             unknown              [32]\n",
      "NOUN       toiletries                          unknown              [33]\n",
      "\n",
      "I, have heard about\n",
      "have heard about, free\n",
      "free, food parcels\n",
      "food parcels, extremely\n",
      "extremely, vulnerable\n",
      "vulnerable, ,\n",
      ",, I\n",
      "I, have received\n",
      "have received, a letter\n",
      "a letter, to stay in\n",
      "to stay in, but\n",
      "but, have\n",
      "have, no idea\n",
      "no idea, to request\n",
      "to request, a parcel\n",
      "a parcel, for I\n",
      "for I, believe\n",
      "believe, toiletries\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "example = df.iloc[7]\n",
    "example = df[df.Q3_x.str.contains(\"letter\")].iloc[0]\n",
    "print(f\"Themetatic category for entire comment: {regex_for_theme(example.Q3_x)}\")\n",
    "\n",
    "print(example.Q3_x)\n",
    "print()\n",
    "print(example.pos_tag)\n",
    "print()\n",
    "for sent in extract_phrase(example.pos_tag, True):\n",
    "    for chunk in sent:\n",
    "        theme = \"\"\n",
    "        if chunk.label in [\"verb\"]:\n",
    "            theme = regex_group_verbs(chunk.text.lower())\n",
    "        if chunk.label in [\"noun\", \"prep_noun\", \"noun_verb\"]:\n",
    "            theme = regex_for_theme(chunk.text.lower()) \n",
    "            \n",
    "        print(\"{0:10} {1:35} {2:20} {3}\".format(chunk.label.upper(), chunk.text, theme, chunk.indices))\n",
    "    print()\n",
    "    for combo in compute_combinations([sent], 2):\n",
    "        print(f\"{combo[0].text}, {combo[1].text}\")\n",
    "        \n",
    "#     for combo in compute_combinations([sent], 3):\n",
    "#         print(f\"{combo[0].text}, {combo[1].text}, {combo[2].text}\")\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a mother in law who is 90yrs old, lives on her own, has diabetes and asthma, \n",
    "so there for self isolating. I am checking on her daily, taking food etc. \n",
    "I go there once a week to change her bedding, which she is safely in her conservatory. \n",
    "I work for a train company but not in a safety critical role, \n",
    "I only serve drinks/snacks, which has been suspended now. \n",
    "They want me to come in to clean inside trains ( where the public are) \n",
    "and the stations. I have said that I don’t want to come in as caring for my mother in law. They have told me \n",
    "that I will have to go off sick and get a sick note from GP? \n",
    "Then I will only get statutory sick pay! I don’t want to run the risk \n",
    "of infecting my at risk elderly parent. Where do I stand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect arg1-arg2 grammatical patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6776bf48f6eb4fb39124790fb2fb6ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys([('verb', 'noun'), ('noun', 'adjective'), ('adjective', 'prep_noun'), ('verb', 'adjective'), ('adjective', 'punct'), ('noun', 'prep_noun'), ('prep_noun', 'noun'), ('pronoun', 'verb'), ('prep_noun', 'verb'), ('punct', 'verb'), ('noun', 'cc'), ('cc', 'noun'), ('noun', 'punct'), ('punct', 'rb'), ('rb', 'prep_noun'), ('noun', 'verb'), ('punct', 'pronoun'), ('cc', 'rb'), ('prep_noun', 'adjective'), ('adjective', 'noun'), ('pronoun', 'rb'), ('rb', 'verb'), ('verb', 'punct'), ('verb', 'pronoun'), ('punct', 'noun'), ('punct', 'cc'), ('prep_noun', 'punct'), ('adjective', 'cc'), ('cc', 'verb'), ('rb', 'pronoun'), ('verb', 'prep_noun'), ('pronoun', 'cc'), ('prep_noun', 'prep_noun'), ('noun', 'pronoun'), ('pronoun', 'punct'), ('adjective', 'verb'), ('cc', 'pronoun'), ('adjective', 'pronoun'), ('verb', 'cc'), ('rb', 'adjective'), ('verb', 'noun_verb'), ('noun_verb', 'cc'), ('pronoun', 'noun'), ('noun', 'rb'), ('prep_noun', 'cc'), ('adjective', 'rb'), ('prep_noun', 'pronoun'), ('pronoun', 'adjective'), ('noun_verb', 'prep_noun'), ('pronoun', 'prep_noun'), ('noun_verb', 'verb'), ('noun_verb', 'punct'), ('rb', 'punct'), ('noun_verb', 'pronoun'), ('prep_noun', 'rb'), ('punct', 'prep_noun'), ('noun', 'noun_verb'), ('noun_verb', 'adjective'), ('cc', 'prep_noun'), ('prep_noun', 'noun_verb'), ('punct', 'adjective'), ('cc', 'adjective'), ('noun_verb', 'noun'), ('punct', 'noun_verb'), ('rb', 'cc'), ('cc', 'noun_verb'), ('noun_verb', 'rb'), ('pronoun', 'noun_verb'), ('rb', 'noun'), ('verb', 'rb'), ('rb', 'noun_verb'), ('adjective', 'noun_verb'), ('cc', 'punct')]),\n",
       " 73)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_d = compute_linguistic_patterns(df.pos_tag, 2)\n",
    "pattern_d.keys(), len(pattern_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_of_interest = [('verb', 'noun'),\n",
    "('noun', 'prep_noun'),\n",
    "('prep_noun', 'prep_noun'),\n",
    "('verb', 'noun_verb'),\n",
    "('verb', 'prep_noun'),\n",
    "('noun', 'noun_verb'),\n",
    "('noun_verb', 'prep_noun')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `arg1` - `arg2` co-occurrence db - couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d72f735bee146bc97a0d66413652e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 73 possible grammatical combos.\n",
      "('verb', 'noun') 9341\n",
      "('noun', 'punct') 4251\n",
      "('noun', 'prep_noun') 3513\n",
      "('noun', 'verb') 3435\n",
      "('verb', 'pronoun') 2649\n",
      "('verb', 'adjective') 2499\n",
      "('noun', 'cc') 2352\n",
      "('prep_noun', 'punct') 2319\n",
      "('verb', 'punct') 1780\n",
      "('prep_noun', 'noun') 1594\n",
      "('noun', 'pronoun') 1556\n",
      "('prep_noun', 'verb') 1484\n",
      "('prep_noun', 'prep_noun') 1403\n",
      "('prep_noun', 'cc') 1064\n",
      "('noun', 'rb') 1027\n"
     ]
    }
   ],
   "source": [
    "pattern_db = {}\n",
    "\n",
    "for vals in tqdm_notebook(df.pos_tag.values):\n",
    "    sents = extract_phrase(vals, True)\n",
    "    for combo in compute_combinations(sents, 2):\n",
    "        key = (combo[0].label, combo[1].label)\n",
    "        arg1 = combo[0].text.lower()\n",
    "        arg2 = combo[1].text.lower()\n",
    "#         arg2 = \" \".join([w.lower() for w,_ in combo[1].tagable_words()])\n",
    "        \n",
    "        if key not in pattern_db.keys():\n",
    "            pattern_db[key] = {}\n",
    "        if arg1 not in pattern_db[key].keys():\n",
    "            pattern_db[key][arg1] = Counter()\n",
    "            \n",
    "        pattern_db[key][arg1][arg2]+=1\n",
    "\n",
    "print(f\"There are {len(pattern_db)} possible grammatical combos.\")\n",
    "for i, (k,v) in enumerate(sorted(pattern_db.items(),\n",
    "                         key = lambda x: len(x[1].values()),\n",
    "                         reverse= True)[0:15],\n",
    "                                 1):\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 got\n",
      "2 to tax\n",
      "3 can\n",
      "4 came to\n",
      "5 having\n",
      "6 driving\n",
      "7 use\n",
      "8 regarding\n",
      "9 says\n",
      "10 say\n",
      "11 following\n",
      "12 to send\n"
     ]
    }
   ],
   "source": [
    "top_100_verbs = [key.lower() for key, value in sorted(pattern_db[('verb', 'noun')].items(), \n",
    "                         key = lambda x: sum(x[1].values()), \n",
    "                         reverse= True)[0:100]]\n",
    "counter = 0\n",
    "for verb in top_100_verbs:\n",
    "    if regex_group_verbs(verb)== \"unknown\":\n",
    "        counter+=1\n",
    "        print(counter, verb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_argument_theme_dictionary(dict_new, dict_old):\n",
    "    for theme, value in dict_new.items():\n",
    "        if theme not in dict_old.keys():\n",
    "            dict_old[theme] = Counter()\n",
    "        for val,count in value.items():\n",
    "            dict_old[theme][val]+=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9341 verbs, accompanied by nouns.\n",
      "There are 358 verbs, accompanied by prep_nouns.\n"
     ]
    }
   ],
   "source": [
    "verb_themes = {}\n",
    "verb_argument_themes = {}\n",
    "argument_themes = {}\n",
    "\n",
    "for pattern in [('verb', 'noun'), ('verb', 'prep_noun')]:\n",
    "    print(f\"There are {len(pattern_db[pattern])} {pattern[0]}s, accompanied by {pattern[1]}s.\")\n",
    "    for i, (arg1, arg2) in enumerate(sorted(pattern_db[pattern].items(),\n",
    "                             key = lambda x: sum(x[1].values()),\n",
    "                             reverse= True),\n",
    "                                     1):\n",
    "        verb_theme = f\"{regex_group_verbs(arg1)}\".upper()\n",
    "\n",
    "        if verb_theme not in verb_themes.keys():\n",
    "            verb_themes[verb_theme] = Counter()\n",
    "        \n",
    "        verb_themes[verb_theme][arg1] += sum(arg2.values())  \n",
    "        \n",
    "#         print(f\"{i}. {arg1} :: {sum(arg2.values())} [{verb_theme}] \\n-----------\")\n",
    "        \n",
    "        if verb_theme not in verb_argument_themes.keys():\n",
    "            verb_argument_themes[verb_theme] = {}\n",
    "\n",
    "        local_themes = {}\n",
    "        \n",
    "        for j, (arg2_val, arg2_counts) in enumerate(arg2.items(), 1):\n",
    "            theme = f\"{regex_for_theme(arg2_val)}\".upper()\n",
    "            if theme not in local_themes.keys():\n",
    "                local_themes[theme] = Counter()\n",
    "                \n",
    "            if theme not in argument_themes.keys():   \n",
    "                argument_themes[theme] = Counter()   \n",
    "                \n",
    "            local_themes[theme][arg2_val]+=arg2_counts   \n",
    "            argument_themes[theme][arg2_val]+=arg2_counts  \n",
    "            \n",
    "        update_argument_theme_dictionary(local_themes, verb_argument_themes[verb_theme])\n",
    "#             print(f\"{j}. {arg2_val} : {arg2_counts} [{regex_for_theme(arg1 +' '+arg2_val)}]\")\n",
    "#         for l, (key,value) in enumerate(sorted(local_themes.items(),\n",
    "#                              key = lambda x: sum(x[1].values()),\n",
    "#                              reverse= True)[0:10],\n",
    "#                                      1):\n",
    "#             print(f\"{l}. {key}:: {sum(value.values())}\")\n",
    "#             for argument, count in value.most_common(5):\n",
    "#                 print(f\"{argument}: {count}\")\n",
    "#             print(\"\")\n",
    "#         print(\"=======\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(argument_themes), len(verb_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UNKNOWN\n",
      "1 INFORMATION\n",
      "2 WORK-MENTION\n",
      "3 CORRESPONDENCE\n",
      "4 SUPPORT\n",
      "5 DELIVERY\n",
      "6 HEALTH-PROBLEM\n",
      "7 BILLS-TO-PAY\n",
      "8 GOODS\n",
      "9 COVID-MENTION\n",
      "10 FAMILY\n",
      "11 HOME-MENTION\n",
      "12 VULNERABLE\n",
      "13 LICENSE\n",
      "14 GIVEN-MONEY\n",
      "15 CHILD\n",
      "16 BENEFIT\n",
      "17 NO-ONE\n",
      "18 ELDERLY\n",
      "19 SELF-ISOLATION\n",
      "20 DATA\n",
      "21 NO-INFORMATION\n",
      "22 UNCERTAINTY\n",
      "23 PENSION\n",
      "24 AT-RISK\n",
      "25 TRAVEL\n",
      "26 LAID-OFF\n",
      "27 RULES\n",
      "28 SCHOOL\n",
      "29 KEY-WORKER\n",
      "30 NO-INCOME\n",
      "31 CARER\n",
      "32 PASSPORT\n",
      "33 GET-MED\n",
      "34 DEATH\n",
      "35 NO-SUPPORT\n",
      "36 SYMPTOMS\n",
      "37 VISA\n",
      "38 NO-CORRESPONDENCE\n",
      "39 DISABLED\n",
      "40 SCHEME\n",
      "41 SELF-EMPLOY\n",
      "42 NO-SYMPTOMS\n",
      "43 WORK\n"
     ]
    }
   ],
   "source": [
    "for i, (argument_type, argument_values) in enumerate(sorted(argument_themes.items(),\n",
    "                             key = lambda x: sum(x[1].values()),\n",
    "                             reverse= True),\n",
    "                                     0):\n",
    "    print(i, argument_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UNKNOWN\n",
      "got 78\n",
      "to tax 55\n",
      "can 48\n",
      "came to 32\n",
      "having 28\n",
      "driving 24\n",
      "use 24\n",
      "say 22\n",
      "regarding 21\n",
      "says 20\n",
      "1 MY-SITUATION\n",
      "have 830\n",
      "am 353\n",
      "have had 90\n",
      "'m 54\n",
      "am in 53\n",
      "am on 50\n",
      "do not have 40\n",
      "’m 33\n",
      "do n’t have 27\n",
      "do n't have 26\n",
      "2 ACQUIRE-SMTHG\n",
      "to get 335\n",
      "get 218\n",
      "received 149\n",
      "can not get 101\n",
      "can get 89\n",
      "have received 65\n",
      "have not received 65\n",
      "ca n't get 42\n",
      "take 40\n",
      "to claim 39\n",
      "3 FIND-SMTHG\n",
      "to find 170\n",
      "looking for 130\n",
      "to find out 88\n",
      "was looking for 57\n",
      "can not find 54\n",
      "to see 51\n",
      "to find out about 46\n",
      "to look for 43\n",
      "find 40\n",
      "to find out if 33\n",
      "4 UNCLEAR-SITUATION\n",
      "is 563\n",
      "had 174\n",
      "was 76\n",
      "'s 37\n",
      "is in 37\n",
      "is on 32\n",
      "is not 27\n",
      "was in 26\n",
      "’s 21\n",
      "was on 18\n",
      "5 OTHERS-SITUATION\n",
      "has 215\n",
      "are 151\n",
      "are in 59\n",
      "has had 23\n",
      "has been 11\n",
      "are on 10\n",
      "re 9\n",
      "are not 9\n",
      "were 9\n",
      "care for 7\n",
      "6 NEED-SMTHG\n",
      "need 288\n",
      "wanted 40\n",
      "want 31\n",
      "needs 26\n",
      "needed 21\n",
      "would like 17\n",
      "to order 12\n",
      "require 10\n",
      "need to speak to 10\n",
      "to request 8\n",
      "7 APPLY-SMTHG\n",
      "to register 55\n",
      "to register as 39\n",
      "to apply for 33\n",
      "to register for 28\n",
      "registered 17\n",
      "apply for 16\n",
      "register 16\n",
      "to register on 14\n",
      "applied for 12\n",
      "can apply for 10\n",
      "8 ACCESS-SMTHG\n",
      "to check 74\n",
      "to access 35\n",
      "check 26\n",
      "to complete 22\n",
      "to check on 22\n",
      "to book 15\n",
      "to cancel 12\n",
      "can not access 12\n",
      "checking 12\n",
      "wanted to check 11\n",
      "9 DO-SMTHNG\n",
      "to make 49\n",
      "to do 44\n",
      "do 38\n",
      "make 21\n",
      "doing 16\n",
      "does 15\n",
      "makes 10\n",
      "to do with 7\n",
      "can do 7\n",
      "can not do 7\n",
      "10 WORK-SMWHR\n",
      "work in 40\n",
      "work for 19\n",
      "work 19\n",
      "working in 11\n",
      "working 10\n",
      "work as 8\n",
      "work at 7\n",
      "to work from 7\n",
      "work from 6\n",
      "to work due to 6\n",
      "11 CHANGE-SMTHG\n",
      "to renew 62\n",
      "to change 49\n",
      "renew 28\n",
      "change 19\n",
      "renew driving 14\n",
      "changed 12\n",
      "need to renew 11\n",
      "need to change 10\n",
      "want to change 8\n",
      "to renew driving 6\n",
      "12 PAY-SMTHG\n",
      "to pay 52\n",
      "pay 38\n",
      "paid 16\n",
      "pays 8\n",
      "paid for 7\n",
      "to pay for 7\n",
      "have to pay 6\n",
      "have paid 5\n",
      "need to pay 4\n",
      "trying to pay 4\n",
      "13 LIVING\n",
      "live in 61\n",
      "to stay at 25\n",
      "live 18\n",
      "live with 12\n",
      "stay at 11\n",
      "lives in 9\n",
      "living in 8\n",
      "to stay 7\n",
      "lives 7\n",
      "to deliver 6\n",
      "14 CONTACT-SMTHG\n",
      "to report 35\n",
      "to contact 34\n",
      "have contacted 12\n",
      "contacted 10\n",
      "report 8\n",
      "contact 7\n",
      "need to contact 6\n",
      "of contacting 5\n",
      "wanted to report 5\n",
      "can contact 4\n",
      "15 GO-SMWHR\n",
      "to go to 31\n",
      "go to 16\n",
      "to go on 8\n",
      "to go 6\n",
      "to go back to 6\n",
      "can go to 6\n",
      "go 5\n",
      "go for 4\n",
      "to go out in 4\n",
      "can not go to 4\n",
      "16 HELP\n",
      "to help 23\n",
      "help with 15\n",
      "to help with 11\n",
      "to support 11\n",
      "to protect 8\n",
      "support 7\n",
      "help 7\n",
      "help in 3\n",
      "help on 3\n",
      "help for 2\n",
      "17 GIVE-SMTHNG\n",
      "give 16\n",
      "to give 12\n",
      "given 11\n",
      "provide 9\n",
      "to provide 9\n",
      "gives 3\n",
      "to give to 2\n",
      "could be given 2\n",
      "provided 2\n",
      "'ve tried to email provided 1\n",
      "18 TRAVEL\n",
      "to travel to 5\n",
      "travel 4\n",
      "to travel from 2\n",
      "can travel in 2\n",
      "to travel in 2\n",
      "to travel 2\n",
      "can travel to 2\n",
      "travel to 2\n",
      "would not consider travelling to 1\n",
      "should not be travelling 1\n"
     ]
    }
   ],
   "source": [
    "for i, (verb_type, verb_values) in enumerate(sorted(verb_themes.items(),\n",
    "                             key = lambda x: sum(x[1].values()),\n",
    "                             reverse= True),\n",
    "                                     0):\n",
    "    print(i, verb_type)    \n",
    "    for verb_value, count in verb_values.most_common(10):\n",
    "        print(verb_value, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MY-SITUATION 3208 43 \n",
      "======\n",
      "HEALTH-PROBLEM\n",
      "copd: 42\n",
      "asthma: 20\n",
      "diabetes: 15\n",
      "health problems: 11\n",
      "cancer: 11\n",
      "---\n",
      "INFORMATION\n",
      "the list: 13\n",
      "list: 11\n",
      "the form: 6\n",
      "details: 4\n",
      "a number: 3\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 42\n",
      "a job: 6\n",
      "an employee: 4\n",
      "job: 4\n",
      "2 jobs: 3\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 48\n",
      "letter: 7\n",
      "letters: 4\n",
      "email: 2\n",
      "letter.no: 1\n",
      "---\n",
      "ELDERLY\n",
      "77 years: 8\n",
      "73 years: 8\n",
      "81 years: 5\n",
      "80 years: 5\n",
      "71 years: 5\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable person: 26\n",
      "extremely vulnerable person: 5\n",
      "the vulnerable list: 4\n",
      "extremely vulnerable group: 4\n",
      "the vulnerable category: 3\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 24\n",
      "no one: 16\n",
      "no family: 15\n",
      "nobody shops: 1\n",
      "nothing other: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 27\n",
      "housebound: 5\n",
      "house: 5\n",
      "the house: 3\n",
      "home sats: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 4\n",
      "a single parent: 4\n",
      "wife: 3\n",
      "family: 2\n",
      "mother: 2\n",
      "---\n",
      "NO-INCOME\n",
      "no income: 21\n",
      "no money: 14\n",
      "no work: 5\n",
      "no wages: 3\n",
      "no money national insurance number: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "a mortgage: 4\n",
      "a tax rebate: 4\n",
      "bills: 3\n",
      "debt: 2\n",
      "tax return: 2\n",
      "---\n",
      "COVID-MENTION\n",
      "covid-19: 9\n",
      "covid 19: 7\n",
      "the virus: 6\n",
      "covid19: 5\n",
      "coronavirus: 3\n",
      "---\n",
      "SELF-ISOLATION\n",
      "isolation: 12\n",
      "self isolation: 10\n",
      "self isolating: 7\n",
      "self isolate: 6\n",
      "lockdown: 3\n",
      "---\n",
      "CHILD\n",
      "children: 6\n",
      "daughter: 6\n",
      "son: 5\n",
      "a son: 4\n",
      "grandchildren: 2\n",
      "---\n",
      "KEY-WORKER\n",
      "a key worker: 31\n",
      "a keyworker: 4\n",
      "a staff nurse: 1\n",
      "a nurse: 1\n",
      "a key worker son: 1\n",
      "---\n",
      "GOODS\n",
      "shopping: 12\n",
      "food: 9\n",
      "no food: 2\n",
      "money no food: 1\n",
      "food items: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 12\n",
      "a high risk person: 2\n",
      "a high risk: 2\n",
      "the high risk: 2\n",
      "a high risk group: 2\n",
      "---\n",
      "SUPPORT\n",
      "priority: 3\n",
      "a priority: 3\n",
      "access: 3\n",
      "help: 3\n",
      "support: 2\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 10\n",
      "any money: 8\n",
      "a tax refund: 2\n",
      "the money: 2\n",
      "a refund: 2\n",
      "---\n",
      "UNCERTAINTY\n",
      "no idea: 14\n",
      "no way: 4\n",
      "no choice: 4\n",
      "a way: 2\n",
      "a choice: 2\n",
      "---\n",
      "DELIVERY\n",
      "deliveries: 2\n",
      "no slots: 2\n",
      "a delivery driver: 2\n",
      "a delivery slot: 2\n",
      "any slots: 1\n",
      "---\n",
      "BENEFIT\n",
      "pip: 5\n",
      "ssp: 2\n",
      "any benefit: 2\n",
      "eligible: 1\n",
      "some ssp: 1\n",
      "---\n",
      "CARER\n",
      "carer: 7\n",
      "a carer: 6\n",
      "carers: 2\n",
      "husband carer: 1\n",
      "the sole carer: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 11\n",
      "any symptoms: 2\n",
      "the symptoms: 1\n",
      "symptoms extreme: 1\n",
      "concerned with the symptoms: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 4\n",
      "no advice: 2\n",
      "no contact: 2\n",
      "no form: 1\n",
      "no other form: 1\n",
      "---\n",
      "PENSION\n",
      "pension: 4\n",
      "a pension payslip: 1\n",
      "a small euro pension: 1\n",
      "a basic state pension: 1\n",
      "a state pension employer: 1\n",
      "---\n",
      "LICENSE\n",
      "driving licence: 2\n",
      "licence: 2\n",
      "license: 2\n",
      "a licence: 1\n",
      "an old licence: 1\n",
      "---\n",
      "SCHOOL\n",
      "a student: 2\n",
      "student finance: 1\n",
      "student loans: 1\n",
      "the first year student: 1\n",
      "an international student: 1\n",
      "---\n",
      "LAID-OFF\n",
      "the furlough scheme: 3\n",
      "furlough: 3\n",
      "80 % pay: 1\n",
      "the current furlough agreement: 1\n",
      "80 % wage: 1\n",
      "---\n",
      "PASSPORT\n",
      "a passport: 2\n",
      "no passport: 1\n",
      "an irish passport uc: 1\n",
      "português passport: 1\n",
      "an austrian passport: 1\n",
      "---\n",
      "DATA\n",
      "a situation: 3\n",
      "status: 2\n",
      "no immigration status: 1\n",
      "multiple sclerosis the primary progressive type: 1\n",
      "a desperate situation: 1\n",
      "---\n",
      "DISABLED\n",
      "a disabled badge: 1\n",
      "class disability: 1\n",
      "a disabled member: 1\n",
      "no disability: 1\n",
      "disability problems sciatica arthritis poly arthritis poly arthralgia: 1\n",
      "---\n",
      "GET-MED\n",
      "medication: 6\n",
      "medications: 2\n",
      "prescriptions: 1\n",
      "a prescription: 1\n",
      "---\n",
      "TRAVEL\n",
      "a flight: 3\n",
      "flight: 1\n",
      "a return flight: 1\n",
      "five flights: 1\n",
      "no direct commercial flights: 1\n",
      "---\n",
      "NO-CORRESPONDENCE\n",
      "no letter: 6\n",
      "no communication: 2\n",
      "no email: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 4\n",
      "no access: 2\n",
      "no support network: 1\n",
      "no priority: 1\n",
      "---\n",
      "DEATH\n",
      "death sentences heads: 1\n",
      "a death sentence: 1\n",
      "deaths hands: 1\n",
      "death hands: 1\n",
      "the deaths: 1\n",
      "---\n",
      "VISA\n",
      "a spousal visa: 1\n",
      "a uk settlement visa: 1\n",
      "a settlement visa valid: 1\n",
      "a tourist visa: 1\n",
      "---\n",
      "RULES\n",
      "no rights: 1\n",
      "the social distancing rules: 1\n",
      "---\n",
      "NO-SYMPTOMS\n",
      "no symptoms: 1\n",
      "with no symptoms: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "the self employment scheme: 1\n",
      "self employment: 1\n",
      "---\n",
      "SCHEME\n",
      "the scheme: 1\n",
      "---\n",
      "\n",
      "2. ACQUIRE-SMTHG 2709 40 \n",
      "======\n",
      "DELIVERY\n",
      "a slot: 39\n",
      "a delivery slot: 34\n",
      "a delivery: 21\n",
      "home delivery: 13\n",
      "deliveries: 10\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 122\n",
      "letter: 24\n",
      "an email: 22\n",
      "a text: 13\n",
      "the letter: 11\n",
      "---\n",
      "SUPPORT\n",
      "help: 105\n",
      "any help: 20\n",
      "support: 13\n",
      "priority: 12\n",
      "access: 9\n",
      "---\n",
      "INFORMATION\n",
      "information: 31\n",
      "an answer: 11\n",
      "advice: 10\n",
      "contact: 8\n",
      "the list: 8\n",
      "---\n",
      "GOODS\n",
      "food: 44\n",
      "shopping: 31\n",
      "a food parcel: 9\n",
      "any shopping: 6\n",
      "groceries: 5\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 29\n",
      "a refund: 10\n",
      "a grant: 8\n",
      "some money: 7\n",
      "any money: 6\n",
      "---\n",
      "BENEFIT\n",
      "benefits: 11\n",
      "ssp: 10\n",
      "universal credit: 6\n",
      "esa: 5\n",
      "pip: 4\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "tax: 7\n",
      "tax return: 4\n",
      "car tax: 3\n",
      "a vehicle tax reminder: 3\n",
      "insurance: 2\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 11\n",
      "employment: 3\n",
      "company: 3\n",
      "a small business grant: 2\n",
      "job: 2\n",
      "---\n",
      "COVID-MENTION\n",
      "covid 19: 6\n",
      "coronavirus: 5\n",
      "the virus: 5\n",
      "this virus: 2\n",
      "covid-19: 2\n",
      "---\n",
      "PENSION\n",
      "state pension: 7\n",
      "pension: 5\n",
      "a pension forecast: 2\n",
      "pension credit: 2\n",
      "a pension summary: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 %: 11\n",
      "80 % wages: 5\n",
      "the furlough: 2\n",
      "80 % furlough wage: 1\n",
      "80 % pay: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 3\n",
      "son: 3\n",
      "child benefit: 2\n",
      "child: 2\n",
      "child tax: 1\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 14\n",
      "a caution nothing the injuries: 1\n",
      "nothing tel 0282766: 1\n",
      "esa nobody: 1\n",
      "nothing question: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable letter: 4\n",
      "the vulnerable list: 3\n",
      "the vulnerable register: 2\n",
      "information a vulnerable person: 1\n",
      "nhs vulnerable letter: 1\n",
      "---\n",
      "GET-MED\n",
      "medication: 5\n",
      "prescription: 3\n",
      "medications: 2\n",
      "repeat prescriptions: 2\n",
      "medicals: 1\n",
      "---\n",
      "LICENSE\n",
      "licence: 4\n",
      "drivers licence: 2\n",
      "driving licence: 2\n",
      "the licence: 1\n",
      "driving license: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 3\n",
      "family: 2\n",
      "daily chemotherapy: 1\n",
      "one cause mum: 1\n",
      "ex husband: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home visits: 3\n",
      "house: 3\n",
      "a home kit: 1\n",
      "household shopping: 1\n",
      "the house: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 6\n",
      "no support: 2\n",
      "no help gp: 1\n",
      "hospital no help: 1\n",
      "---\n",
      "TRAVEL\n",
      "a flight home: 3\n",
      "a flight: 2\n",
      "travel mileage: 1\n",
      "date travel information: 1\n",
      "travel alerts: 1\n",
      "---\n",
      "SCHOOL\n",
      "student finance: 2\n",
      "school voucher: 1\n",
      "a student loan: 1\n",
      "a school place: 1\n",
      "schools: 1\n",
      "---\n",
      "ELDERLY\n",
      "food 91 year: 1\n",
      "help 85 year: 1\n",
      "a letter 90 year: 1\n",
      "87 year: 1\n",
      "70 year: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 2\n",
      "the high risk e mail: 1\n",
      "a high risk letter: 1\n",
      "any risks: 1\n",
      "the risk: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport: 3\n",
      "a new british passport: 1\n",
      "passport photo: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "a self isolation note: 2\n",
      "an isolation note employers: 1\n",
      "isolation pay: 1\n",
      "the voluntary isolation: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "this awful disease: 1\n",
      "the same healthcare: 1\n",
      "the disease: 1\n",
      "heart disease medication: 1\n",
      "with health: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 3\n",
      "no advice: 1\n",
      "no phone number available: 1\n",
      "---\n",
      "NO-CORRESPONDENCE\n",
      "no letter: 3\n",
      "no text: 1\n",
      "no email: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "any symptoms: 2\n",
      "symptoms: 1\n",
      "some symptoms: 1\n",
      "---\n",
      "NO-INCOME\n",
      "no money: 2\n",
      "no work: 1\n",
      "---\n",
      "RULES\n",
      "the official rules: 1\n",
      "restrictions: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "answers self employment grant questions: 1\n",
      "self employment benefit: 1\n",
      "---\n",
      "CARER\n",
      "carers: 1\n",
      "carers allowance: 1\n",
      "---\n",
      "DEATH\n",
      "a death certificate: 1\n",
      "---\n",
      "DISABLED\n",
      "the disability allowance: 1\n",
      "---\n",
      "SCHEME\n",
      "this scheme: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "any way: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "some other key workers: 1\n",
      "---\n",
      "\n",
      "3. FIND-SMTHG 2366 39 \n",
      "======\n",
      "INFORMATION\n",
      "information: 121\n",
      "advice: 63\n",
      "any information: 24\n",
      "guidance: 24\n",
      "info: 20\n",
      "---\n",
      "SUPPORT\n",
      "help: 81\n",
      "support: 18\n",
      "any help: 11\n",
      "assistance: 8\n",
      "some help: 6\n",
      "---\n",
      "WORK-MENTION\n",
      "employer: 8\n",
      "work: 5\n",
      "a job: 5\n",
      "employees: 4\n",
      "the job retention scheme: 3\n",
      "---\n",
      "COVID-MENTION\n",
      "the virus: 5\n",
      "coronavirus: 3\n",
      "the coronavirus: 2\n",
      "covid-19 guidance: 2\n",
      "the coronavirus job retention scheme: 2\n",
      "---\n",
      "FAMILY\n",
      "father: 6\n",
      "mother: 6\n",
      "parents: 5\n",
      "husband: 5\n",
      "dad: 4\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 6\n",
      "an email: 4\n",
      "the letter: 3\n",
      "message: 3\n",
      "letter: 3\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "tax code: 5\n",
      "tax rebate: 2\n",
      "a tax rebate: 2\n",
      "tax: 2\n",
      "a tax return: 2\n",
      "---\n",
      "DATA\n",
      "the situation: 6\n",
      "data: 3\n",
      "the progress: 3\n",
      "situation: 3\n",
      "status: 3\n",
      "---\n",
      "DELIVERY\n",
      "food delivery: 5\n",
      "food deliveries: 4\n",
      "any delivery slots: 3\n",
      "a delivery: 3\n",
      "delivery slots: 3\n",
      "---\n",
      "RULES\n",
      "the rules: 12\n",
      "rules: 7\n",
      "rights: 4\n",
      "restrictions: 3\n",
      "the exact rules: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "a way: 28\n",
      "any way: 9\n",
      "no means: 1\n",
      "any means: 1\n",
      "---\n",
      "CHILD\n",
      "children: 10\n",
      "son: 8\n",
      "daughter: 4\n",
      "childcare: 1\n",
      "child arrangement orders: 1\n",
      "---\n",
      "LICENSE\n",
      "license: 5\n",
      "licence: 4\n",
      "driving licence: 4\n",
      "driving license: 3\n",
      "licence renewal: 2\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 3\n",
      "funding: 2\n",
      "grant: 2\n",
      "refund: 2\n",
      "a refund: 2\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "conditions: 2\n",
      "illnesses the gov: 1\n",
      "a local mental health support telephone service: 1\n",
      "diabetes advice: 1\n",
      "people diabetes: 1\n",
      "---\n",
      "TRAVEL\n",
      "travel: 4\n",
      "a flight: 2\n",
      "travel restrictions: 2\n",
      "flights: 2\n",
      "travel information: 1\n",
      "---\n",
      "BENEFIT\n",
      "benefits: 3\n",
      "universal credit: 2\n",
      "benefit: 2\n",
      "sickness benefit claim: 1\n",
      "the attendance allowance rates: 1\n",
      "---\n",
      "LAID-OFF\n",
      "furlough: 5\n",
      "80 %: 4\n",
      "the furlough scheme: 2\n",
      "the furlough abuse hotline: 1\n",
      "furlough leave: 1\n",
      "---\n",
      "PENSION\n",
      "pension: 6\n",
      "state pension: 3\n",
      "a pension forecast: 1\n",
      "pension credit: 1\n",
      "armed forces pension: 1\n",
      "---\n",
      "GOODS\n",
      "food parcels: 4\n",
      "food: 3\n",
      "shopping: 1\n",
      "food supplies: 1\n",
      "supplies: 1\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 12\n",
      "nobody: 1\n",
      "day no one doctors: 1\n",
      "no one: 1\n",
      "help wen no one: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable person: 4\n",
      "the vulnerable person advice re: 1\n",
      "a severe vulnerable disabled person: 1\n",
      "a vulnerable child: 1\n",
      "the vulnerable persons list: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 3\n",
      "the home: 1\n",
      "home page: 1\n",
      "household cleaning products: 1\n",
      "a university student home: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "a isolation note: 1\n",
      "the isolation period: 1\n",
      "self isolation: 1\n",
      "a self isolation note: 1\n",
      "the isolation: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 4\n",
      "no mention: 2\n",
      "no answers: 1\n",
      "no guidance: 1\n",
      "---\n",
      "DEATH\n",
      "the deadline: 1\n",
      "the death toll: 1\n",
      "the death date: 1\n",
      "the daily deaths: 1\n",
      "death: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport interviews: 1\n",
      "a urgent passport: 1\n",
      "passport: 1\n",
      "a passport the holder: 1\n",
      "a replacement passport: 1\n",
      "---\n",
      "SCHOOL\n",
      "a current student: 1\n",
      "student loan: 1\n",
      "the school: 1\n",
      "schools: 1\n",
      "student loan repayments: 1\n",
      "---\n",
      "CARER\n",
      "carers washing: 1\n",
      "home carers: 1\n",
      "a replacement carer: 1\n",
      "carers allowance: 1\n",
      "care homes: 1\n",
      "---\n",
      "ELDERLY\n",
      "89 year: 1\n",
      "92 year: 1\n",
      "99 year: 1\n",
      "75 year: 1\n",
      "---\n",
      "SCHEME\n",
      "a scheme: 1\n",
      "the scheme instructions: 1\n",
      "youth mobility scheme visa: 1\n",
      "about the national voucher scheme: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 1\n",
      "the symptoms: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of the symptoms: 1\n",
      "---\n",
      "DISABLED\n",
      "a disabled person: 2\n",
      "disabled child 24/7: 1\n",
      "---\n",
      "VISA\n",
      "visa: 1\n",
      "visa appeal application: 1\n",
      "uk visa: 1\n",
      "---\n",
      "AT-RISK\n",
      "the high risk definitions: 1\n",
      "about the high risk group: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "a key worker son: 1\n",
      "---\n",
      "GET-MED\n",
      "a repeat prescription: 1\n",
      "---\n",
      "\n",
      "4. UNCLEAR-SITUATION 1888 41 \n",
      "======\n",
      "INFORMATION\n",
      "a link: 6\n",
      "info: 5\n",
      "information: 5\n",
      "list: 5\n",
      "guidance: 4\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 24\n",
      "a message: 10\n",
      "letter: 7\n",
      "a text: 5\n",
      "a text message: 2\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 21\n",
      "no guidance: 6\n",
      "no mention: 5\n",
      "no advice: 4\n",
      "no link: 3\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "a stroke: 5\n",
      "an issue: 3\n",
      "type 1 diabetic: 2\n",
      "breast cancer: 2\n",
      "a heart attack: 2\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 17\n",
      "employer: 4\n",
      "a care worker: 3\n",
      "a company: 2\n",
      "business: 2\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 25\n",
      "no one: 3\n",
      "nobody: 2\n",
      "nothing similar: 1\n",
      "nothing online: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "no way: 18\n",
      "no option: 5\n",
      "any way: 3\n",
      "a way: 3\n",
      "no means: 2\n",
      "---\n",
      "COVID-MENTION\n",
      "the virus: 5\n",
      "covid-19: 5\n",
      "this virus: 2\n",
      "covid 19: 2\n",
      "covid 19 positive: 1\n",
      "---\n",
      "SUPPORT\n",
      "help: 8\n",
      "any help: 7\n",
      "some help: 2\n",
      "government help: 1\n",
      "any support: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "tax: 3\n",
      "rent: 2\n",
      "an apprentice: 1\n",
      "no feed: 1\n",
      "fined: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 2\n",
      "wife: 2\n",
      "impossible at the moment: 2\n",
      "a partner a bigger professional partnership: 1\n",
      "a chemotherapy drug bones: 1\n",
      "---\n",
      "ELDERLY\n",
      "82 years: 3\n",
      "90 years: 2\n",
      "81 years: 2\n",
      "80 years: 2\n",
      "78 yrs: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 8\n",
      "a risk: 2\n",
      "a high risk area: 1\n",
      "a higher risk: 1\n",
      "an act risk person: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable person: 3\n",
      "the vulnerable list: 3\n",
      "the vulnerable category: 2\n",
      "a vulnerable adult: 1\n",
      "a vulnerable elderly lady: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 11\n",
      "no access: 1\n",
      "no assistance: 1\n",
      "no support: 1\n",
      "---\n",
      "CHILD\n",
      "son: 5\n",
      "daughter: 2\n",
      "single parent 2 children: 1\n",
      "granddaughter: 1\n",
      "the gov.uk/child-maintenance section: 1\n",
      "---\n",
      "CARER\n",
      "carer: 4\n",
      "a carer: 3\n",
      "a care home: 2\n",
      "carer husband: 1\n",
      "a carer dad: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "lockdown: 5\n",
      "isolation: 2\n",
      "12 week isolation: 1\n",
      "14 days isolation: 1\n",
      "self isolating: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 4\n",
      "house: 2\n",
      "staff shortages the homes: 1\n",
      "houses: 1\n",
      "the house: 1\n",
      "---\n",
      "DELIVERY\n",
      "deliveries: 3\n",
      "a delivery slot: 1\n",
      "1 delivery: 1\n",
      "food delivery: 1\n",
      "one delivery: 1\n",
      "---\n",
      "GOODS\n",
      "food: 4\n",
      "no food: 1\n",
      "a food parcel a week: 1\n",
      "a food parcel: 1\n",
      "food parcel: 1\n",
      "---\n",
      "NO-CORRESPONDENCE\n",
      "no letter: 3\n",
      "no communication: 2\n",
      "no email: 1\n",
      "no message: 1\n",
      "no email confirmation: 1\n",
      "---\n",
      "SCHOOL\n",
      "students: 2\n",
      "a student radiographer: 1\n",
      "a college student: 1\n",
      "s student: 1\n",
      "a full time student: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "a key worker: 6\n",
      "a community nurse: 1\n",
      "the district nurse: 1\n",
      "---\n",
      "BENEFIT\n",
      "maternity allowance calculate: 1\n",
      "benefits: 1\n",
      "ssp: 1\n",
      "the pipeline: 1\n",
      "eligible for the one: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 3\n",
      "a tax refund: 2\n",
      "money gojng: 1\n",
      "tax refund: 1\n",
      "any money: 1\n",
      "---\n",
      "DATA\n",
      "situation: 2\n",
      "a ridiculous situation: 1\n",
      "the situation: 1\n",
      "news: 1\n",
      "this situation: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 3\n",
      "these symptoms: 1\n",
      "the symptoms: 1\n",
      "---\n",
      "PENSION\n",
      "pensioner: 1\n",
      "pension: 1\n",
      "a british state pension: 1\n",
      "the state pension age changes: 1\n",
      "---\n",
      "RULES\n",
      "the rules: 1\n",
      "the current self distancing rules: 1\n",
      "those rules: 1\n",
      "the rule: 1\n",
      "---\n",
      "DISABLED\n",
      "a disabled 77yrs: 1\n",
      "a disabled person: 1\n",
      "a disabled space: 1\n",
      "---\n",
      "TRAVEL\n",
      "the travel restrictions: 1\n",
      "no flights: 1\n",
      "flights: 1\n",
      "---\n",
      "NO-INCOME\n",
      "no money: 2\n",
      "to.close shop no income wots: 1\n",
      "---\n",
      "PASSPORT\n",
      "uk passport holder: 1\n",
      "passport: 1\n",
      "---\n",
      "LICENSE\n",
      "license: 1\n",
      "a licence: 1\n",
      "---\n",
      "VISA\n",
      "a spouse settlement visa: 1\n",
      "application documents visa last week: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "a self employed worker: 1\n",
      "---\n",
      "GET-MED\n",
      "medication: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 % wages: 1\n",
      "---\n",
      "NO-SYMPTOMS\n",
      "no symptoms: 1\n",
      "---\n",
      "\n",
      "5. OTHERS-SITUATION 1218 42 \n",
      "======\n",
      "HEALTH-PROBLEM\n",
      "copd: 17\n",
      "diabetes: 7\n",
      "cancer: 7\n",
      "asthma: 6\n",
      "dementia: 4\n",
      "---\n",
      "INFORMATION\n",
      "the list: 6\n",
      "contact: 3\n",
      "information: 3\n",
      "a number: 2\n",
      "list: 2\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 6\n",
      "workers: 3\n",
      "business: 2\n",
      "no school work: 1\n",
      "both seasonal workers: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 13\n",
      "house: 4\n",
      "home country: 2\n",
      "homeowners: 1\n",
      "home 14 days: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "lockdown: 8\n",
      "isolation: 4\n",
      "self isolate: 3\n",
      "self isolating: 2\n",
      "self isolation: 2\n",
      "---\n",
      "COVID-MENTION\n",
      "covid 19: 3\n",
      "corona virus: 3\n",
      "coronavirus: 2\n",
      "the coronavirus: 2\n",
      "covid: 2\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 5\n",
      "emails: 4\n",
      "letter: 3\n",
      "a message: 1\n",
      "an email help: 1\n",
      "---\n",
      "DELIVERY\n",
      "no slots: 7\n",
      "no delivery slots: 3\n",
      "no shopping slots: 1\n",
      "no deliveries: 1\n",
      "food bank delivery: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 3\n",
      "a family: 2\n",
      "family history: 1\n",
      "dad: 1\n",
      "mother: 1\n",
      "---\n",
      "CHILD\n",
      "children: 4\n",
      "son: 3\n",
      "daughter: 2\n",
      "four children: 1\n",
      "a young daughter: 1\n",
      "---\n",
      "SUPPORT\n",
      "help: 3\n",
      "priority: 2\n",
      "support: 2\n",
      "heart help: 1\n",
      "no internet access: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no guidance: 2\n",
      "no link: 2\n",
      "no links: 2\n",
      "no information: 1\n",
      "no parliamentary contact details: 1\n",
      "---\n",
      "TRAVEL\n",
      "no flights: 2\n",
      "flights: 2\n",
      "a return flight: 1\n",
      "no flights home: 1\n",
      "any repatriation flights: 1\n",
      "---\n",
      "GOODS\n",
      "food: 4\n",
      "shopping: 2\n",
      "the food: 1\n",
      "a specialfood diet: 1\n",
      "food harvesting this year: 1\n",
      "---\n",
      "VULNERABLE\n",
      "the vulnerable list: 3\n",
      "both extremely vulnerable: 1\n",
      "the vulnerable section: 1\n",
      "the vulnerable category: 1\n",
      "the vulnerable person list: 1\n",
      "---\n",
      "ELDERLY\n",
      "70 years: 2\n",
      "93 year: 1\n",
      "85 yr: 1\n",
      "83 years: 1\n",
      "82 years: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 3\n",
      "no risk: 1\n",
      "both high risk: 1\n",
      "the high risk: 1\n",
      "the risk group: 1\n",
      "---\n",
      "NO-ONE\n",
      "no family: 4\n",
      "nothing: 4\n",
      "no one: 1\n",
      "nobody: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "no mortgage: 1\n",
      "no tax: 1\n",
      "bills: 1\n",
      "a renter: 1\n",
      "a new tax year: 1\n",
      "---\n",
      "NO-INCOME\n",
      "no work: 3\n",
      "no money: 3\n",
      "no income: 2\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 5\n",
      "these symptoms: 1\n",
      "---\n",
      "CARER\n",
      "carers: 2\n",
      "no carers: 1\n",
      "a carer: 1\n",
      "a care home: 1\n",
      "---\n",
      "DATA\n",
      "the news: 2\n",
      "a difficult situation: 1\n",
      "all my data: 1\n",
      "news: 1\n",
      "---\n",
      "VISA\n",
      "6 month visa: 1\n",
      "a residence visa: 1\n",
      "visa: 1\n",
      "visa approval: 1\n",
      "---\n",
      "DEATH\n",
      "deaths: 1\n",
      "deadlines: 1\n",
      "these deaths.ĺ: 1\n",
      "death: 1\n",
      "---\n",
      "NO-SYMPTOMS\n",
      "no symptoms: 4\n",
      "---\n",
      "SCHOOL\n",
      "school refusal: 1\n",
      "those students: 1\n",
      "school each day: 1\n",
      "school: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 2\n",
      "no access: 1\n",
      "retail there no help: 1\n",
      "---\n",
      "PENSION\n",
      "pensioners: 1\n",
      "four pensioners: 1\n",
      "pension credit: 1\n",
      "pension: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "keyworkers: 2\n",
      "a key worker: 1\n",
      "nurse: 1\n",
      "---\n",
      "RULES\n",
      "rules: 1\n",
      "the rules: 1\n",
      "2 meter rule: 1\n",
      "for restrictions: 1\n",
      "---\n",
      "BENEFIT\n",
      "benefits: 1\n",
      "changes pip benefits decbbie: 1\n",
      "allowances: 1\n",
      "on ssp: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "a refund: 1\n",
      "the grant: 1\n",
      "refund: 1\n",
      "---\n",
      "GET-MED\n",
      "medicals: 2\n",
      "prescriptions: 1\n",
      "---\n",
      "LICENSE\n",
      "licence: 2\n",
      "a private driving licence plate: 1\n",
      "---\n",
      "DISABLED\n",
      "a disability blue badge: 1\n",
      "a disabled son: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "no way: 1\n",
      "no option: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 %: 1\n",
      "furlough payments: 1\n",
      "---\n",
      "SCHEME\n",
      "this furlouf scheme: 1\n",
      "schemes: 1\n",
      "---\n",
      "PASSPORT\n",
      "no problem scanning passports: 1\n",
      "---\n",
      "NO-CORRESPONDENCE\n",
      "no email: 1\n",
      "---\n",
      "\n",
      "6. NEED-SMTHG 917 31 \n",
      "======\n",
      "INFORMATION\n",
      "information: 19\n",
      "advice: 17\n",
      "info: 7\n",
      "guidance: 6\n",
      "clarification: 5\n",
      "---\n",
      "SUPPORT\n",
      "help: 91\n",
      "some help: 14\n",
      "support: 8\n",
      "access: 5\n",
      "priority: 2\n",
      "---\n",
      "GOODS\n",
      "food: 23\n",
      "shopping: 6\n",
      "a food parcel: 4\n",
      "groceries: 4\n",
      "a free food parcel: 3\n",
      "---\n",
      "DELIVERY\n",
      "home delivery: 3\n",
      "home deliveries: 2\n",
      "slots: 2\n",
      "a supermarket delivery slot: 2\n",
      "a food delivery: 2\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 10\n",
      "the money: 4\n",
      "a refund: 3\n",
      "this money: 2\n",
      "that money: 2\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a letter: 6\n",
      "the letter: 2\n",
      "the letter files: 1\n",
      "letter employers: 1\n",
      "the text book van: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "a tax return: 2\n",
      "a budget loan: 1\n",
      "feed: 1\n",
      "tax tables b: 1\n",
      "insurance: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 6\n",
      "employees: 2\n",
      "a shielding note employers: 1\n",
      "new one works dbs check: 1\n",
      "the work: 1\n",
      "---\n",
      "LICENSE\n",
      "license: 3\n",
      "licence: 3\n",
      "an import license: 1\n",
      "a uk licence: 1\n",
      "license asap: 1\n",
      "---\n",
      "FAMILY\n",
      "2020 partnership tax return: 1\n",
      "partner: 1\n",
      "wife: 1\n",
      "mother: 1\n",
      "the resident parent: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "the coronavirus act: 1\n",
      "covid19: 1\n",
      "covid-19 free: 1\n",
      "covid -19: 1\n",
      "covid 19: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 4\n",
      "a home shop: 1\n",
      "the house: 1\n",
      "---\n",
      "DATA\n",
      "the stats: 1\n",
      "the daily stats: 1\n",
      "the news station: 1\n",
      "this pandemic situation: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 1\n",
      "children: 1\n",
      "child maintenance: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "an isolation note: 2\n",
      "a self isolation note: 1\n",
      "---\n",
      "BENEFIT\n",
      "proof pip: 1\n",
      "the benefit: 1\n",
      "a review pip assessment: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport: 1\n",
      "a paper passport renewal application: 1\n",
      "---\n",
      "TRAVEL\n",
      "flight: 1\n",
      "travel updates: 1\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 1\n",
      "no family: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 %: 1\n",
      "furloughed: 1\n",
      "---\n",
      "VISA\n",
      "visa: 1\n",
      "visa application gwf055610021: 1\n",
      "---\n",
      "GET-MED\n",
      "prescription collecting: 1\n",
      "---\n",
      "CARER\n",
      "a carer: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "a complaint there no email address: 1\n",
      "---\n",
      "AT-RISK\n",
      "the risk: 1\n",
      "---\n",
      "PENSION\n",
      "a pension: 1\n",
      "---\n",
      "SCHOOL\n",
      "student loan: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "a idea: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "a key worker: 1\n",
      "---\n",
      "VULNERABLE\n",
      "vulnerable: 1\n",
      "---\n",
      "\n",
      "7. APPLY-SMTHG 732 36 \n",
      "======\n",
      "VULNERABLE\n",
      "a vulnerable person: 50\n",
      "extremely vulnerable person: 10\n",
      "a vulnerable elderly person: 2\n",
      "vulnerable: 2\n",
      "the vulnerable list: 2\n",
      "---\n",
      "FAMILY\n",
      "husband: 9\n",
      "father: 7\n",
      "mother: 6\n",
      "wife: 6\n",
      "parents: 4\n",
      "---\n",
      "DELIVERY\n",
      "home delivery: 10\n",
      "home deliveries: 4\n",
      "a home delivery: 2\n",
      "deliveries least 3: 1\n",
      "deliveries: 1\n",
      "---\n",
      "SUPPORT\n",
      "help: 16\n",
      "support: 3\n",
      "assistance: 2\n",
      "this income support scheme: 1\n",
      "priority: 1\n",
      "---\n",
      "INFORMATION\n",
      "nhs number: 2\n",
      "the form: 2\n",
      "insurance number: 1\n",
      "self assessment income form: 1\n",
      "updates: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "job seekers: 3\n",
      "company: 2\n",
      "jobs: 2\n",
      "employees: 2\n",
      "work: 2\n",
      "---\n",
      "BENEFIT\n",
      "universal credit: 7\n",
      "ssp: 3\n",
      "marriage allowance: 2\n",
      "esa: 2\n",
      "benefits: 2\n",
      "---\n",
      "GOODS\n",
      "line shopping: 4\n",
      "food: 2\n",
      "food parcel: 2\n",
      "food parcels: 2\n",
      "a food parcel: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "a loan: 2\n",
      "20 tax return: 1\n",
      "tax reture: 1\n",
      "the loan: 1\n",
      "budget loan: 1\n",
      "---\n",
      "LICENSE\n",
      "licence: 4\n",
      "driving licence: 2\n",
      "driving licence 3 month reduction time: 1\n",
      "a provisional license: 1\n",
      "license: 1\n",
      "---\n",
      "CHILD\n",
      "son: 2\n",
      "child benefit: 1\n",
      "sons provisional licence 3 4 weeks: 1\n",
      "daughter: 1\n",
      "daughters: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "government grant: 2\n",
      "the grant: 2\n",
      "an advanced grant: 1\n",
      "grant: 1\n",
      "some money: 1\n",
      "---\n",
      "ELDERLY\n",
      "90 year: 2\n",
      "92 year: 1\n",
      "98 year: 1\n",
      "88 year: 1\n",
      "93 year: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 % wages: 2\n",
      "the furlough scheme: 2\n",
      "80 %: 2\n",
      "80 % grant: 1\n",
      "80 % wages thanks: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "coronavirus extremely- vunerable: 1\n",
      "www.gov.uk/corona virus: 1\n",
      "a covid-19 support webinar: 1\n",
      "the covid alerts: 1\n",
      "rotavirus: 1\n",
      "---\n",
      "SCHEME\n",
      "the retention scheme: 1\n",
      "the scheme: 1\n",
      "any scheme: 1\n",
      "the new retention scheme: 1\n",
      "eu settlement scheme: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home shopping: 2\n",
      "a light home: 1\n",
      "the warm home grant: 1\n",
      "home grocery benefit: 1\n",
      "---\n",
      "DEATH\n",
      "a death: 3\n",
      "sister death: 1\n",
      "---\n",
      "DATA\n",
      "status: 3\n",
      "the settled status: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "health issues: 1\n",
      "the allied health professions: 1\n",
      "copd: 1\n",
      "with serious medical conditions: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "self employment: 2\n",
      "a self employment grant: 1\n",
      "self employment grant: 1\n",
      "---\n",
      "SCHOOL\n",
      "freedom school meals: 1\n",
      "school: 1\n",
      "student suport: 1\n",
      "---\n",
      "TRAVEL\n",
      "a flight: 1\n",
      "travel updates: 1\n",
      "an emergency travel document 7 years: 1\n",
      "---\n",
      "AT-RISK\n",
      "the high risk register: 1\n",
      "a high risk patient: 1\n",
      "at risk: 1\n",
      "---\n",
      "VISA\n",
      "visit visa: 1\n",
      "a visa: 1\n",
      "visa: 1\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSION\n",
      "pension credits: 1\n",
      "pensioners free food box: 1\n",
      "state pension: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "a vunerabje adult the 1on the letter: 1\n",
      "the sms text support service: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport: 1\n",
      "a new british passport: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "nurse: 2\n",
      "---\n",
      "NO-ONE\n",
      "no one: 1\n",
      "a complain nothing: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "self isolation: 1\n",
      "---\n",
      "DISABLED\n",
      "an elderly disabled pensioner: 1\n",
      "---\n",
      "CARER\n",
      "carers uk: 1\n",
      "---\n",
      "RULES\n",
      "2 meter rule: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 1\n",
      "---\n",
      "\n",
      "8. ACCESS-SMTHG 614 31 \n",
      "======\n",
      "INFORMATION\n",
      "information: 6\n",
      "details: 5\n",
      "the form: 5\n",
      "advice: 4\n",
      "updates: 3\n",
      "---\n",
      "DELIVERY\n",
      "a slot: 12\n",
      "a delivery slot: 6\n",
      "home delivery: 4\n",
      "food deliveries: 3\n",
      "delivery: 2\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "the tax: 4\n",
      "tax code: 3\n",
      "car insurance: 3\n",
      "tax return: 3\n",
      "car tax: 2\n",
      "---\n",
      "DATA\n",
      "progress: 3\n",
      "the situation: 2\n",
      "the progress: 2\n",
      "status: 2\n",
      "cases: 2\n",
      "---\n",
      "COVID-MENTION\n",
      "coronavirus: 3\n",
      "the virus: 3\n",
      "coronavirus statistics: 2\n",
      "covid-19: 2\n",
      "the covid: 1\n",
      "---\n",
      "GOODS\n",
      "food: 5\n",
      "food parcel: 3\n",
      "any essential groceries: 1\n",
      "the online food services: 1\n",
      "food the stores: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 2\n",
      "the job retention: 1\n",
      "the job retention scheme: 1\n",
      "work place: 1\n",
      "the governments job retention scheme: 1\n",
      "---\n",
      "PENSION\n",
      "pension status: 3\n",
      "state pension: 3\n",
      "pension: 3\n",
      "state pension date: 1\n",
      "pension benefits: 1\n",
      "---\n",
      "TRAVEL\n",
      "travel advice: 4\n",
      "the travel advice pages: 1\n",
      "5 flights: 1\n",
      "flight: 1\n",
      "travel: 1\n",
      "---\n",
      "SUPPORT\n",
      "help: 2\n",
      "gov support: 1\n",
      "the support: 1\n",
      "any financial support situation: 1\n",
      "support: 1\n",
      "---\n",
      "RULES\n",
      "the rules: 3\n",
      "restrictions: 2\n",
      "the lockdown rules: 1\n",
      "garden fire rules: 1\n",
      "exercise rules: 1\n",
      "---\n",
      "LICENSE\n",
      "renew driving license: 1\n",
      "driving licence: 1\n",
      "atv licence: 1\n",
      "licence application progress: 1\n",
      "license renewal: 1\n",
      "---\n",
      "FAMILY\n",
      "wife: 2\n",
      "ex partners car rax: 1\n",
      "father career niw: 1\n",
      "mums weekly: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "the gov.uk messages every day: 1\n",
      "date email subscriptions: 1\n",
      "a message: 1\n",
      "email: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "the lockdown: 1\n",
      "isolation note: 1\n",
      "5 weeks self isolation: 1\n",
      "---\n",
      "CHILD\n",
      "childcare account: 1\n",
      "the paye login sons company: 1\n",
      "daughter application: 1\n",
      "---\n",
      "VULNERABLE\n",
      "the vulnerable persons list: 1\n",
      "extremely vulnerable persons: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "the public health england: 1\n",
      "these conditions: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 1\n",
      "housemate: 1\n",
      "---\n",
      "BENEFIT\n",
      "pip entitlement: 1\n",
      "ssp: 1\n",
      "---\n",
      "DEATH\n",
      "deaths: 1\n",
      "death register: 1\n",
      "---\n",
      "LAID-OFF\n",
      "the furlough scheme: 1\n",
      "80 % grant: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "funds: 1\n",
      "grant: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 1\n",
      "---\n",
      "SCHEME\n",
      "rural payments agency basic payments scheme 2020: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "any way: 1\n",
      "---\n",
      "CARER\n",
      "carer: 1\n",
      "---\n",
      "VISA\n",
      "the visa: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "own with no family contact: 1\n",
      "---\n",
      "\n",
      "9. DO-SMTHNG 569 32 \n",
      "======\n",
      "INFORMATION\n",
      "nhs number: 5\n",
      "contact: 4\n",
      "list: 3\n",
      "form: 2\n",
      "the list: 2\n",
      "---\n",
      "WORK-MENTION\n",
      "job: 5\n",
      "work: 4\n",
      "employees: 3\n",
      "a good job: 2\n",
      "business: 2\n",
      "---\n",
      "GOODS\n",
      "shopping: 14\n",
      "food: 5\n",
      "food shopping: 2\n",
      "any shopping: 2\n",
      "line shopping: 2\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "car tax: 2\n",
      "a personal tax account: 1\n",
      "advances budget loan: 1\n",
      "tax assessment: 1\n",
      "tax returns: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "the specific conditions: 1\n",
      "the health executives: 1\n",
      "this horrible disease: 1\n",
      "the current health emergency: 1\n",
      "health isssues: 1\n",
      "---\n",
      "BENEFIT\n",
      "a universal credit application: 2\n",
      "a benefit claim: 2\n",
      "a universal credit claim: 2\n",
      "a new universal credit claim: 1\n",
      "the heating allowance: 1\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 6\n",
      "everything online no one: 1\n",
      "no one: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid 19: 1\n",
      "coronavirus: 1\n",
      "the virus: 1\n",
      "the cornovirus: 1\n",
      "covid-19: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "letters: 1\n",
      "the letters: 1\n",
      "a letter: 1\n",
      "this automated email: 1\n",
      "the letter gp: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 2\n",
      "children: 1\n",
      "daughters: 1\n",
      "son: 1\n",
      "sons previous emoloyer: 1\n",
      "---\n",
      "FAMILY\n",
      "mother ashes: 1\n",
      "parents: 1\n",
      "husband: 1\n",
      "dads house: 1\n",
      "at the moment: 1\n",
      "---\n",
      "DATA\n",
      "this situation: 2\n",
      "any progress: 1\n",
      "situation: 1\n",
      "the database: 1\n",
      "---\n",
      "DELIVERY\n",
      "deliveries: 2\n",
      "a tesco delivery: 1\n",
      "online shopping: 1\n",
      "---\n",
      "VULNERABLE\n",
      "the vulnerable category: 1\n",
      "the vulnerable: 1\n",
      "extremely vulnerable: 1\n",
      "severely vulnerable guideline: 1\n",
      "---\n",
      "SUPPORT\n",
      "any help: 1\n",
      "some help: 1\n",
      "help: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home work: 1\n",
      "one household member: 1\n",
      "home: 1\n",
      "---\n",
      "PASSPORT\n",
      "photo passport: 1\n",
      "uk passport: 1\n",
      "---\n",
      "GET-MED\n",
      "medicals: 2\n",
      "---\n",
      "LICENSE\n",
      "licence renewal: 1\n",
      "the license: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "14 days isolation: 1\n",
      "the lockdown: 1\n",
      "---\n",
      "AT-RISK\n",
      "the high risk categories: 1\n",
      "at risk: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no help: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no mention: 1\n",
      "---\n",
      "RULES\n",
      "the restrictions: 1\n",
      "---\n",
      "UNCERTAINTY\n",
      "any ideas: 1\n",
      "---\n",
      "PENSION\n",
      "pension: 1\n",
      "---\n",
      "SCHOOL\n",
      "school closure: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "a key worker: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "any symptoms: 1\n",
      "---\n",
      "LAID-OFF\n",
      "the furlough form: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "any money: 1\n",
      "---\n",
      "\n",
      "10. WORK-SMWHR 407 23 \n",
      "======\n",
      "HOME-MENTION\n",
      "home: 29\n",
      "a private nursing home: 1\n",
      "a nursing home: 1\n",
      "a food factory working home: 1\n",
      "a rest home: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "a company: 4\n",
      "another employer: 2\n",
      "2 jobs: 2\n",
      "the business: 2\n",
      "a small company: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid 19: 5\n",
      "the corona virus: 3\n",
      "the coronavirus: 2\n",
      "the virus: 1\n",
      "coronavirus: 1\n",
      "---\n",
      "FAMILY\n",
      "the moment: 5\n",
      "the nhs mother: 1\n",
      "mum being: 1\n",
      "wife: 1\n",
      "3 weeks partner dosnt: 1\n",
      "---\n",
      "CARER\n",
      "a care home: 6\n",
      "the care home: 1\n",
      "a carer: 1\n",
      "a community carer: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "tax: 3\n",
      "tax credits: 2\n",
      "the airport feeling: 1\n",
      "tax credit: 1\n",
      "tax deductions: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "the private healthcare organisations: 1\n",
      "health know: 1\n",
      "healthcare: 1\n",
      "health: 1\n",
      "a health: 1\n",
      "---\n",
      "GOODS\n",
      "a food distribution centre: 1\n",
      "food retail: 1\n",
      "24/7 food production site: 1\n",
      "food factory(ready meals: 1\n",
      "food factory: 1\n",
      "---\n",
      "SCHOOL\n",
      "school: 2\n",
      "different school 1: 1\n",
      "2 schools: 1\n",
      "the second school: 1\n",
      "---\n",
      "SUPPORT\n",
      "choice support: 1\n",
      "a support worker: 1\n",
      "a barmaid: 1\n",
      "supermarket support: 1\n",
      "help: 1\n",
      "---\n",
      "INFORMATION\n",
      "number: 1\n",
      "id number: 1\n",
      "details: 1\n",
      "the fco any advice: 1\n",
      "for any advice: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "lockdown: 1\n",
      "the lockdown: 1\n",
      "this lockdown: 1\n",
      "isolation: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "notice period: 2\n",
      "---\n",
      "AT-RISK\n",
      "a high risk job: 1\n",
      "---\n",
      "RULES\n",
      "rules: 1\n",
      "---\n",
      "DATA\n",
      "a newspaper: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "grant scheme: 1\n",
      "---\n",
      "LAID-OFF\n",
      "furlough: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "a nurse: 1\n",
      "---\n",
      "NO-ONE\n",
      "nothing: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable elderly person: 1\n",
      "---\n",
      "\n",
      "11. CHANGE-SMTHG 396 19 \n",
      "======\n",
      "LICENSE\n",
      "licence: 36\n",
      "driving licence: 26\n",
      "license: 11\n",
      "driving license: 8\n",
      "hgv licence: 5\n",
      "---\n",
      "INFORMATION\n",
      "address: 37\n",
      "the address: 5\n",
      "bank details: 5\n",
      "email address: 3\n",
      "details: 3\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "car tax: 12\n",
      "tax: 6\n",
      "vehicle tax: 4\n",
      "tax code: 3\n",
      "vehicle road tax: 2\n",
      "---\n",
      "WORK-MENTION\n",
      "jobs: 7\n",
      "job: 1\n",
      "employer: 1\n",
      "job search: 1\n",
      "employers: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport: 4\n",
      "a uk passport: 1\n",
      "a passport: 1\n",
      "brand new passport: 1\n",
      "the passport: 1\n",
      "---\n",
      "FAMILY\n",
      "fathers blue badge: 1\n",
      "the way grandmother: 1\n",
      "husbands: 1\n",
      "the name husband: 1\n",
      "---\n",
      "BENEFIT\n",
      "marriage allowance: 2\n",
      "tax free allowance: 1\n",
      "---\n",
      "DATA\n",
      "status: 2\n",
      "ref the corona situation: 1\n",
      "---\n",
      "CHILD\n",
      "son undergraduate student loan: 1\n",
      "child maintenance: 1\n",
      "child services: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid-19: 2\n",
      "coronavirus: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "country alert emails: 1\n",
      "e - mail: 1\n",
      "---\n",
      "DELIVERY\n",
      "delivery: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "passport that day issues: 1\n",
      "---\n",
      "SUPPORT\n",
      "hearing aid batteries: 1\n",
      "---\n",
      "TRAVEL\n",
      "travel advice: 1\n",
      "---\n",
      "DEATH\n",
      "the death: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no phone number: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "self employed: 1\n",
      "---\n",
      "\n",
      "12. PAY-SMTHG 347 21 \n",
      "======\n",
      "BILLS-TO-PAY\n",
      "rent: 24\n",
      "tax: 20\n",
      "bills: 17\n",
      "car tax: 10\n",
      "road tax: 9\n",
      "---\n",
      "WORK-MENTION\n",
      "business rates: 4\n",
      "employees: 2\n",
      "the rent company: 1\n",
      "agency workers: 1\n",
      "jobworths: 1\n",
      "---\n",
      "CHILD\n",
      "child maintenance: 2\n",
      "daughter: 1\n",
      "child minder: 1\n",
      "daughters settlement visa: 1\n",
      "a child: 1\n",
      "---\n",
      "LAID-OFF\n",
      "80 %: 2\n",
      "others 80 %: 1\n",
      "80 % salary: 1\n",
      "the furlough: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "any money: 3\n",
      "money: 1\n",
      "income tax refund: 1\n",
      "---\n",
      "BENEFIT\n",
      "ssp: 4\n",
      "the benefit: 1\n",
      "---\n",
      "SUPPORT\n",
      "child support agency: 1\n",
      "the state aid support package: 1\n",
      "help: 1\n",
      "---\n",
      "PENSION\n",
      "people pensions: 1\n",
      "pensions: 1\n",
      "tax nhs pension: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "corona virus: 1\n",
      "covid19 problem: 1\n",
      "80 % covid19 retention scheme: 1\n",
      "---\n",
      "PASSPORT\n",
      "the new passport: 1\n",
      "for passport: 1\n",
      "---\n",
      "SCHOOL\n",
      "student loan: 2\n",
      "---\n",
      "HOME-MENTION\n",
      "household bills: 1\n",
      "---\n",
      "LICENSE\n",
      "road fund licence: 1\n",
      "---\n",
      "INFORMATION\n",
      "e - mail contact: 1\n",
      "---\n",
      "FAMILY\n",
      "mothers pension: 1\n",
      "---\n",
      "VISA\n",
      "the visa: 1\n",
      "---\n",
      "NO-INCOME\n",
      "no income.also food: 1\n",
      "---\n",
      "SCHEME\n",
      "the paye scheme: 1\n",
      "---\n",
      "TRAVEL\n",
      "flights: 1\n",
      "---\n",
      "GOODS\n",
      "food utility bills: 1\n",
      "---\n",
      "\n",
      "13. LIVING 331 23 \n",
      "======\n",
      "HOME-MENTION\n",
      "home: 61\n",
      "house: 2\n",
      "the same home: 1\n",
      "the same house: 1\n",
      "a different house: 1\n",
      "---\n",
      "FAMILY\n",
      "a mother: 1\n",
      "parents: 1\n",
      "husband: 1\n",
      "mum: 1\n",
      "parent: 1\n",
      "---\n",
      "INFORMATION\n",
      "contact: 2\n",
      "home advice: 1\n",
      "spain list: 1\n",
      "address: 1\n",
      "the wrong address: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "work: 10\n",
      "---\n",
      "GOODS\n",
      "food: 2\n",
      "any shopping 🛒: 1\n",
      "any shopping: 1\n",
      "any food: 1\n",
      "emergency food package: 1\n",
      "---\n",
      "NO-ONE\n",
      "no family: 2\n",
      "nothing: 1\n",
      "alone with no one: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable person: 3\n",
      "---\n",
      "ELDERLY\n",
      "85 year: 1\n",
      "78 year: 1\n",
      "93 year: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "asthma: 1\n",
      "no underlying health problems: 1\n",
      "health reasons: 1\n",
      "---\n",
      "GET-MED\n",
      "medication: 1\n",
      "meds: 1\n",
      "husbands prescription: 1\n",
      "---\n",
      "DELIVERY\n",
      "slot: 1\n",
      "slots: 1\n",
      "---\n",
      "SUPPORT\n",
      "some support thk: 1\n",
      "any support: 1\n",
      "---\n",
      "BENEFIT\n",
      "ssp: 2\n",
      "---\n",
      "UNCERTAINTY\n",
      "a way: 1\n",
      "---\n",
      "AT-RISK\n",
      "a high risk person: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "dad not a key worker: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "BILLS-TO-PAY\n",
      "feet: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "no funds: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "letter: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "isolation: 1\n",
      "---\n",
      "SCHOOL\n",
      "all students: 1\n",
      "---\n",
      "\n",
      "14. CONTACT-SMTHG 237 18 \n",
      "======\n",
      "WORK-MENTION\n",
      "employer: 3\n",
      "work: 2\n",
      "a company: 1\n",
      "business open: 1\n",
      "the jobcentre: 1\n",
      "---\n",
      "DEATH\n",
      "a death: 5\n",
      "the death: 2\n",
      "a death bereavement: 1\n",
      "death: 1\n",
      "---\n",
      "CHILD\n",
      "son: 2\n",
      "child maintenance: 2\n",
      "the child maintenance service: 1\n",
      "child benefit department: 1\n",
      "---\n",
      "FAMILY\n",
      "fathers deah: 1\n",
      "mum death: 1\n",
      "the other parent: 1\n",
      "a parent: 1\n",
      "a change mothers circumstances: 1\n",
      "---\n",
      "INFORMATION\n",
      "the telephone number: 1\n",
      "the contact centres: 1\n",
      "a change details: 1\n",
      "new e - mail address:-: 1\n",
      "details: 1\n",
      "---\n",
      "BENEFIT\n",
      "maternity allowance: 1\n",
      "the esa team: 1\n",
      "esa a few weeks: 1\n",
      "universal credit: 1\n",
      "the pip service: 1\n",
      "---\n",
      "DATA\n",
      "mse news department: 1\n",
      "the situation: 1\n",
      "cases: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "hmrc email scam: 1\n",
      "a tv scam email: 1\n",
      "email: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid19 lockdown breach: 1\n",
      "covid 19: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "a medical condition: 1\n",
      "an issue: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "the tax office: 1\n",
      "the tax: 1\n",
      "---\n",
      "SCHOOL\n",
      "student finance wales: 1\n",
      "school 4 times: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home office: 1\n",
      "the home office: 1\n",
      "---\n",
      "SYMPTOMS\n",
      "symptoms: 1\n",
      "---\n",
      "LICENSE\n",
      "driving licence: 1\n",
      "---\n",
      "GET-MED\n",
      "medical practice: 1\n",
      "---\n",
      "PASSPORT\n",
      "passport: 1\n",
      "---\n",
      "\n",
      "15. GO-SMWHR 223 21 \n",
      "======\n",
      "WORK-MENTION\n",
      "work: 41\n",
      "job centre: 1\n",
      "another employer: 1\n",
      "any officine job center: 1\n",
      "work place: 1\n",
      "---\n",
      "GOODS\n",
      "shopping: 7\n",
      "food: 5\n",
      "food shopping: 2\n",
      "foodstuffs: 1\n",
      "---\n",
      "FAMILY\n",
      "dads: 2\n",
      "girlfriends family house: 1\n",
      "family members: 1\n",
      "shopping husband: 1\n",
      "girlfriends dads house: 1\n",
      "---\n",
      "INFORMATION\n",
      "the link: 3\n",
      "a secure link: 1\n",
      "number: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid 19: 2\n",
      "the corona virus restrictions: 1\n",
      "the corona virus: 1\n",
      "work covid 19: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "clients house: 1\n",
      "house: 1\n",
      "of your house: 1\n",
      "---\n",
      "SUPPORT\n",
      "the accessibility: 1\n",
      "help: 1\n",
      "some help: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable list: 1\n",
      "a vulnerable person: 1\n",
      "extremely vulnerable list: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "text: 1\n",
      "a letter: 1\n",
      "the letter: 1\n",
      "---\n",
      "SCHOOL\n",
      "school: 2\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "insurance incase: 1\n",
      "debt: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "lockdown: 1\n",
      "isolation: 1\n",
      "---\n",
      "WORK\n",
      "work invade: 1\n",
      "---\n",
      "LAID-OFF\n",
      "the furlough job retention scheme: 1\n",
      "---\n",
      "DATA\n",
      "this situation: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "the asthma page: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "the contribution key workers: 1\n",
      "---\n",
      "CARER\n",
      "a care home: 1\n",
      "---\n",
      "AT-RISK\n",
      "at risk: 1\n",
      "---\n",
      "\n",
      "16. HELP 155 26 \n",
      "======\n",
      "CHILD\n",
      "daughter: 1\n",
      "children free school: 1\n",
      "sons application: 1\n",
      "daughter application: 1\n",
      "daughter student loan application: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 3\n",
      "family: 3\n",
      "mother: 1\n",
      "dad: 1\n",
      "wife: 1\n",
      "---\n",
      "GOODS\n",
      "shopping: 6\n",
      "food shoppin: 1\n",
      "a food parcel: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "employees: 2\n",
      "company owners: 1\n",
      "business: 1\n",
      "the brunei workforce: 1\n",
      "company car allowance: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "bills: 2\n",
      "rent: 1\n",
      "tax services: 1\n",
      "the current status: 1\n",
      "the annual tax return line two years: 1\n",
      "---\n",
      "VULNERABLE\n",
      "a vulnerable person: 1\n",
      "the vulnerable: 1\n",
      "the vulnerable communities: 1\n",
      "the vulnerable people letter: 1\n",
      "the vulnerable people: 1\n",
      "---\n",
      "INFORMATION\n",
      "advice: 1\n",
      "the form: 1\n",
      "the government information: 1\n",
      "number: 1\n",
      "---\n",
      "SCHOOL\n",
      "students: 2\n",
      "a student finance application: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "home: 2\n",
      "the house: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "covid: 1\n",
      "the coronavirus: 1\n",
      "the corona virus: 1\n",
      "---\n",
      "ELDERLY\n",
      "89 year: 1\n",
      "86 year: 1\n",
      "---\n",
      "BENEFIT\n",
      "esa: 1\n",
      "benefit: 1\n",
      "---\n",
      "SCHEME\n",
      "scheme: 1\n",
      "this scheme: 1\n",
      "---\n",
      "HEALTH-PROBLEM\n",
      "illnesses: 1\n",
      "illness manageable: 1\n",
      "---\n",
      "NO-SUPPORT\n",
      "no web site no help: 1\n",
      "---\n",
      "DISABLED\n",
      "a disabled friend: 1\n",
      "---\n",
      "GIVEN-MONEY\n",
      "money: 1\n",
      "---\n",
      "NO-ONE\n",
      "money nothing: 1\n",
      "---\n",
      "DELIVERY\n",
      "food deliveries: 1\n",
      "---\n",
      "DATA\n",
      "statistics: 1\n",
      "---\n",
      "PENSION\n",
      "pension: 1\n",
      "---\n",
      "SELF-EMPLOY\n",
      "self employment payments: 1\n",
      "---\n",
      "SELF-ISOLATION\n",
      "self isolated problems: 1\n",
      "---\n",
      "TRAVEL\n",
      "travel: 1\n",
      "---\n",
      "KEY-WORKER\n",
      "keyworkers: 1\n",
      "---\n",
      "\n",
      "17. GIVE-SMTHNG 95 12 \n",
      "======\n",
      "INFORMATION\n",
      "details: 6\n",
      "information: 4\n",
      "a link: 2\n",
      "any relevant information: 1\n",
      "shielding advice: 1\n",
      "---\n",
      "SUPPORT\n",
      "support: 2\n",
      "priority: 1\n",
      "access: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "the job: 1\n",
      "employer: 1\n",
      "work: 1\n",
      "---\n",
      "CORRESPONDENCE\n",
      "notice: 2\n",
      "---\n",
      "GOODS\n",
      "the public food service: 1\n",
      "shopping: 1\n",
      "---\n",
      "NO-INFORMATION\n",
      "no information: 1\n",
      "no guidance: 1\n",
      "---\n",
      "BILLS-TO-PAY\n",
      "the current crisis: 1\n",
      "feedback: 1\n",
      "---\n",
      "FAMILY\n",
      "husband: 1\n",
      "the moment: 1\n",
      "---\n",
      "CHILD\n",
      "hours childcare: 1\n",
      "---\n",
      "DELIVERY\n",
      "delivery slots: 1\n",
      "---\n",
      "PASSPORT\n",
      "the passport office reference: 1\n",
      "---\n",
      "\n",
      "18. TRAVEL 54 12 \n",
      "======\n",
      "INFORMATION\n",
      "update: 2\n",
      "info: 1\n",
      "---\n",
      "SUPPORT\n",
      "assistance: 1\n",
      "maidstone: 1\n",
      "---\n",
      "HOME-MENTION\n",
      "house: 1\n",
      "a homes: 1\n",
      "---\n",
      "FAMILY\n",
      "documents mothers funeral: 1\n",
      "---\n",
      "WORK-MENTION\n",
      "company: 1\n",
      "---\n",
      "COVID-MENTION\n",
      "the coronavirus pandemic: 1\n",
      "---\n",
      "RULES\n",
      "the cv19 restrictions: 1\n",
      "---\n",
      "PENSION\n",
      "pension: 1\n",
      "---\n",
      "PASSPORT\n",
      "nz passport: 1\n",
      "---\n",
      "CHILD\n",
      "daughter: 1\n",
      "---\n",
      "SCHOOL\n",
      "school holiday period: 1\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (key,value) in enumerate(sorted([(k,v) for k,v in verb_argument_themes.items() if k != \"UNKNOWN\"],\n",
    "                                       key = lambda x: sum([sum(counter.values()) for counter in x[1].values()]),\n",
    "                                      reverse=True),1):\n",
    "\n",
    "    print(f\"{i}. {key} {sum([sum(counter.values()) for counter in value.values()])} {len(value)} \\n======\")\n",
    "    for j, (argument, counter) in enumerate(sorted([(k,v) for k,v in value.items() if k != \"UNKNOWN\"],\n",
    "                                                   key = lambda x: sum(x[1].values()),\n",
    "                                                   reverse=True\n",
    "                                                  )\n",
    "                                            , 1):\n",
    "\n",
    "        print(f\"{argument}\")\n",
    "        for l, (arg_theme, vals) in enumerate(counter.most_common(5)):\n",
    "            print(f\"{arg_theme}: {vals}\")\n",
    "        print(\"---\")\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign themes to actions and things people are talking about \n",
    "### Tag response comments (Q3) with appropriate themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b1ab28f2ce46c3b21ff0b433013091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "phrase_mentions = []\n",
    "for vals in tqdm_notebook(df.pos_tag.values):\n",
    "    sents = extract_phrase(vals, True)\n",
    "    phrase_mentions.append([])\n",
    "    for combo in compute_combinations(sents, 2):\n",
    "        key = (combo[0].label, combo[1].label)\n",
    "        arg1 = combo[0].text.lower()\n",
    "        arg2 = combo[1].text.lower()\n",
    "        \n",
    "        if key in [('verb', 'noun'), ('verb', 'prep_noun'), \n",
    "                   ('verb', 'noun_verb'), ('noun','prep_noun'),\n",
    "                  ('prep_noun','noun'), ('prep_noun','prep_noun')]:\n",
    "            mention_theme = f\"{regex_group_verbs(arg1)} - {regex_for_theme(arg2)}\"\n",
    "            \n",
    "            arg1 = re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", arg1)\n",
    "            arg2 = re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", arg2)\n",
    "            phrase = f\"{arg1} {arg2}\"\n",
    "            phrase_mentions[-1].append((key, phrase, mention_theme, (arg1,arg2)))\n",
    "            \n",
    "df['theme_mentions'] = phrase_mentions       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prep_noun', 'noun'),\n",
       "  'for 2017 tax year',\n",
       "  'unknown - unknown',\n",
       "  ('for 2017 tax', 'year')),\n",
       " (('verb', 'noun'),\n",
       "  'are taking the michael',\n",
       "  'others-situation - unknown',\n",
       "  ('are taking', 'the michael'))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['theme_mentions'].str.len()>0].iloc[100].theme_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['theme_mentions_list'] = df['theme_mentions'].map(lambda x: [mention for key,_,mention,_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_group(arg1, arg2):\n",
    "    if re.search(r\"((('|’|^(a)?)m)|(have been)|(feel))$\", arg1):\n",
    "        return re.sub(r\"^((the)|a)\\s\",\"\", arg2)\n",
    "    return \"\"\n",
    "\n",
    "def resolve_function(x):\n",
    "    res = [get_user_group(*args) for theme,_,_,args in x if \"verb\" in theme[0]]\n",
    "    return [r for r in res if r != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key-worker']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [[('verb', 'noun'),None,None,('feel', 'the key-worker')]]\n",
    "resolve_function(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['theme_mentions_user'] = df['theme_mentions'].map(resolve_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('self employed', 64),\n",
       "  ('self isolating', 49),\n",
       "  ('key worker', 23),\n",
       "  ('vulnerable person', 18),\n",
       "  ('carer', 10),\n",
       "  ('77 years', 7),\n",
       "  ('73 years', 7),\n",
       "  ('director', 6),\n",
       "  ('81 years', 5),\n",
       "  ('self - employed', 5)],\n",
       " True,\n",
       " 383)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_groups = Counter()\n",
    "for vals in df[df['theme_mentions_user'].str.len()>0].theme_mentions_user.values:\n",
    "    for val in vals:\n",
    "        user_groups[val] +=1\n",
    "user_groups.most_common(10), \"housebound\" in user_groups, len(user_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'told register as a vulnerable person': 'told to register as a vulnerable person'}\n",
      "{'housebound': 'housebound'}\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "from difflib import SequenceMatcher as SM\n",
    "from nltk.util import ngrams\n",
    "import codecs\n",
    "\n",
    "needle = \"told register as a vulnerable person\"\n",
    "hay    = \"told to register as a vulnerable person for delivery service for on line shopping\"\n",
    "\n",
    "def find_needle(needle, hay):\n",
    "    needle_length  = len(needle.split())\n",
    "    max_sim_val    = 0\n",
    "    max_sim_string = u\"\"\n",
    "#     print(needle)\n",
    "    for ngram in ngrams(hay.split(), needle_length + int(.65*needle_length)):\n",
    "        hay_ngram = u\" \".join(ngram)\n",
    "        similarity = SM(None, hay_ngram, needle).ratio() \n",
    "        if similarity > max_sim_val:\n",
    "            max_sim_val = similarity\n",
    "            max_sim_string = hay_ngram\n",
    "    \n",
    "    if max_sim_string == \"\":\n",
    "        max_sim_string = hay\n",
    "\n",
    "    tokens = needle.split(\" \")\n",
    "    if len(tokens) == 1:\n",
    "        expression = tokens[0]\n",
    "    else:\n",
    "        expression = f\"({tokens[0]}).*({tokens[-1]})\"\n",
    "    result = regex.search(expression, max_sim_string)\n",
    "    \n",
    "    if result is not None:\n",
    "        pattern = result.group()\n",
    "        \n",
    "        return {needle: pattern}\n",
    "    return {needle:None}\n",
    "\n",
    "print(find_needle(needle, hay))\n",
    "print(find_needle(\"housebound\", \"i am housebound\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([(('verb', 'noun'), 'trying to get an update', 'acquire-smthg - unknown', ('trying to get', 'an update')), (('verb', 'noun'), 'for driving lorry license', 'unknown - license', ('for driving', 'lorry license')), (('noun', 'prep_noun'), 'lorry license after illness', 'unknown - health-problem', ('lorry license', 'after illness')), (('prep_noun', 'prep_noun'), 'after illness at christmas', 'unknown - unknown', ('after illness', 'at christmas')), (('verb', 'noun'), 'needing to get back to work', 'acquire-smthg - work-mention', ('needing to get back to', 'work')), (('noun', 'prep_noun'), 'work as hgv', 'work-smwhr - unknown', ('work', 'as hgv')), (('prep_noun', 'noun'), 'as hgv key worker driver', 'unknown - key-worker', ('as hgv', 'key worker driver'))]),\n",
       "       'Trying to get an up[date from medical/re application for driving/lorry license after illness at Christmas 2019.  Needing to get back to work as HGV key worker/driver.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['theme_mentions', \"Q3_pii_removed\"]].iloc[142].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10506/10506 [00:00<00:00, 147796.93it/s]\n",
      "100%|██████████| 10506/10506 [00:00<00:00, 137349.71it/s]\n"
     ]
    }
   ],
   "source": [
    "## remove special characters\n",
    "df[\"Q3_pii_removed\"] = df[\"Q3_pii_removed\"].replace(np.nan, '', regex=True)\n",
    "df[\"Q3_pii_removed\"] = df[\"Q3_pii_removed\"].progress_map(lambda x: ' '.join(\n",
    "                                    re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", x).split()))\n",
    "\n",
    "df[\"Q3_x_edit\"] = df[\"Q3_x\"].replace(np.nan, '', regex=True)\n",
    "df[\"Q3_x_edit\"] = df[\"Q3_x_edit\"].progress_map(lambda x: ' '.join(re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns for `phrases` and `user_groups`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([(('verb', 'noun'), 'told to register as a vulnerable person', 'apply-smthg - vulnerable', ('told to register as', 'a vulnerable person')), (('noun', 'prep_noun'), 'a vulnerable person for delivery', 'unknown - delivery', ('a vulnerable person', 'for delivery')), (('prep_noun', 'noun'), 'for delivery service', 'living - unknown', ('for delivery', 'service')), (('noun', 'prep_noun'), 'service on line', 'unknown - unknown', ('service', 'on line')), (('prep_noun', 'noun'), 'on line shopping', 'unknown - goods', ('on line', 'shopping'))]),\n",
       "       'told to register as a vulnerable person for delivery service for on line shopping'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['theme_mentions', \"Q3_x_edit\"]].iloc[6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 790/10506 [00:17<06:02, 26.77it/s] "
     ]
    }
   ],
   "source": [
    "df['phrases_dict'] = df[['theme_mentions', \"Q3_x_edit\"]][:].\\\n",
    "            progress_apply(lambda x: [find_needle(phrase, x[1].lower()) for _,phrase,_,_  in x[0]], axis=1)\n",
    "df['phrases_list'] = df['phrases_dict'].progress_map(lambda x: [value for phrase_dict in x \n",
    "                                                                 for value in phrase_dict.values() \n",
    "                                                                 if value is not None]\n",
    "                                                if not isinstance(x, float) else [])\n",
    "df['phrases'] = df['phrases_list'].progress_map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_counts = Counter()\n",
    "for phrase_list in df.phrases_list.values:\n",
    "    for phrase in phrase_list:\n",
    "        phrase_counts[phrase]+=1\n",
    "phrase_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['phrases']!=''][['phrases', 'Q3_x_edit']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_phrases_dict'] = df[['theme_mentions_user', \"Q3_x_edit\"]][:].\\\n",
    "            progress_apply(lambda x: [find_needle(phrase, x[1].lower()) for phrase  in x[0]], axis=1)\n",
    "df['user_phrases_list'] = df['user_phrases_dict'].progress_map(lambda x: [value for phrase_dict in x \n",
    "                                                                 for value in phrase_dict.values() \n",
    "                                                                 if value is not None]\n",
    "                                                if not isinstance(x, float) else [])\n",
    "\n",
    "df['user_phrases'] = df['user_phrases_list'].progress_map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = Counter()\n",
    "for vals in df[df['user_phrases_list'].str.len()>0].user_phrases_list.values:\n",
    "    for val in vals:\n",
    "        user_groups[val] +=1\n",
    "user_groups.most_common(10), \"housebound\" in user_groups, len(user_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "for phrase_list, comment in df[~df['phrases_dict'].isna()][['phrases_dict', 'Q3_x_edit']].values:\n",
    "    for phrase_dict in phrase_list:\n",
    "        for key,value in phrase_dict.items():\n",
    "            if str(value) not in comment.lower():\n",
    "                missing+=1\n",
    "missing       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results for tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[['primary_key', 'intents_clientID', 'visitId', 'fullVisitorId',\n",
    "       'hits_pagePath', 'Started', 'Ended', 'Q1_x', 'Q2_x', 'Q3_x_edit', 'Q4_x',\n",
    "       'Q5_x', 'Q6_x', 'Q7_x', 'Q8_x', 'session_id', 'dayofweek', 'isWeekend',\n",
    "       'hour', 'country', 'country_grouping', 'UK_region', 'UK_metro_area',\n",
    "       'channelGrouping', 'deviceCategory',\n",
    "       'total_seconds_in_session_across_days',\n",
    "       'total_pageviews_in_session_across_days', 'finding_count',\n",
    "       'updates_and_alerts_count', 'news_count', 'decisions_count',\n",
    "       'speeches_and_statements_count', 'transactions_count',\n",
    "       'regulation_count', 'guidance_count', 'business_support_count',\n",
    "       'policy_count', 'consultations_count', 'research_count',\n",
    "       'statistics_count', 'transparency_data_count',\n",
    "       'freedom_of_information_releases_count', 'incidents_count',\n",
    "       'done_page_flag', 'count_client_error', 'count_server_error',\n",
    "       'ga_visit_start_timestamp', 'ga_visit_end_timestamp',\n",
    "       'intents_started_date', 'events_sequence', 'search_terms_sequence',\n",
    "       'cleaned_search_terms_sequence', 'top_level_taxons_sequence',\n",
    "       'page_format_sequence', 'Sequence', 'PageSequence', 'flag_for_criteria',\n",
    "       'full_url_in_session_flag', 'UserID', 'UserNo', 'Name', 'Email',\n",
    "       'IP Address', 'Unique ID', 'Tracking Link', 'clientID', 'Page Path',\n",
    "       'Q1_y', 'Q2_y', 'Q3_y', 'Q4_y', 'Q5_y', 'Q6_y', 'Q7_y', 'Q8_y',\n",
    "       'Started_Date', 'Ended_Date', 'Started_Date_sub_12h', 'phrases', 'user_phrases']]\n",
    "\n",
    "df_sub.rename(columns={'Q3_x_edit':'Q3_x'}, inplace=True)\n",
    "df_sub.to_csv(os.path.join(DATA_DIR, 'uis_20200401_20200409_phrases_user_groups.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
