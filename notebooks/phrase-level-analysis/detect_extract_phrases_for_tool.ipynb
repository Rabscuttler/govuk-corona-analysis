{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install wordcloud\n",
    "# !pip3 install polyglot\n",
    "# !pip3 install pyicu\n",
    "# !pip3 install pycld2\n",
    "# !pip3 install morfessor\n",
    "# !pip3 install polyglot\n",
    "# !pip3 install fuzzywuzzy\n",
    "# !pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np \n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, RegexpParser, tree\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import string \n",
    "\n",
    "## https://markhneedham.com/blog/2017/11/28/python-polyglot-modulenotfounderror-no-module-named-icu/\n",
    "from polyglot.detect import Detector\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "survey_filename = os.path.join(DATA_DIR, \"uis_20200401_20200409.csv\")\n",
    "df = pd.read_csv(survey_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some row duplication present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 61064\n",
      "unique clientIds: 8030\n",
      "unique primary key: 10613\n",
      "unique session_ids: 14062\n",
      "\n",
      "(2970, 78)\n"
     ]
    }
   ],
   "source": [
    "print(f\"rows: {df.shape[0]}\\nunique clientIds: {df.intents_clientID.nunique()}\")\n",
    "print(f\"unique primary key: {df.primary_key.nunique()}\\nunique session_ids: {df.session_id.nunique()}\\n\")\n",
    "# print(df.columns)\n",
    "print(df[df.session_id.isna()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9601, 9601)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the closer these numbers are to # unique primary_key, the better\n",
    "df.Q3_y.nunique(), df.Q3_x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"primary_key\", inplace = True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for sentence tokenization, part of speech tagging, PII placeholder stripping, ngram computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\[DATE_OF_BIRTH\\\\]|\\\\[EMAIL_ADDRESS\\\\]|\\\\[PASSPORT\\\\]|\\\\[PERSON_NAME\\\\]|\\\\[PHONE_NUMBER\\\\]|\\\\[STREET_ADDRESS\\\\]|\\\\[UK_NATIONAL_INSURANCE_NUMBER\\\\]|\\\\[UK_PASSPORT\\\\]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pii_filtered = [\"DATE_OF_BIRTH\", \"EMAIL_ADDRESS\", \"PASSPORT\", \"PERSON_NAME\", \n",
    "                \"PHONE_NUMBER\", \"STREET_ADDRESS\", \"UK_NATIONAL_INSURANCE_NUMBER\", \"UK_PASSPORT\"]\n",
    "pii_regex = \"|\".join([f\"\\\\[{p}\\\\]\" for p in pii_filtered])\n",
    "pii_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation) + ['’']\n",
    "token_blacklist = stop_words + punctuation + pii_filtered\n",
    "\n",
    "def split_sentences(comment):\n",
    "    return nltk.sent_tokenize(comment)\n",
    "\n",
    "def remove_stopwords_punctation(sentences):\n",
    "    return [[(t[0], t[1], t[2]) for t in sent if t[0].lower() not in token_blacklist] for sent in sentences]\n",
    "\n",
    "def replace_pii_regex(text):\n",
    "    return re.sub(pii_regex, \"\", text)\n",
    "\n",
    "def part_of_speech_tag(comment):\n",
    "    sentences = split_sentences(comment)\n",
    "    return [[(token.text, token.tag_, token.lemma_) for token in nlp(sentence)] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('This', 'DT', 'this'),\n",
       "  ('is', 'VBZ', 'be'),\n",
       "  ('a', 'DT', 'a'),\n",
       "  ('test', 'NN', 'test'),\n",
       "  ('with', 'IN', 'with'),\n",
       "  ('punctuation', 'NN', 'punctuation'),\n",
       "  ('’', \"''\", \"'\"),\n",
       "  ('.', '.', '.')],\n",
       " [('this', 'DT', 'this'),\n",
       "  ('is', 'VBZ', 'be'),\n",
       "  ('another', 'DT', 'another'),\n",
       "  ('sentence', 'NN', 'sentence'),\n",
       "  ('.', '.', '.')]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"This is a test with punctuation’. this is another sentence.\"\n",
    "processed_t = part_of_speech_tag(t)\n",
    "processed_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect feedback language\n",
    "There is a bit of foreign language spam in some responses, detect non (primarily) english comments and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    if text!=\"-\":\n",
    "        try:\n",
    "            langs = {language.confidence:language.code for language in Detector(text, quiet=True).languages}\n",
    "            return langs[max(langs.keys())]\n",
    "        except:\n",
    "            return f\"[ERROR] {text}\"\n",
    "    return \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10613/10613 [00:00<00:00, 288121.19it/s]\n",
      "  0%|          | 0/10600 [00:00<?, ?it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "  6%|▌         | 622/10600 [00:00<00:01, 5381.22it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 16%|█▌        | 1722/10600 [00:00<00:01, 6354.21it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 26%|██▌       | 2712/10600 [00:00<00:01, 7119.08it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 35%|███▍      | 3700/10600 [00:00<00:00, 7764.39it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 43%|████▎     | 4600/10600 [00:00<00:00, 8087.70it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 53%|█████▎    | 5653/10600 [00:00<00:00, 8686.82it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 64%|██████▎   | 6732/10600 [00:00<00:00, 9225.68it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 73%|███████▎  | 7690/10600 [00:00<00:00, 9328.83it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 82%|████████▏ | 8694/10600 [00:00<00:00, 9513.44it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 94%|█████████▍| 9968/10600 [00:01<00:00, 10295.16it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "100%|██████████| 10600/10600 [00:01<00:00, 9929.10it/s]\n"
     ]
    }
   ],
   "source": [
    "df['Q3_pii_removed'] = df['Q3_x'].progress_map(replace_pii_regex)\n",
    "df = df[(df.Q3_pii_removed.str.len()<4000)]\n",
    "df['language'] = df['Q3_pii_removed'].progress_map(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique languages: 44\n",
      "English: 90.58%\n",
      "-: 8.3%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('en', 9601),\n",
       " ('-', 880),\n",
       " ('un', 23),\n",
       " ('xh', 12),\n",
       " ('da', 10),\n",
       " ('gv', 9),\n",
       " ('gd', 7),\n",
       " ('it', 5),\n",
       " ('mg', 4),\n",
       " ('pl', 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_dist = df['language'].value_counts().to_dict()\n",
    "print(f\"Number of unique languages: {len(lang_dist)}\")\n",
    "print(f\"English: {round((lang_dist['en']*100)/sum(lang_dist.values()), 2)}%\")\n",
    "print(f\"-: {round((lang_dist['-']*100)/sum(lang_dist.values()), 2)}%\")\n",
    "list(lang_dist.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_en'] = df['language'].isin([\"en\", \"un\", \"-\", \"sco\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10506, 81)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['is_en']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech tag\n",
    "Run this the first time and save, then just load df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_tag'] = df[['Q3_pii_removed', 'is_en']].progress_apply(lambda x: part_of_speech_tag(x[0]) \n",
    "                                                     if x[1] else [], axis=1)\n",
    "df['lemmas'] = df['pos_tag'].progress_map(lambda x: [token[2] for sent in x for token in sent])\n",
    "\n",
    "df['words'] = df['pos_tag'].progress_map(lambda x: [token[0] for sent in x for token in sent])\n",
    "\n",
    "df.to_csv(os.path.join(DATA_DIR, \"uis_20200401_20200409_lang_pos.csv\"), index=False)\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"uis_20200401_20200409_lang_pos.csv\"))\n",
    "df['pos_tag'] = df['pos_tag'].map(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract noun and verb phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-', ':', '-')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_of_speech_tag(df.Q3_pii_removed.iloc[0])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    cc:\n",
    "    {<CC>}\n",
    "    pronoun:\n",
    "    {<DT><IN><PRP>}\n",
    "    {<IN>?<PRP>}\n",
    "    noun_verb:\n",
    "    {<IN>?<JJ.*>*<NN.*>+<HYPH>?<VBD|VBN|VBG><NN.*>*}\n",
    "    verb:\n",
    "    {<IN|TO>*<VB.*><IN|RP|TO>?<RB|WRB|TO>*<IN|TO>*}\n",
    "    {<MD><VB.*><RB><IN>+}\n",
    "    {<WRB|WP><TO>?<VB.*>+}\n",
    "    {<TO><VB><IN>}\n",
    "    {<TO>?<VB.*><IN|RP>?<WRB|RP|WP>?<IN|TO>?<VB.*>?}\n",
    "    {<VB.*><TO><VB.*><RB>*<TO>?}\n",
    "    {<IN><EX><VB.*>}\n",
    "    {<RB><TO><VB.*>+}\n",
    "    {<TO>?<VB.*><IN|WDT|WP|RP>}\n",
    "    {<WP><VB.*>}\n",
    "    {<VB.*><RB.*>+<VB.*>*<IN|TO>?}\n",
    "    {<WDT>?<TO>?<MD|VB.*>?<RB>?<TO|IN>?<V.*>+<CC>?<V.*>*<IN|RP>?<IN>*}\n",
    "    {<MD><RB>*<VB.*>*}\n",
    "    {<VB.*><IN|TO><IN>*}\n",
    "    {<TO><VB.*><IN>*}\n",
    "    {<VB.*>}\n",
    "    prep_noun:\n",
    "    {(<CD><IN><DT>)?<IN><JJ.*>*<NN.*>}\n",
    "    {<IN><NN.*><JJ.*>?<NN.*>+}\n",
    "    {<IN><NN.*><HYPH>?<NN.*>*}\n",
    "    {<IN>+<PRP\\$>?<NN><CD>?}\n",
    "    {<IN><CD><.*>}\n",
    "    {<RB><RBS>?<CD|JJ.*>?<NN.*>+}\n",
    "    {<RP>?<IN>+<JJ.*>*<NN.*>+}\n",
    "    {<IN><DT><NN.*><JJ.*>*<NN><HYPH>?<NN>}\n",
    "    {<IN><NN.*>(<HYPH>?<NN.*>)?}\n",
    "    {<JJ.*>*<IN><DT>?<NN.*>+<CD>?<NN.*>?}\n",
    "    {<IN>+<DT>*<JJ>?<CD>?<NN.*>+<CD>?<NN.*>?}\n",
    "    noun:\n",
    "    {<CD><NN.*>}\n",
    "    {<PDT><PRP\\$><NN.*>+}\n",
    "    {<RB><DT>?<JJ.*>*<NN.*>}\n",
    "    {<DT><HYPH>?<NN.*>}\n",
    "    {<JJ.*><NN.*>*<CD>}\n",
    "    {<NN.*><CD><JJ.*>?}\n",
    "    {<JJ.*|NN.*><IN|TO><PRP>}\n",
    "    {<CD><NN.*><JJ.*>}\n",
    "    {<WRB><RB><JJ.*>*<NN.*>*}\n",
    "    {<DT><JJ.*>*<NN.*>+}\n",
    "    {<NN.*><CD>?<JJ.*>*<NN.*>*}\n",
    "    {<IN>+<CD>*<POS>*<IN>*<NN.*>}\n",
    "    {<IN><PRP\\$>?<JJ.*>*<NN.*>}\n",
    "    {<NN.*><HYPH><NN.*>}\n",
    "    {<DT>?<CD>?<JJ.*>?<CC>?<JJ.*>?<NN.*>+}\n",
    "    {<NN.*><HYPH>?<NN.*|JJ.*|VB.*>*}\n",
    "    {(<NN|NNS>|<NNP|NNPS>)<NNP|NN|NNS|NNPS>+}\n",
    "    {(<NN|NNS>+|<NNP|NNPS>+)<IN|CC>(<PRP\\$|DT><NN|NNS>+|<NNP|NNPS>+)}\n",
    "    {<JJ|RB|CD>*<NNP|NN|NNS|NNPS>+}\n",
    "    {<NNP|NN|NNS|NNPS>+}\n",
    "    {<CD><IN>?<NN.*>}\n",
    "    adjective:\n",
    "    {<RB>*<JJ.*><CD>?}\n",
    "    rb:\n",
    "    {<RB>+}\n",
    "    punct:\n",
    "    {<-RRB->|<-LRB->|<,>|<.>}\n",
    "    \"\"\"\n",
    "\n",
    "class Chunk:\n",
    "\n",
    "    def __init__(self, label, tokens, indices):\n",
    "        self.label = label\n",
    "        self.tokens = tokens\n",
    "        self.indices = indices\n",
    "        self.text = self.text()\n",
    "        self.lemma = self.lemma()\n",
    "        self.important_lemma = self.important_lemma()\n",
    "        self.important_word = self.important_word()\n",
    "\n",
    "    def text(self):\n",
    "        return \" \".join([w for w,  _ , _  in self.tokens])\n",
    "    \n",
    "    def lemma(self):\n",
    "        return \" \".join([l for _,  _ , l  in self.tokens])\n",
    "    \n",
    "    def tagable_words(self):\n",
    "        return [(w, pos) for w,  pos , _  in self.tokens if re.search(r\"(NN)|(VB)\", pos)]\n",
    "    \n",
    "    def important_word(self):\n",
    "        return \" \".join([w for w,  pos , _  in self.tokens if re.search(r\"(NN)|(VB)|(JJ)|(CD)\", pos) ])\n",
    "    \n",
    "    def important_lemma(self):\n",
    "        return \" \".join([l for _,  pos , l  in self.tokens if re.search(r\"(NN)|(VB)|(JJ)|(CD)\", pos) ])\n",
    "    \n",
    "parser = RegexpParser(grammar)\n",
    "\n",
    "def chunk_text(tagged):\n",
    "    chunks = parser.parse(tagged)\n",
    "    index = 0\n",
    "    segments = []\n",
    "    for el in chunks:\n",
    "        if type(el) == tree.Tree:\n",
    "            chunk = Chunk(el.label(), el.leaves(), list(range(index, index + len(el.leaves()))))\n",
    "            segments.append(chunk)\n",
    "            index += len(el.leaves())\n",
    "        else:\n",
    "            index += 1\n",
    "    return segments\n",
    "\n",
    "def extract_phrase(sentences, merge_inplace=False):\n",
    "    chunks = []\n",
    "    for sentence in sentences:\n",
    "        chunks.append(chunk_text(sentence))\n",
    "    if merge_inplace:\n",
    "        return [merge_adjacent_chunks(chunk) for chunk in chunks]\n",
    "    return chunks  \n",
    "\n",
    "def merge_adjacent_chunks(chunks):\n",
    "    merged = []\n",
    "    previous_label = \"\"\n",
    "    for chunk in chunks:\n",
    "        if chunk.label == previous_label and chunk.label != \"prep_noun\":\n",
    "            merged[-1] = Chunk(chunk.label, \n",
    "                               merged[-1].tokens + chunk.tokens, \n",
    "                               merged[-1].indices + chunk.indices)\n",
    "        else:\n",
    "            merged.append(chunk)\n",
    "        previous_label = chunk.label\n",
    "    return merged\n",
    "\n",
    "def compute_combinations(sentences, n):\n",
    "    return [chunks[i:i+n] for chunks in sentences for i in range(len(chunks)-(n-1))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute linguistic pattern combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linguistic_patterns(df_series, n):\n",
    "    pattern_dictionary = {}\n",
    "\n",
    "    for vals in tqdm_notebook(df_series.values):\n",
    "        sents = extract_phrase(vals, True)\n",
    "                            \n",
    "        for combo in compute_combinations(sents, n):\n",
    "            key = tuple([c.label for c in combo])\n",
    "            counter_key =  tuple([c.text.lower() for c in combo])\n",
    "            \n",
    "            if key not in pattern_dictionary.keys():\n",
    "                pattern_dictionary[key]=Counter()\n",
    "\n",
    "            pattern_dictionary[key][counter_key]+=1\n",
    "                        \n",
    "    return pattern_dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105d9f7de06e4b71bba39ca2596102eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('verb',\n",
       "  'noun'): Counter({('signed up for', 'repatriation advice'): 1,\n",
       "          ('told to register as', 'a vulnerable person'): 1,\n",
       "          ('have', 'a mother'): 1,\n",
       "          ('has', 'diabetes'): 1,\n",
       "          ('am checking on', 'daily'): 1,\n",
       "          ('taking', 'food'): 1,\n",
       "          ('go there once', 'a week'): 1,\n",
       "          ('to change', 'bedding'): 1,\n",
       "          ('is safely in', 'conservatory'): 1,\n",
       "          ('work for', 'a train company'): 1,\n",
       "          ('serve', 'drinks snacks'): 1,\n",
       "          ('to come in to clean inside', 'trains'): 1,\n",
       "          ('do n’t want to come in as caring for', 'mother'): 1,\n",
       "          ('get', 'a sick note'): 1,\n",
       "          ('do n’t want to run', 'the risk'): 1,\n",
       "          ('does survive', 'this horrible disease'): 1}),\n",
       " ('noun', 'adjective'): Counter({('repatriation advice', 'due'): 1}),\n",
       " ('adjective', 'prep_noun'): Counter({('due', 'to covid 19 outbreak'): 1}),\n",
       " ('verb',\n",
       "  'adjective'): Counter({('to register as', 'vulnerable'): 1,\n",
       "          ('is 90yrs', 'old'): 1,\n",
       "          ('lives on', 'own'): 1,\n",
       "          ('will have to go off', 'sick'): 1,\n",
       "          ('will only get', 'statutory sick'): 1,\n",
       "          ('would firstly like to send', 'best'): 1}),\n",
       " ('adjective',\n",
       "  'punct'): Counter({('vulnerable', '.'): 1,\n",
       "          ('old', ','): 1,\n",
       "          ('own', ','): 1}),\n",
       " ('noun',\n",
       "  'prep_noun'): Counter({('a vulnerable person', 'for delivery'): 1,\n",
       "          ('service', 'on line'): 1,\n",
       "          ('a mother', 'in law'): 1,\n",
       "          ('mother', 'in law'): 1,\n",
       "          ('a sick note', 'from gp'): 1,\n",
       "          ('regards', 'to boris'): 1}),\n",
       " ('prep_noun',\n",
       "  'noun'): Counter({('for delivery', 'service'): 1,\n",
       "          ('on line', 'shopping'): 1,\n",
       "          ('for self', 'isolating'): 1,\n",
       "          ('to boris', 'johnson today'): 1}),\n",
       " ('pronoun',\n",
       "  'verb'): Counter({('i', 'have'): 1,\n",
       "          ('i', 'am checking on'): 1,\n",
       "          ('i', 'go there once'): 1,\n",
       "          ('she', 'is safely in'): 1,\n",
       "          ('i', 'work for'): 1,\n",
       "          ('they', 'want'): 1,\n",
       "          ('me', 'to come in to clean inside'): 1,\n",
       "          ('i', 'have said'): 1,\n",
       "          ('that i', 'do n’t want to come in as caring for'): 1,\n",
       "          ('they', 'have told'): 1,\n",
       "          ('me that i', 'will have to go off'): 1,\n",
       "          ('i', 'will only get'): 1,\n",
       "          ('i', 'do n’t want to run'): 1,\n",
       "          ('i', 'stand'): 1,\n",
       "          ('i', 'would firstly like to send'): 1,\n",
       "          ('he', 'does survive'): 1}),\n",
       " ('prep_noun', 'verb'): Counter({('in law', 'is 90yrs'): 1}),\n",
       " ('punct',\n",
       "  'verb'): Counter({(',', 'lives on'): 1,\n",
       "          (',', 'has'): 1,\n",
       "          (',', 'taking'): 1,\n",
       "          (',', 'has been suspended now'): 1}),\n",
       " ('noun',\n",
       "  'cc'): Counter({('diabetes', 'and'): 1, ('a train company', 'but'): 1}),\n",
       " ('cc', 'noun'): Counter({('and', 'asthma'): 1, ('and', 'the stations'): 1}),\n",
       " ('noun',\n",
       "  'punct'): Counter({('asthma', ','): 1,\n",
       "          ('isolating', '.'): 1,\n",
       "          ('daily', ','): 1,\n",
       "          ('food', '.'): 1,\n",
       "          ('bedding', ','): 1,\n",
       "          ('conservatory', '.'): 1,\n",
       "          ('role', ','): 1,\n",
       "          ('drinks snacks', ','): 1,\n",
       "          ('trains', '('): 1,\n",
       "          ('the stations', '.'): 1,\n",
       "          ('pay', '!'): 1,\n",
       "          ('parent', '.'): 1,\n",
       "          ('johnson today', '...'): 1,\n",
       "          ('this horrible disease', '...'): 1}),\n",
       " ('punct', 'rb'): Counter({(',', 'so there'): 1}),\n",
       " ('rb',\n",
       "  'prep_noun'): Counter({('so there', 'for self'): 1,\n",
       "          ('not', 'in a safety'): 1}),\n",
       " ('noun',\n",
       "  'verb'): Counter({('a week', 'to change'): 1,\n",
       "          ('the public', 'are'): 1,\n",
       "          ('the risk', 'of infecting'): 1}),\n",
       " ('punct',\n",
       "  'pronoun'): Counter({(',', 'she'): 1, (',', 'i'): 1, ('...', 'i'): 1}),\n",
       " ('cc', 'rb'): Counter({('but', 'not'): 1}),\n",
       " ('prep_noun',\n",
       "  'adjective'): Counter({('in a safety', 'critical'): 1,\n",
       "          ('at risk', 'elderly'): 1}),\n",
       " ('adjective',\n",
       "  'noun'): Counter({('critical', 'role'): 1,\n",
       "          ('statutory sick', 'pay'): 1,\n",
       "          ('elderly', 'parent'): 1,\n",
       "          ('best', 'regards'): 1}),\n",
       " ('pronoun', 'rb'): Counter({('i', 'only'): 1, ('i', 'really'): 1}),\n",
       " ('rb', 'verb'): Counter({('only', 'serve'): 1, ('really', 'hope'): 1}),\n",
       " ('verb',\n",
       "  'punct'): Counter({('has been suspended now', '.'): 1,\n",
       "          ('are', ')'): 1,\n",
       "          ('stand', '?'): 1}),\n",
       " ('verb',\n",
       "  'pronoun'): Counter({('want', 'me'): 1,\n",
       "          ('have said', 'that i'): 1,\n",
       "          ('have told', 'me that i'): 1,\n",
       "          ('do', 'i'): 1,\n",
       "          ('hope', 'he'): 1}),\n",
       " ('punct', 'noun'): Counter({('(', 'the public'): 1}),\n",
       " ('punct', 'cc'): Counter({(')', 'and'): 1}),\n",
       " ('prep_noun', 'punct'): Counter({('in law', '.'): 1, ('from gp', '?'): 1}),\n",
       " ('adjective', 'cc'): Counter({('sick', 'and'): 1}),\n",
       " ('cc', 'verb'): Counter({('and', 'get'): 1}),\n",
       " ('rb', 'pronoun'): Counter({('then', 'i'): 1}),\n",
       " ('verb', 'prep_noun'): Counter({('of infecting', 'at risk'): 1})}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_linguistic_patterns(df.pos_tag[0:10], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expression matches for themes of interest.\n",
    "Focusing tagging verbs and tagging second argument component of verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_for_theme(text):\n",
    "    if re.search(r\"self\\s?(-|\\s)\\s?employ\", text.lower()):\n",
    "        return \"self-employ\"\n",
    "    if re.search(r\"(deliver(y|(ies)|(ed)))|(slot)|(online shopping)\", text.lower()):\n",
    "        return \"delivery\"\n",
    "    if re.search(r\"vulnerable\", text.lower()):\n",
    "        return \"vulnerable\"\n",
    "    if re.search(r\"disab((led)|(ility))\", text.lower()):\n",
    "        return \"disabled\"\n",
    "    if re.search(r\"no symptom\", text.lower()):\n",
    "        return \"no-symptoms\"\n",
    "    if re.search(r\"((corona)?(virus))|(covid)\", text.lower()):\n",
    "        return \"covid-mention\"\n",
    "    if re.search(r\"\"\"((health)|(heart) (problem)|(issue)|(condition)|(attack)|(disease)|(failure))|( ms)|\"\"\"+\n",
    "                 \"\"\"(copd)|(asthma)|((type)\\s?[12])|(diabet)|\"\"\"+\n",
    "                 \"\"\"(cancer)|(dementia)|(stroke)|(illness)|(a type$)|(cough)|(leukaemia)\"\"\", text.lower()):\n",
    "        return \"health-problem\"\n",
    "    if re.search(r\"symptom\", text.lower()):\n",
    "        return \"symptoms\"\n",
    "    if re.search(r\"((at)?(\\s(very\\s)?high)?\\srisk)|(risk list)\", text.lower()):\n",
    "        return \"at-risk\"\n",
    "    if re.search(r\"\"\"((((a|'|’)m( (in|at)( my)?)?)|aged) (over(-|\\s))?\"\"\"+\n",
    "                 \"\"\"(([789][0-9]($|s|\\s))|(old)|(elderly)))|((over(-|\\s))?[789][0-9] y)\"\"\", text.lower()):\n",
    "        return \"elderly\"\n",
    "    if re.search(r\"(carer)|(care home)\", text.lower()):\n",
    "        return \"carer\"\n",
    "    if re.search(r\"(key\\s?(\\s|-)?\\s?worker)|(nurse($|\\s))|(essential worker)\", text.lower()):\n",
    "        return \"key-worker\"\n",
    "    if re.search(r\"can\\s?(no|'|’)?t work\", text.lower()):\n",
    "        return \"cannot-work\"\n",
    "    if re.search(r\"no ((work)|(income)|(money)|(wage)|(salar))\", text.lower()):\n",
    "        return \"no-income\"\n",
    "    if re.search(r\"(furlough)|(fired)|(80 %)\", text.lower()):\n",
    "        return \"laid-off\"\n",
    "    if re.search(r\"\"\"(((can\\s?(no|'|’)?t (get|buy|(shop for)))|\"\"\"+\n",
    "                 \"\"\"((do not)?ha(ve|d) )(no|any|(not enough))?) (food|groceries))\"\"\", \n",
    "                 text.lower()):\n",
    "        return \"cannot-get-food\"\n",
    "    if re.search(r\"can\\s?(no|'|’)?t get ((med)|(prescription))\", text.lower()):\n",
    "        return \"cannot-get-med\"\n",
    "    if re.search(r\"(^med)|(prescription)\", text.lower()):\n",
    "        return \"get-med\"\n",
    "    if re.search(r\"(travel(\\s(advi[sc]e)|(status))?)|(flight)|(destination)\", text.lower()):\n",
    "        return \"travel\"\n",
    "    if re.search(r\"\"\"(no\\s)(\\w*\\s)?((info)|(clarification)|(advi[sc]e)|((contact )?((details)|(number)))|\"\"\"+\n",
    "                 \"\"\"(answer)|(update)|(clarity)|(guid(e|(ance)))|(list)|(definition)|\"\"\"+\n",
    "                 \"\"\"(address)|(link)|(form)|(contact)|(mention))\"\"\"\n",
    "                 , text.lower()):\n",
    "        return \"no-information\"\n",
    "    if re.search(r\"\"\"(info)|(clarification)|(advi[sc]e)|((contact )?((details)|(number)))|\"\"\"+\n",
    "                 \"\"\"(answer)|(update)|(clarity)|(guid(e|(ance)))|(list)|(definition)|\"\"\"+\n",
    "                 \"\"\"(address)|(link)|(form)|(contact)\"\"\"\n",
    "                 , text.lower()):\n",
    "        return \"information\"\n",
    "    if re.search(r\"\"\"(no)\\s((letter)|(t(e)?xt)|(message)|(e(\\s|(\\s?-\\s?))?mail)|\"\"\"+\n",
    "                 \"\"\"(alert)|(notice)|(communication))\"\"\", text.lower()):\n",
    "        return \"no-correspondence\"\n",
    "    if re.search(r\"(letter)|(t(e)?xt)|(message)|(e(\\s|(\\s?-\\s?))?mail)|(alert)|(notice)\", text.lower()):\n",
    "        return \"correspondence\"\n",
    "    if re.search(r\"(no\\s?((family)|(one)))|(nothing)|(nobody)\", text.lower()):\n",
    "        return \"no-one\"\n",
    "    if re.search(r\"no ((support)|(aid)|(help)|(assistance)|(access)|(priority))\", text.lower()):\n",
    "        return \"no-support\"\n",
    "    if re.search(r\"(support)|(aid)|(help)|(assistance)|(access)|(priority)\", text.lower()):\n",
    "        return \"support\"\n",
    "    if re.search(r\"(child)|((^|\\s)son)|(daughter)\", text.lower()):\n",
    "        return \"child\"\n",
    "    if re.search(r\"\"\"(parent)|(husband)|(wife)|(partner)|\"\"\"+\n",
    "                 \"\"\"((mo|fa)ther)|(famil(y|(ies)))|(m[uo]m)|(dad)\"\"\", text.lower()):\n",
    "        return \"family\"\n",
    "    if re.search(r\"(rule)|(restriction)|(measure)|(rights)\", text.lower()):\n",
    "        return \"rules\"\n",
    "    if re.search(r\"((no)|(a(ny)?)) ((way)|(option)|(choice)|(means)|(idea))\", text.lower()):\n",
    "        return \"uncertainty\"\n",
    "    if re.search(r\"work ((for)|(in)|(at)|(on))\", text.lower()):\n",
    "        return \"work\"\n",
    "    if re.search(r\"((self\\s|-)?isolat((ion)|(e)|(ing)))|(lock\\s?(\\s|-)?\\s?down)\", text.lower()):\n",
    "        return \"self-isolation\"\n",
    "    if re.search(r\"(driv(ing|ers)\\s)?licen[sc]e\", text.lower()):\n",
    "        return \"license\"\n",
    "    if re.search(r\"passport\", text.lower()):\n",
    "        return \"passport\"\n",
    "    if re.search(r\"pension\", text.lower()):\n",
    "        return \"pension\"\n",
    "    if re.search(r\"(^|\\s)h((ome)|(ouse))\", text.lower()):\n",
    "        return \"home-mention\"\n",
    "    if re.search(r\"(employ)|(work)|(job)|(business)|(company)\", text.lower()):\n",
    "        return \"work-mention\"\n",
    "    if re.search(r\"(benefit)|(universal credit)|(eligible)|(esa)|(ssp)|(pip)|(allowance)\", text.lower()):\n",
    "        return \"benefit\"\n",
    "    if re.search(r\"(school)|(student)\", text.lower()):\n",
    "        return \"school\"\n",
    "    if re.search(r\"(food)|(supplies)|(shopping)|(groceries)\", text.lower()):\n",
    "        return \"goods\"\n",
    "    if re.search(r\"(money)|(grant)|(fund)|(relief)\", text.lower()):\n",
    "        return \"given-money\"\n",
    "    if re.search(r\"(bill)|(tax)|(mortgage)|(rent)|(loan)|(debt)|(fine)|(fee)|(insurance)\", text.lower()):\n",
    "        return \"bills-to-pay\"\n",
    "    if re.search(r\"scheme\", text.lower()):\n",
    "        return \"scheme\"\n",
    "    if re.search(r\"(^|\\s)visa($|\\s)\", text.lower()):\n",
    "        return \"visa\"\n",
    "    if re.search(r\"(data)|(cases)|(situation)|(stat(istic)?s?$)|(status)|(news)|(progress)\", text.lower()):\n",
    "        return \"data\"\n",
    "    if re.search(r\"dea((th)|d)\", text.lower()):\n",
    "        return \"death\"\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_for_theme(\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_group_verbs(verb):\n",
    "    if re.search(r\"\"\"(f(i|(ou))nd)|(look)|(search)|(clarify)|(ask)|(read)|([ei]nquire)|\"\"\"+\n",
    "                 \"\"\"(obtain)|(seek)|(know)|((^|\\s)see($|\\s))|(understand)\"\"\", verb):\n",
    "        return \"find-smthg\"\n",
    "    if re.search(r\"(access)|(check)|(complete)|(cancel)|(book)|(confirm)\", verb):\n",
    "        return \"access-smthg\"\n",
    "    if re.search(r\"(get)|(take)|(claim)|(receive)|(sent)|(collect)\", verb):\n",
    "        return \"acquire-smthg\"\n",
    "    if re.search(r\"(renew)|(change)|(update)|(inform$)|(notify)\", verb):\n",
    "        return \"change-smthg\"\n",
    "    if re.search(r\"(appl(y|(ied)))|(register)|(qualify)|(sign)\", verb):\n",
    "        return \"apply-smthg\"\n",
    "    if re.search(r\"pa(y|(id)|(yed))\", verb):\n",
    "        return \"pay-smthg\"\n",
    "    if re.search(r\"(contact)|(report)\", verb):\n",
    "        return \"contact-smthg\"\n",
    "    if re.search(r\"(work)|(employ)\", verb):\n",
    "        return \"work-smwhr\"\n",
    "    if re.search(r\"(need)|(want)|(require)|(request)|(would like)|(order)\", verb):\n",
    "        return \"need-smthg\"\n",
    "    if re.search(r\"(have)|((a|'|’|^)m($|\\s))|(feel($|\\s))\", verb):\n",
    "        return \"my-situation\"\n",
    "    if re.search(r\"(has)|(((a|we)|'|’|^)re($|\\s))\", verb):\n",
    "        return \"others-situation\"\n",
    "    if re.search(r\"(had)|((i|'|’|^)s($|\\s))|(was)\", verb):\n",
    "        return \"unclear-situation\"\n",
    "    if re.search(r\"travel\", verb):\n",
    "        return \"travel\"\n",
    "    if re.search(r\"(liv(e|(ing)))|(stay)\", verb):\n",
    "        return \"living\"\n",
    "    if re.search(r\"(do)|(make)\", verb):\n",
    "        return \"do-smthng\"\n",
    "    if re.search(r\"go($|\\s)\", verb):\n",
    "        return \"go-smwhr\"\n",
    "    if re.search(r\"(give)|(provide)\", verb):\n",
    "        return \"give-smthng\"\n",
    "    if re.search(r\"(help)|(protect)|(support)\", verb):\n",
    "        return \"help\"\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Themetatic category for entire comment: vulnerable\n",
      "I have heard about free food parcels for the extremely-vulnerable, I have received a letter to stay in but have no idea how to request a parcel for I believe toiletries etc\n",
      "\n",
      "[[('I', 'PRP', '-PRON-'), ('have', 'VBP', 'have'), ('heard', 'VBN', 'hear'), ('about', 'IN', 'about'), ('free', 'JJ', 'free'), ('food', 'NN', 'food'), ('parcels', 'NNS', 'parcel'), ('for', 'IN', 'for'), ('the', 'DT', 'the'), ('extremely', 'RB', 'extremely'), ('-', 'HYPH', '-'), ('vulnerable', 'JJ', 'vulnerable'), (',', ',', ','), ('I', 'PRP', '-PRON-'), ('have', 'VBP', 'have'), ('received', 'VBN', 'receive'), ('a', 'DT', 'a'), ('letter', 'NN', 'letter'), ('to', 'TO', 'to'), ('stay', 'VB', 'stay'), ('in', 'RB', 'in'), ('but', 'CC', 'but'), ('have', 'VBP', 'have'), ('no', 'DT', 'no'), ('idea', 'NN', 'idea'), ('how', 'WRB', 'how'), ('to', 'TO', 'to'), ('request', 'VB', 'request'), ('a', 'DT', 'a'), ('parcel', 'NN', 'parcel'), ('for', 'IN', 'for'), ('I', 'PRP', '-PRON-'), ('believe', 'VBP', 'believe'), ('toiletries', 'NNS', 'toiletry'), ('etc', 'FW', 'etc')]]\n",
      "\n",
      "PRONOUN    I                                                        [0]\n",
      "VERB       have                                my-situation         [1]\n",
      "VERB       heard about                         unknown              [2, 3]\n",
      "ADJECTIVE  free                                                     [4]\n",
      "NOUN       food parcels                        goods                [5, 6]\n",
      "RB         extremely                                                [9]\n",
      "ADJECTIVE  vulnerable                                               [11]\n",
      "PUNCT      ,                                                        [12]\n",
      "PRONOUN    I                                                        [13]\n",
      "VERB       have                                my-situation         [14]\n",
      "VERB       received                            acquire-smthg        [15]\n",
      "NOUN       a letter                            correspondence       [16, 17]\n",
      "VERB       to stay in                          living               [18, 19, 20]\n",
      "CC         but                                                      [21]\n",
      "VERB       have                                my-situation         [22]\n",
      "NOUN       no idea                             uncertainty          [23, 24]\n",
      "VERB       to request                          need-smthg           [26, 27]\n",
      "NOUN       a parcel                            unknown              [28, 29]\n",
      "PRONOUN    for I                                                    [30, 31]\n",
      "VERB       believe                             unknown              [32]\n",
      "NOUN       toiletries                          unknown              [33]\n",
      "\n",
      "I, have\n",
      "have, heard about\n",
      "heard about, free\n",
      "free, food parcels\n",
      "food parcels, extremely\n",
      "extremely, vulnerable\n",
      "vulnerable, ,\n",
      ",, I\n",
      "I, have\n",
      "have, received\n",
      "received, a letter\n",
      "a letter, to stay in\n",
      "to stay in, but\n",
      "but, have\n",
      "have, no idea\n",
      "no idea, to request\n",
      "to request, a parcel\n",
      "a parcel, for I\n",
      "for I, believe\n",
      "believe, toiletries\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "example = df.iloc[7]\n",
    "example = df[df.Q3_x.str.contains(\"letter\")].iloc[0]\n",
    "print(f\"Themetatic category for entire comment: {regex_for_theme(example.Q3_x)}\")\n",
    "\n",
    "print(example.Q3_x)\n",
    "print()\n",
    "print(example.pos_tag)\n",
    "print()\n",
    "for sent in extract_phrase(example.pos_tag, False):\n",
    "    for chunk in sent:\n",
    "        theme = \"\"\n",
    "        if chunk.label in [\"verb\"]:\n",
    "            theme = regex_group_verbs(chunk.text.lower())\n",
    "        if chunk.label in [\"noun\", \"prep_noun\", \"noun_verb\"]:\n",
    "            theme = regex_for_theme(chunk.text.lower()) \n",
    "            \n",
    "        print(\"{0:10} {1:35} {2:20} {3}\".format(chunk.label.upper(), chunk.text, theme, chunk.indices))\n",
    "    print()\n",
    "    for combo in compute_combinations([sent], 2):\n",
    "        print(f\"{combo[0].text}, {combo[1].text}\")\n",
    "        \n",
    "#     for combo in compute_combinations([sent], 3):\n",
    "#         print(f\"{combo[0].text}, {combo[1].text}, {combo[2].text}\")\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a mother in law who is 90yrs old, lives on her own, has diabetes and asthma, \n",
    "so there for self isolating. I am checking on her daily, taking food etc. \n",
    "I go there once a week to change her bedding, which she is safely in her conservatory. \n",
    "I work for a train company but not in a safety critical role, \n",
    "I only serve drinks/snacks, which has been suspended now. \n",
    "They want me to come in to clean inside trains ( where the public are) \n",
    "and the stations. I have said that I don’t want to come in as caring for my mother in law. They have told me \n",
    "that I will have to go off sick and get a sick note from GP? \n",
    "Then I will only get statutory sick pay! I don’t want to run the risk \n",
    "of infecting my at risk elderly parent. Where do I stand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect arg1-arg2 grammatical patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Signed', 'VBN', 'sign')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pos_tag[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20e4702bd57466c9e49b40009666d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_d = compute_linguistic_patterns(df.pos_tag, 2)\n",
    "len(pattern_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_of_interest = [('verb', 'noun'),\n",
    "('noun', 'prep_noun'),\n",
    "('prep_noun', 'prep_noun'),\n",
    "('verb', 'noun_verb'),\n",
    "('verb', 'prep_noun'),\n",
    "('noun', 'noun_verb'),\n",
    "('noun_verb', 'prep_noun')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `arg1` - `arg2` co-occurrence db - couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0037cc3bf12d4077924536f3d878e2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 73 possible grammatical combos.\n",
      "('verb', 'noun') 9341\n",
      "('noun', 'punct') 4251\n",
      "('noun', 'prep_noun') 3513\n",
      "('noun', 'verb') 3435\n",
      "('verb', 'pronoun') 2649\n",
      "('verb', 'adjective') 2499\n",
      "('noun', 'cc') 2352\n",
      "('prep_noun', 'punct') 2319\n",
      "('verb', 'punct') 1780\n",
      "('prep_noun', 'noun') 1594\n",
      "('noun', 'pronoun') 1556\n",
      "('prep_noun', 'verb') 1484\n",
      "('prep_noun', 'prep_noun') 1403\n",
      "('prep_noun', 'cc') 1064\n",
      "('noun', 'rb') 1027\n"
     ]
    }
   ],
   "source": [
    "pattern_db = {}\n",
    "\n",
    "for vals in tqdm_notebook(df.pos_tag.values):\n",
    "    sents = extract_phrase(vals, True)\n",
    "    for combo in compute_combinations(sents, 2):\n",
    "        key = (combo[0].label, combo[1].label)\n",
    "        arg1 = combo[0].text.lower()\n",
    "        arg2 = combo[1].text.lower()\n",
    "#         arg2 = \" \".join([w.lower() for w,_ in combo[1].tagable_words()])\n",
    "        \n",
    "        if key not in pattern_db.keys():\n",
    "            pattern_db[key] = {}\n",
    "        if arg1 not in pattern_db[key].keys():\n",
    "            pattern_db[key][arg1] = Counter()\n",
    "            \n",
    "        pattern_db[key][arg1][arg2]+=1\n",
    "\n",
    "print(f\"There are {len(pattern_db)} possible grammatical combos.\")\n",
    "for i, (k,v) in enumerate(sorted(pattern_db.items(),\n",
    "                         key = lambda x: len(x[1].values()),\n",
    "                         reverse= True)[0:15],\n",
    "                                 1):\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of verbs currently not being captured/categorized with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 got\n",
      "2 to tax\n",
      "3 can\n",
      "4 came to\n",
      "5 having\n",
      "6 driving\n",
      "7 use\n",
      "8 regarding\n",
      "9 says\n",
      "10 say\n",
      "11 following\n",
      "12 to send\n"
     ]
    }
   ],
   "source": [
    "top_100_verbs = [key.lower() for key, value in sorted(pattern_db[('verb', 'noun')].items(), \n",
    "                         key = lambda x: sum(x[1].values()), \n",
    "                         reverse= True)[0:100]]\n",
    "counter = 0\n",
    "for verb in top_100_verbs:\n",
    "    if regex_group_verbs(verb)== \"unknown\":\n",
    "        counter+=1\n",
    "        print(counter, verb)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create co-occurrence tables for `verb_theme-verb`, `verb_theme-argument_theme`, argument_theme-argument` pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_argument_theme_dictionary(dict_new, dict_old):\n",
    "    for theme, value in dict_new.items():\n",
    "        if theme not in dict_old.keys():\n",
    "            dict_old[theme] = Counter()\n",
    "        for val,count in value.items():\n",
    "            dict_old[theme][val]+=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9341 verbs, accompanied by nouns.\n",
      "There are 358 verbs, accompanied by prep_nouns.\n"
     ]
    }
   ],
   "source": [
    "verb_themes = {}\n",
    "verb_argument_themes = {}\n",
    "argument_themes = {}\n",
    "\n",
    "verb_argument_fillers = {}\n",
    "\n",
    "for pattern in [('verb', 'noun'), ('verb', 'prep_noun')]:\n",
    "    print(f\"There are {len(pattern_db[pattern])} {pattern[0]}s, accompanied by {pattern[1]}s.\")\n",
    "    for i, (arg1, arg2) in enumerate(sorted(pattern_db[pattern].items(),\n",
    "                             key = lambda x: sum(x[1].values()),\n",
    "                             reverse= True),\n",
    "                                     1):\n",
    "        verb_theme = f\"{regex_group_verbs(arg1)}\".upper()\n",
    "\n",
    "        if verb_theme not in verb_themes.keys():\n",
    "            verb_themes[verb_theme] = Counter()\n",
    "        \n",
    "        verb_themes[verb_theme][arg1] += sum(arg2.values())  \n",
    "        \n",
    "#         print(f\"{i}. {arg1} :: {sum(arg2.values())} [{verb_theme}] \\n-----------\")\n",
    "        \n",
    "        if verb_theme not in verb_argument_themes.keys():\n",
    "            verb_argument_themes[verb_theme] = {}\n",
    "\n",
    "        local_themes = {}\n",
    "        \n",
    "        for j, (arg2_val, arg2_counts) in enumerate(arg2.items(), 1):\n",
    "            theme = f\"{regex_for_theme(arg2_val)}\".upper()\n",
    "            if theme not in local_themes.keys():\n",
    "                local_themes[theme] = Counter()\n",
    "                \n",
    "            if theme not in argument_themes.keys():   \n",
    "                argument_themes[theme] = Counter()   \n",
    "                \n",
    "            local_themes[theme][arg2_val]+=arg2_counts   \n",
    "            argument_themes[theme][arg2_val]+=arg2_counts  \n",
    "            \n",
    "            verb_argument_theme = (verb_theme, theme)\n",
    "            \n",
    "            if verb_argument_theme not in verb_argument_fillers.keys():\n",
    "                verb_argument_fillers[verb_argument_theme] = {}\n",
    "                \n",
    "            if arg1 not in verb_argument_fillers[verb_argument_theme].keys():\n",
    "                verb_argument_fillers[verb_argument_theme][arg1] = Counter() \n",
    "                \n",
    "            verb_argument_fillers[verb_argument_theme][arg1][arg2_val] += arg2_counts\n",
    "            \n",
    "            \n",
    "        update_argument_theme_dictionary(local_themes, verb_argument_themes[verb_theme])\n",
    "        \n",
    "#         for l, (key,value) in enumerate(sorted(local_themes.items(),\n",
    "#                              key = lambda x: sum(x[1].values()),\n",
    "#                              reverse= True)[0:10],\n",
    "#                                      1):\n",
    "#             print(f\"{l}. {key}:: {sum(value.values())}\")\n",
    "#             for argument, count in value.most_common(5):\n",
    "#                 print(f\"{argument}: {count}\")\n",
    "#             print(\"\")\n",
    "#         print(\"=======\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 19)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(argument_themes), len(verb_themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MY-SITUATION', 'FAMILY') 52\n",
      "('MY-SITUATION', 'HEALTH-PROBLEM') 272\n",
      "('MY-SITUATION', 'INFORMATION') 136\n",
      "('MY-SITUATION', 'UNCERTAINTY') 30\n",
      "('MY-SITUATION', 'NO-INCOME') 46\n",
      "('MY-SITUATION', 'NO-ONE') 60\n",
      "('MY-SITUATION', 'CARER') 19\n",
      "('MY-SITUATION', 'CORRESPONDENCE') 93\n",
      "('MY-SITUATION', 'TRAVEL') 9\n",
      "('MY-SITUATION', 'UNKNOWN') 1569\n"
     ]
    }
   ],
   "source": [
    "for key, value in list(verb_argument_fillers.items())[0:10]:\n",
    "    print(key, sum([vs for v in value.values() for vs in v.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with 20 most frequently occurring generic phrases and their components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FIND-SMTHG', 'INFORMATION') 616\n",
      "verbs:\n",
      " ['to find : 109', 'looking for : 80', 'was looking for : 39', 'can not find : 29', 'to find out : 24', 'to look for : 22', 'find : 18', \"ca n't find : 13\", 'trying to find : 13', 'am looking for : 11']\n",
      "arguments:\n",
      " ['information : 121', 'advice : 63', 'any information : 24', 'guidance : 24', 'info : 20', 'an answer : 13', 'details : 13', 'an email address : 12', 'a link : 9', 'the form : 9']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'DELIVERY') 325\n",
      "verbs:\n",
      " ['to get : 88', 'can not get : 52', 'get : 29', 'can get : 26', \"ca n't get : 15\", 'ca n’t get : 14', 'could get : 6', 'ca nt get : 5', 'in getting : 4', 'trying to get : 3']\n",
      "arguments:\n",
      " ['a slot : 39', 'a delivery slot : 34', 'a delivery : 21', 'home delivery : 13', 'deliveries : 10', 'a home delivery : 9', 'delivery slots : 8', 'a food delivery : 8', 'food deliveries : 8', 'home deliveries : 7']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'CORRESPONDENCE') 298\n",
      "verbs:\n",
      " ['received : 86', 'have not received : 38', 'have received : 33', 'was sent : 11', 'has not received : 9', 'get : 7', 'sent : 7', 'have n’t received : 6', 'has received : 6', 'to get : 5']\n",
      "arguments:\n",
      " ['a letter : 122', 'letter : 24', 'an email : 22', 'a text : 13', 'the letter : 11', 'a message : 6', 'a shielding letter : 5', 'emails : 5', 'email : 4', 'a government letter : 4']\n",
      "====\n",
      "('MY-SITUATION', 'HEALTH-PROBLEM') 272\n",
      "verbs:\n",
      " ['have : 179', 'am : 18', 'have underlying : 17', 'do not have : 5', 'have got : 4', 'have had : 3', 'am over : 3', 'am on : 2', 'do have : 2', 'do not have underlying : 2']\n",
      "arguments:\n",
      " ['copd : 42', 'asthma : 20', 'diabetes : 15', 'cancer : 11', 'health problems : 11', 'heart failure : 9', 'health issues : 6', 'health conditions : 6', 'type 2 diabetes : 5', 'a medical condition : 5']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'SUPPORT') 220\n",
      "verbs:\n",
      " ['to get : 59', 'get : 32', 'can get : 29', 'can not get : 9', 'could get : 7', \"ca n't get : 3\", 'trying to get : 3', 'getting : 3', 'am trying to get : 3', 'would get : 3']\n",
      "arguments:\n",
      " ['help : 105', 'any help : 20', 'support : 13', 'priority : 12', 'access : 9', 'some help : 8', 'assistance : 7', 'any support : 3', 'the help : 2', 'help shopping : 2']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'INFORMATION') 204\n",
      "verbs:\n",
      " ['to get : 60', 'get : 9', 'received : 9', 'sent : 8', 'to get on : 8', 'trying to get : 7', 'can not get : 6', \"ca n't get : 5\", 'can get : 3', \"have n't received : 3\"]\n",
      "arguments:\n",
      " ['information : 31', 'an answer : 11', 'advice : 10', 'the list : 8', 'contact : 8', 'some information : 7', 'updates : 6', 'info : 6', 'answers : 4', 'clarity : 4']\n",
      "====\n",
      "('NEED-SMTHG', 'INFORMATION') 166\n",
      "verbs:\n",
      " ['need : 58', 'wanted : 32', 'needed : 12', 'want : 9', 'would like : 5', 'needs : 2', 'require : 2', 'to request : 2', 'required : 2', 'want to keep : 2']\n",
      "arguments:\n",
      " ['information : 19', 'advice : 17', 'info : 7', 'guidance : 6', 'clarification : 5', 'clarity : 4', 'details : 4', 'a form : 4', 'a telephone number : 3', 'some advice : 3']\n",
      "====\n",
      "('FIND-SMTHG', 'SUPPORT') 162\n",
      "verbs:\n",
      " ['looking for : 17', 'to see : 16', 'to find : 14', 'to find out : 12', 'to look for : 7', 'was looking for : 5', 'to find out about : 4', 'to ask for : 4', 'can not find : 3', 'to obtain : 2']\n",
      "arguments:\n",
      " ['help : 81', 'support : 18', 'any help : 11', 'assistance : 8', 'some help : 6', 'access : 3', 'the financial support : 2', 'the help : 2', 'priority : 2', 'help onbenefits : 1']\n",
      "====\n",
      "('PAY-SMTHG', 'BILLS-TO-PAY') 157\n",
      "verbs:\n",
      " ['to pay : 31', 'pay : 24', 'paid : 7', 'to pay for : 4', 'pays : 4', 'have paid : 4', 'need to pay : 4', 'trying to pay : 3', 'ca n’t pay : 3', 'can pay : 3']\n",
      "arguments:\n",
      " ['rent : 24', 'tax : 20', 'bills : 17', 'car tax : 10', 'road tax : 9', 'council tax : 7', 'the tax : 6', 'taxes : 6', 'vehicle tax : 4', 'the bills : 4']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'GOODS') 149\n",
      "verbs:\n",
      " ['to get : 33', 'get : 17', 'can get : 8', 'can not get : 7', 'have received : 4', 'with getting : 4', 'received : 3', 'ca n’t get : 3', 'trying to get : 3', 'for getting : 3']\n",
      "arguments:\n",
      " ['food : 44', 'shopping : 31', 'a food parcel : 9', 'any shopping : 6', 'groceries : 5', 'line shopping : 5', 'supplies : 4', 'some food : 4', 'some shopping : 3', 'food parcels : 3']\n",
      "====\n",
      "('NEED-SMTHG', 'SUPPORT') 138\n",
      "verbs:\n",
      " ['need : 97', 'needed : 6', 'needs : 4', 'would like : 4', 'want : 3', 'do not need : 2', 'require : 1', 'to request : 1', 'required : 1', 'want is : 1']\n",
      "arguments:\n",
      " ['help : 91', 'some help : 14', 'support : 8', 'access : 5', 'priority : 2', 'any support : 2', 'help sir : 1', 'assistance just the basic food stuffs : 1', 'revenue support : 1', 'no extra help : 1']\n",
      "====\n",
      "('MY-SITUATION', 'INFORMATION') 136\n",
      "verbs:\n",
      " ['have : 22', 'am not on : 16', 'am on : 6', 'do n’t have : 6', '’m not on : 3', 'am : 2', 'am in : 2', 'do not have : 2', \"do n't have : 2\", 'to have : 2']\n",
      "arguments:\n",
      " ['the list : 13', 'list : 11', 'the form : 6', 'details : 4', 'a number : 3', 'contact : 3', 'the number : 3', 'the wrong address : 2', 'information : 2', 'nhs number : 2']\n",
      "====\n",
      "('MY-SITUATION', 'WORK-MENTION') 130\n",
      "verbs:\n",
      " ['am : 15', 'have : 14', 'have lost : 6', \"'m : 5\", '’m : 3', \"do n't have : 3\", 'am out of : 3', 'am currently off : 3', '’m off : 3', 'do not have : 2']\n",
      "arguments:\n",
      " ['work : 42', 'a job : 6', 'an employee : 4', 'job : 4', 'a critical worker : 3', '2 jobs : 3', 'a care worker : 2', 'a small business : 2', 'a limited company : 2', 'no job : 2']\n",
      "====\n",
      "('CHANGE-SMTHG', 'LICENSE') 111\n",
      "verbs:\n",
      " ['to renew : 37', 'renew driving : 14', 'renew : 9', 'need to renew : 9', 'to renew driving : 6', 'on renewing : 4', 'have been trying to renew : 2', 'to change : 1', 'change : 1', 'have recently changed : 1']\n",
      "arguments:\n",
      " ['licence : 36', 'driving licence : 26', 'license : 11', 'driving license : 8', 'hgv licence : 5', 'lorry licence : 3', 'vehicle licence : 2', 'drivers licence : 2', 'lgv licence : 2', 'driver license : 2']\n",
      "====\n",
      "('UNCLEAR-SITUATION', 'INFORMATION') 103\n",
      "verbs:\n",
      " ['is : 38', 'is not on : 8', 'was : 7', 'had : 3', \"'s : 3\", 'was on : 3', 'was given : 2', 'was following : 2', 'is on : 1', 'is only : 1']\n",
      "arguments:\n",
      " ['a link : 6', 'information : 5', 'info : 5', 'list : 5', 'the advice : 4', 'guidance : 4', 'a list : 3', 'a form : 3', 'the form : 3', 'the list : 3']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'GIVEN-MONEY') 102\n",
      "verbs:\n",
      " ['get : 13', 'to get : 10', 'to claim : 8', 'claim : 8', 'can get : 6', 'can claim : 6', 'will get : 3', 'can not get : 2', 'receive : 2', 'could get : 2']\n",
      "arguments:\n",
      " ['money : 29', 'a refund : 10', 'a grant : 8', 'some money : 7', 'any money : 6', 'grant : 5', 'tax refund : 4', 'a tax refund : 4', 'the grant : 4', 'the tax refund : 2']\n",
      "====\n",
      "('OTHERS-SITUATION', 'HEALTH-PROBLEM') 96\n",
      "verbs:\n",
      " ['has : 71', 'has had : 7', 'are : 4', 'has underlying : 2', 'are with : 1', 'has got : 1', 'are talking about : 1', 'are shielding because of underlying : 1', 'has under lining : 1', 'has recently had bowel : 1']\n",
      "arguments:\n",
      " ['copd : 17', 'diabetes : 7', 'cancer : 7', 'asthma : 6', 'dementia : 4', 'type 2 diabetes : 3', 'type 1 diabetes : 3', 'a heart condition : 3', 'heart failure : 3', 'leukaemia : 2']\n",
      "====\n",
      "('MY-SITUATION', 'CORRESPONDENCE') 93\n",
      "verbs:\n",
      " ['have : 20', 'have had : 18', 'have not had : 9', \"have n't had : 6\", 'have got : 4', 'have not recieved : 4', 'am still waiting for : 2', 'have n’t had : 2', 'do not have : 1', 'have not got : 1']\n",
      "arguments:\n",
      " ['a letter : 48', 'letter : 7', 'letters : 4', 'email : 2', 'letter.no : 1', 'the shielding letter : 1', 'tu download the letter : 1', 'a nhs letter : 1', 'a text message : 1', 'the letters : 1']\n",
      "====\n",
      "('MY-SITUATION', 'ELDERLY') 93\n",
      "verbs:\n",
      " ['am : 76', '’m : 4', \"'m : 3\", 'am over : 2', 'have : 1', 'm : 1', 'am of : 1', 'am trying to help : 1', '’m am : 1', 'am caring for : 1']\n",
      "arguments:\n",
      " ['73 years : 8', '77 years : 8', '81 years : 5', '80 years : 5', '71 years : 5', '74 years : 4', '82 years : 4', '85 years : 4', '86 years : 4', '88 years : 3']\n",
      "====\n",
      "('APPLY-SMTHG', 'VULNERABLE') 90\n",
      "verbs:\n",
      " ['to register as : 25', 'to register : 7', 'to try to register as : 5', 'to register on : 4', 'register as : 4', 'to apply as : 2', 'needed to register as : 2', 'to sign up as : 2', 'need to register as : 2', 'wanted to register as : 2']\n",
      "arguments:\n",
      " ['a vulnerable person : 50', 'extremely vulnerable person : 10', 'a vulnerable elderly person : 2', 'vulnerable : 2', 'the vulnerable list : 2', 'covid19 vulnerable : 1', 'a vulnerable older adult : 1', 'extreemley vulnerable : 1', 'a vulnerable individual : 1', 'extremely vulnerable adult : 1']\n",
      "====\n",
      "('CHANGE-SMTHG', 'INFORMATION') 89\n",
      "verbs:\n",
      " ['to change : 29', 'change : 7', 'need to change : 7', 'want to change : 6', 'to update : 4', 'changed : 3', 'have changed : 3', 'update : 2', 'wanted to change : 2', 'updated : 2']\n",
      "arguments:\n",
      " ['address : 37', 'the address : 5', 'bank details : 5', 'details : 3', 'email address : 3', 'information : 3', 'address details : 2', 'bank account details : 2', 'phone number : 2', 'guidance : 2']\n",
      "====\n",
      "('ACCESS-SMTHG', 'INFORMATION') 84\n",
      "verbs:\n",
      " ['to check : 23', 'to access : 6', 'to check on : 5', 'check : 4', 'to complete : 4', 'complete : 4', 'completed : 3', 'checking : 2', 'wanted to check : 2', 'check on : 2']\n",
      "arguments:\n",
      " ['information : 6', 'details : 5', 'the form : 5', 'advice : 4', 'the information : 3', 'updates : 3', 'guidelines : 2', 'the advice : 2', 'the guidance : 2', 'list : 2']\n",
      "====\n",
      "('MY-SITUATION', 'VULNERABLE') 78\n",
      "verbs:\n",
      " ['am : 26', 'am in : 9', \"'m : 7\", 'am on : 4', \"'m in : 3\", 'am classed as : 3', 'am not on : 2', '’m in : 2', 'have : 1', 'm : 1']\n",
      "arguments:\n",
      " ['a vulnerable person : 26', 'extremely vulnerable person : 5', 'extremely vulnerable group : 4', 'the vulnerable list : 4', 'the vulnerable category : 3', 'the vulnerable group : 3', 'extremely vulnerable people : 2', 'extremely vulnerable category : 2', 'the vulnerable : 2', 'extremely vulnerable : 2']\n",
      "====\n",
      "('LIVING', 'HOME-MENTION') 78\n",
      "verbs:\n",
      " ['to stay at : 25', 'stay at : 8', 'live in : 5', 'staying at : 4', 'should stay at : 3', 'live at : 3', 'living in : 1', 'to stay : 1', 'stay in : 1', 'to stay in : 1']\n",
      "arguments:\n",
      " ['home : 61', 'house : 2', 'home 12 weeks : 1', 'the same home : 1', 'the same house : 1', 'a different house : 1', 'two homes : 1', 'a house hold : 1', 'home two sisters : 1', 'the house : 1']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'BENEFIT') 74\n",
      "verbs:\n",
      " ['to claim : 11', 'can claim : 7', 'get : 6', 'receive : 4', 'can not get : 2', 'claim : 2', 'claiming : 2', 'can not claim : 2', 'can receive : 2', 'to get : 1']\n",
      "arguments:\n",
      " ['benefits : 11', 'ssp : 10', 'universal credit : 6', 'esa : 5', 'any benefits : 4', 'pip : 4', 'housing benefit : 3', 'marriage allowance : 2', 'some universal credit : 2', 'no benefits : 2']\n",
      "====\n",
      "('UNCLEAR-SITUATION', 'CORRESPONDENCE') 71\n",
      "verbs:\n",
      " ['had : 45', '’ve had : 4', 'is : 2', 'was : 1', 'is on : 1', 'was on : 1', \"is n't : 1\", 'was given : 1', 'was hoping for : 1', 've had : 1']\n",
      "arguments:\n",
      " ['a letter : 24', 'a message : 10', 'letter : 7', 'a text : 5', 'a text message : 2', 'an email : 2', 'an email purporting : 1', 'the same letter : 1', 'gov letter : 1', '2 letters : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'WORK-MENTION') 69\n",
      "verbs:\n",
      " ['to find out if : 4', 'to find : 3', 'to find out about : 3', 'to look for : 3', 'looking for : 2', 'have been asked by : 2', 'to find out how to furlough : 2', 'find : 1', 'to see if : 1', 'to find out why : 1']\n",
      "arguments:\n",
      " ['employer : 8', 'work : 5', 'a job : 5', 'employees : 4', 'the job retention scheme : 3', 'an employee : 3', 'the job centre : 2', 'the small business grant : 2', 'agency workers : 2', 'employment : 2']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'BILLS-TO-PAY') 64\n",
      "verbs:\n",
      " ['received : 7', 'to get : 6', 'to claim : 5', 'claim : 5', 'get : 3', 'have received : 3', 'can not get : 1', 'can get : 1', 'have not received : 1', 'to take : 1']\n",
      "arguments:\n",
      " ['tax : 7', 'tax return : 4', 'a vehicle tax reminder : 3', 'car tax : 3', 'insurance : 2', 'rent : 2', 'tax credits : 2', 'tax rebate : 2', 'a tax return : 2', 'a car tax reminder : 1']\n",
      "====\n",
      "('MY-SITUATION', 'NO-ONE') 60\n",
      "verbs:\n",
      " ['have : 37', 'have heard : 8', \"have n't heard : 2\", 'have had : 1', 'have been : 1', 'feel : 1', 'feel like ’s : 1', 'am have : 1', 'have not done : 1', 'have spoken to say : 1']\n",
      "arguments:\n",
      " ['nothing : 24', 'no one : 16', 'no family : 15', 'nobody shops : 1', 'nothing other : 1', 'nobody : 1', 'five stone no one : 1', 'another nobody : 1']\n",
      "====\n",
      "('UNCLEAR-SITUATION', 'NO-INFORMATION') 59\n",
      "verbs:\n",
      " ['is : 38', 'was : 8', \"'s : 4\", 'had : 2', '’s : 2', '’ve had : 1', 'is still : 1', 'do n’t ’s : 1', 'seems is : 1', 'is n’t at all : 1']\n",
      "arguments:\n",
      " ['no information : 21', 'no guidance : 6', 'no mention : 5', 'no advice : 4', 'no link : 3', 'no email address : 2', 'no contact : 2', 'no info : 1', 'no phone number : 1', 'no contact number : 1']\n",
      "====\n",
      "('ACQUIRE-SMTHG', 'WORK-MENTION') 57\n",
      "verbs:\n",
      " ['get : 4', 'to get to : 4', 'can not get : 3', 'sent : 2', 'to get : 1', 'received : 1', 'can get : 1', 'have not received : 1', \"ca n't get : 1\", 'to take : 1']\n",
      "arguments:\n",
      " ['work : 11', 'employment : 3', 'company : 3', 'job : 2', 'a small business grant : 2', 'another job : 2', 'a new job : 2', 'a part time job : 2', 'employees : 2', 'workplace : 2']\n",
      "====\n",
      "('OTHERS-SITUATION', 'INFORMATION') 57\n",
      "verbs:\n",
      " ['are not on : 5', 'has : 3', 'are : 2', 'are waiting for : 2', 'are not included in : 2', 'are in : 1', 'are on : 1', 'has been : 1', 're : 1', 'has been in : 1']\n",
      "arguments:\n",
      " ['the list : 6', 'information : 3', 'contact : 3', 'a number : 2', 'list : 2', 'the advice : 2', 'details : 2', 'the gov.uk list : 1', 'the shielding list : 1', 'the answer : 1']\n",
      "====\n",
      "('UNCLEAR-SITUATION', 'HEALTH-PROBLEM') 56\n",
      "verbs:\n",
      " ['is : 18', 'had : 18', 'is in : 1', 'is not : 1', 'is at : 1', '’ve had : 1', \"'ve had : 1\", 'is also : 1', 'was diagnosed with : 1', '’ve had to self isolate due to : 1']\n",
      "arguments:\n",
      " ['a stroke : 5', 'an issue : 3', 'type 1 diabetic : 2', 'breast cancer : 2', 'a heart attack : 2', 'cancer : 2', 'heart failure : 2', 'condition : 2', 'dr health surgery : 1', 'a type : 1']\n",
      "====\n",
      "('ACCESS-SMTHG', 'DELIVERY') 56\n",
      "verbs:\n",
      " ['to book : 12', 'to access : 7', 'can not book : 5', 'to cancel : 2', 'can not access : 2', 'can book : 2', 'can access : 2', 'book : 2', 'booked : 1', 'access : 1']\n",
      "arguments:\n",
      " ['a slot : 12', 'a delivery slot : 6', 'home delivery : 4', 'food deliveries : 3', 'an online shopping slot : 2', 'a delivery : 2', 'delivery : 2', 'shopping deliveries : 2', 'an asda delivery : 1', 'an online shopping facility : 1']\n",
      "====\n",
      "('MY-SITUATION', 'HOME-MENTION') 55\n",
      "verbs:\n",
      " ['have : 4', 'am : 3', 'have been advised to stay at : 3', \"'m : 2\", 'have to stay at : 2', 'have been confined to : 2', 'have moved : 2', 'have been at : 2', 'have stayed at : 2', 'am at : 1']\n",
      "arguments:\n",
      " ['home : 27', 'housebound : 5', 'house : 5', 'the house : 3', 'home sats : 1', 'a second home : 1', 'home tagging : 1', 'a question the home office : 1', 'an elderly housebound lady : 1', 'home career : 1']\n",
      "====\n",
      "('NEED-SMTHG', 'GOODS') 53\n",
      "verbs:\n",
      " ['need : 9', 'to order : 7', 'order : 3', 'do not need : 2', 'can order : 2', 'have tried to order : 2', 'want : 1', 'needs : 1', 'require : 1', 'want is : 1']\n",
      "arguments:\n",
      " ['food : 23', 'shopping : 6', 'a food parcel : 4', 'groceries : 4', 'a free food parcel : 3', 'some shopping : 2', 'food shopping : 2', 'food parcels : 2', 'food supplies : 1', 'some food : 1']\n",
      "====\n",
      "('MY-SITUATION', 'FAMILY') 52\n",
      "verbs:\n",
      " ['have : 17', 'am : 10', '’m : 3', \"'m : 2\", 'do not have : 1', 'am at : 1', 'm : 1', 'do nt have : 1', \"'m currently in : 1\", 'have been advised to shield for : 1']\n",
      "arguments:\n",
      " ['husband : 4', 'a single parent : 4', 'wife : 3', 'family : 2', 'mother : 2', 'a partner : 2', 'a single mother : 2', 'a mother : 1', 'a copy parents marriage certificate : 1', 'mothers old american passport : 1']\n",
      "====\n",
      "('UNCLEAR-SITUATION', 'WORK-MENTION') 52\n",
      "verbs:\n",
      " ['is : 9', 'had : 4', 'was : 2', 'is going back to : 2', \"'s : 1\", 'was advised by : 1', 'was told : 1', 'is classed as : 1', \"'s out of : 1\", 'was told on : 1']\n",
      "arguments:\n",
      " ['work : 17', 'employer : 4', 'a care worker : 3', 'a company : 2', 'business : 2', 'nhs front line workers : 1', '81yrs ex employee : 1', 'the manager business : 1', 'a non - public sector employer : 1', 'workers : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'COVID-MENTION') 52\n",
      "verbs:\n",
      " ['looking for : 7', 'to find out : 4', 'to find out about : 4', 'was looking for : 3', 'to read : 2', 'understand : 2', 'to understand : 2', 'of spreading : 2', 'to see : 1', 'to look for : 1']\n",
      "arguments:\n",
      " ['the virus : 5', 'coronavirus : 3', 'the coronavirus : 2', 'covid-19 guidance : 2', 'about covid : 2', 'the coronavirus job retention scheme : 2', 'covid : 2', 'covid 19 : 2', 'covid19 testing data : 1', 'covid 19 advice : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'FAMILY') 50\n",
      "verbs:\n",
      " ['to find out if : 5', 'to see if : 3', 'see : 3', 'to find out how : 2', 'can see : 2', 'to find out whether : 2', 'to see : 1', 'to find out about : 1', 'find : 1', 'to obtain : 1']\n",
      "arguments:\n",
      " ['mother : 6', 'father : 6', 'parents : 5', 'husband : 5', 'dad : 4', 'wife : 3', 'family : 2', 'a partner : 1', 'ex partner : 1', 'partners work : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'CORRESPONDENCE') 49\n",
      "verbs:\n",
      " ['found : 3', 'to find out about : 2', 'to read : 2', 'to find out how to get : 2', 'was asked to by : 2', 'looking for : 1', 'to look for : 1', 'to find out if : 1', 'am looking for : 1', 'understand : 1']\n",
      "arguments:\n",
      " ['a letter : 6', 'an email : 4', 'message : 3', 'letter : 3', 'the letter : 3', 'a email : 2', 'nhs letter : 2', 'letters : 2', 'email : 2', 'emails : 2']\n",
      "====\n",
      "('FIND-SMTHG', 'BILLS-TO-PAY') 47\n",
      "verbs:\n",
      " ['to find : 2', 'to obtain : 2', 'to find out how to pay : 2', 'to find out : 1', 'to look for : 1', 'find : 1', 'see : 1', 'to find out why : 1', 'am looking for : 1', 'know : 1']\n",
      "arguments:\n",
      " ['tax code : 5', 'tax rebate : 2', 'a tax rebate : 2', 'tax : 2', 'a tax return : 2', 'the current membership : 1', 'the fee : 1', 'a current dbs certificate : 1', 'a mortgage : 1', 'garden waste bill : 1']\n",
      "====\n",
      "('MY-SITUATION', 'NO-INCOME') 46\n",
      "verbs:\n",
      " ['have : 38', 'have had : 3', 'will have : 2', 'have been given : 1', 'have to wait with : 1', 'am currently with : 1']\n",
      "arguments:\n",
      " ['no income : 21', 'no money : 14', 'no work : 5', 'no wages : 3', 'no money national insurance number : 1', 'no income watsoever : 1', 'no income husband : 1']\n",
      "====\n",
      "('MY-SITUATION', 'BILLS-TO-PAY') 46\n",
      "verbs:\n",
      " ['have : 16', 'am : 3', 'am on : 2', 'have not had : 1', \"have n't had : 1\", 'am entitled to : 1', 'am not in : 1', 'have rang : 1', \"have n't : 1\", 'may have : 1']\n",
      "arguments:\n",
      " ['a mortgage : 4', 'a tax rebate : 4', 'bills : 3', 'debt : 2', 'tax return : 2', 'rent : 1', 'an exempt tax : 1', 'incurred bank fees : 1', 'no feed : 1', '8 years national insurance stamps : 1']\n",
      "====\n",
      "('GO-SMWHR', 'WORK-MENTION') 45\n",
      "verbs:\n",
      " ['to go to : 9', 'go to : 8', 'to go back to : 4', 'go back to : 4', 'can go to : 3', 'to go : 2', 'ca nt go to : 2', 'should go to : 2', 'can not go to : 1', 'believe having to go back to : 1']\n",
      "arguments:\n",
      " ['work : 41', 'job centre : 1', 'another employer : 1', 'work place : 1', 'any officine job center : 1']\n",
      "====\n",
      "('MY-SITUATION', 'COVID-MENTION') 44\n",
      "verbs:\n",
      " ['have : 9', 'have had : 2', 'have recovered from : 2', 'have suspected : 2', 'am in : 1', 'do not have : 1', 'do have : 1', 'have to have : 1', 'am following : 1', \"'m out of : 1\"]\n",
      "arguments:\n",
      " ['covid-19 : 9', 'covid 19 : 7', 'the virus : 6', 'covid19 : 5', 'coronavirus : 3', 'a leaflet community coronavirus care : 1', 'viruses : 1', 'the coronavirus : 1', 'coronavirus symptoms : 1', 'covid 19 symptoms : 1']\n",
      "====\n",
      "('MY-SITUATION', 'SELF-ISOLATION') 44\n",
      "verbs:\n",
      " ['am in : 7', 'am : 6', 'have been in : 6', 'have been advised to : 4', 'am on : 2', '’m in : 2', '’m : 1', \"'m in : 1\", '’m on : 1', 'am over : 1']\n",
      "arguments:\n",
      " ['isolation : 12', 'self isolation : 10', 'self isolating : 7', 'self isolate : 6', 'lockdown : 3', '12 week lockdown carnt : 1', '12 week lockdown : 1', '70 self isolating : 1', 'lockdown 75mls : 1', 'a isolation note : 1']\n",
      "====\n",
      "('DO-SMTHNG', 'INFORMATION') 44\n",
      "verbs:\n",
      " ['to download : 3', 'download : 3', \"does n't recognise : 3\", 'to make : 2', 'do : 2', 'to do : 2', 'make : 2', 'do not recognise : 2', 'do not appear on : 2', 'does n’t seem to be : 2']\n",
      "arguments:\n",
      " ['nhs number : 5', 'contact : 4', 'list : 3', 'form : 2', 'the list : 2', 'any lists : 2', 'any information : 2', 'tax overview forms : 1', 'a pa25 form notice : 1', 'an hmrc form : 1']\n",
      "====\n",
      "('ACCESS-SMTHG', 'BILLS-TO-PAY') 42\n",
      "verbs:\n",
      " ['to check : 6', 'to cancel : 6', 'check : 2', 'to complete : 2', 'check on : 2', 'need to complete : 2', 'to access : 1', 'wanted to check : 1', 'completed : 1', 'to check about : 1']\n",
      "arguments:\n",
      " ['the tax : 4', 'tax code : 3', 'car insurance : 3', 'tax return : 3', 'car tax : 2', 'road tax : 2', 'tax : 2', 'a tax return : 2', 'tax status : 1', 'motor insurance : 1']\n",
      "====\n",
      "('MY-SITUATION', 'CHILD') 41\n",
      "verbs:\n",
      " ['have : 18', 'am : 4', 'to have : 2', \"does n't have : 1\", 'am trying to help : 1', 'am struggling now : 1', 'have to leave : 1', 'am currently staying with : 1', '’m still expected to send : 1', 'have moved in with : 1']\n",
      "arguments:\n",
      " ['children : 6', 'daughter : 6', 'son : 5', 'a son : 4', 'no children : 2', 'grandchildren : 2', 'a child deem : 1', 'grandchild : 1', 'a daughter : 1', 'partners children : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'DATA') 41\n",
      "verbs:\n",
      " ['to see : 8', 'to find out : 5', 'clarify : 2', 'to find : 1', 'to look for : 1', 'find : 1', 'to find out why : 1', 'wanted to find : 1', 'need to know : 1', 'was trying to find : 1']\n",
      "arguments:\n",
      " ['the situation : 6', 'the progress : 3', 'situation : 3', 'data : 3', 'status : 3', 'progress : 2', 'the status : 2', 'any news : 1', 'statistics : 1', 'the statistics : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'DELIVERY') 41\n",
      "verbs:\n",
      " ['to find out about : 4', 'to obtain : 4', 'to find : 2', 'finding : 2', 'to enquire about : 2', 'find : 1', \"ca n't find : 1\", 'trying to find : 1', 'to find out how to get : 1', 'obtain : 1']\n",
      "arguments:\n",
      " ['food delivery : 5', 'food deliveries : 4', 'any delivery slots : 3', 'a delivery : 3', 'delivery slots : 3', 'a delivery slot : 2', 'a slot : 2', 'food parcel delivery : 1', 'the online shopping register : 1', 'delivery slot : 1']\n",
      "====\n",
      "('APPLY-SMTHG', 'FAMILY') 41\n",
      "verbs:\n",
      " ['to register : 19', 'register : 3', 'registered : 3', 'trying to register : 3', 'am trying to register : 2', 'have registered : 1', 'wanted to register : 1', 'could register : 1', 'registering to do : 1', 'to try to register : 1']\n",
      "arguments:\n",
      " ['husband : 9', 'father : 7', 'wife : 6', 'mother : 6', 'parents : 4', 'partner : 3', 'mum : 2', 'dad : 1', 'mother death : 1', 'wife name : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'RULES') 40\n",
      "verbs:\n",
      " ['to find out : 8', 'to see : 5', 'find out : 2', 'to find out about driving : 2', 'to find : 1', 'can not find : 1', 'to find out about : 1', 'find : 1', 'trying to find : 1', 'to see if : 1']\n",
      "arguments:\n",
      " ['the rules : 12', 'rules : 7', 'rights : 4', 'restrictions : 3', 'measures : 1', 'any extra measures the government : 1', 'tax rules : 1', 'the exact rules : 1', 'a clear description the lockdown rules : 1', 'the rule : 1']\n",
      "====\n",
      "('APPLY-SMTHG', 'DELIVERY') 40\n",
      "verbs:\n",
      " ['to register for : 11', 'would like to register for : 3', 'can register for : 2', 'wanted to register for : 2', \"ca n't register for : 2\", 'to apply for : 1', 'applied for : 1', 'am trying to register for : 1', 'register for : 1', 'trying to register for : 1']\n",
      "arguments:\n",
      " ['home delivery : 10', 'home deliveries : 4', 'a home delivery : 2', 'deliveries : 1', 'food delivery : 1', 'shopping delivery son : 1', 'delivery : 1', 'food parcel delivery : 1', 'food parcel deliveries : 1', 'priority supermarket delivery slots : 1']\n",
      "====\n",
      "('MY-SITUATION', 'KEY-WORKER') 39\n",
      "verbs:\n",
      " ['am : 19', '’m : 5', 'am classed as : 5', \"'m : 4\", 'am not : 3', 'm : 1', \"'m classed as : 1\", 'am actually : 1']\n",
      "arguments:\n",
      " ['a key worker : 31', 'a keyworker : 4', 'a staff nurse : 1', 'a nurse : 1', 'a key worker son : 1', 'an essential worker : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'UNCERTAINTY') 39\n",
      "verbs:\n",
      " ['can not find : 6', 'to find : 4', 'was looking for : 3', 'find : 2', \"ca n't find : 2\", 'trying to find : 2', 'try to find : 2', 'to try to find : 2', 'looking for : 1', 'could not find : 1']\n",
      "arguments:\n",
      " ['a way : 28', 'any way : 9', 'no means : 1', 'any means : 1']\n",
      "====\n",
      "('MY-SITUATION', 'GOODS') 37\n",
      "verbs:\n",
      " ['have : 7', 'have run out of : 2', '’m running out of : 2', 'am running out of : 2', 'will have to go out : 2', 'have to do : 2', 'have had : 1', 'can have : 1', 'have done : 1', 'could have : 1']\n",
      "arguments:\n",
      " ['shopping : 12', 'food : 9', 'no food : 2', 'money no food : 1', 'food items : 1', 'no shopping : 1', 'no food money : 1', 'supplies : 1', 'food shop : 1', 'no food shopping : 1']\n",
      "====\n",
      "('FIND-SMTHG', 'CHILD') 37\n",
      "verbs:\n",
      " ['to find out if : 4', 'to find out about : 2', 'see : 2', 'to see if : 1', 'want to know if : 1', 'wanted to know if : 1', 'trying to find out if : 1', 'to find out how : 1', 'can see : 1', 'looking at : 1']\n",
      "arguments:\n",
      " ['children : 10', 'son : 8', 'daughter : 4', 'severely autistic daughter : 1', 'childcare : 1', 'child arrangement orders : 1', 'child : 1', 'step children : 1', 'children teenagers : 1', 'food vouchers grandchildren : 1']\n",
      "====\n",
      "('WORK-SMWHR', 'HOME-MENTION') 37\n",
      "verbs:\n",
      " ['to work from : 6', 'work from : 4', 'working from : 4', 'can not work from : 4', 'work in : 2', 'work for : 1', 'working in : 1', 'to work in : 1', 'works in : 1', \"'m working from : 1\"]\n",
      "arguments:\n",
      " ['home : 29', 'home please : 1', 'a private nursing home : 1', 'a nursing home : 1', 'a food factory working home : 1', 'a rest home : 1', 'people homes : 1', 'a homeless hostel : 1', 'the house hold : 1']\n",
      "====\n",
      "('MY-SITUATION', 'AT-RISK') 36\n",
      "verbs:\n",
      " ['am : 9', \"'m in : 6\", 'am in : 4', 'am on : 2', \"'m : 2\", 'am not on : 2', \"'m at : 1\", '’m in : 1', \"did n't have : 1\", 'm on : 1']\n",
      "arguments:\n",
      " ['at risk : 12', 'a high risk person : 2', 'a high risk : 2', 'the high risk : 2', 'a high risk group : 2', 'a risk parents : 1', 'at high risk : 1', 'worried about the risks : 1', 'in the high risk category : 1', 'of the @ risk groups : 1']\n",
      "====\n",
      "('CHANGE-SMTHG', 'BILLS-TO-PAY') 36\n",
      "verbs:\n",
      " ['to renew : 14', 'renew : 11', 'to change : 3', 'want to change : 1', 'am trying to renew : 1', 'want to renew : 1', 'am attempting to change : 1', 'to attempt to renew : 1', 'wanted to renew : 1', 'renews : 1']\n",
      "arguments:\n",
      " ['car tax : 12', 'tax : 6', 'vehicle tax : 4', 'tax code : 3', 'vehicle road tax : 2', 'the tax : 1', 'vehicle tax car : 1', 'tax disc : 1', 'car insurance : 1', 'road tax : 1']\n",
      "====\n",
      "('MY-SITUATION', 'SUPPORT') 35\n",
      "verbs:\n",
      " ['have : 6', 'am : 5', 'can have : 2', 'am entitled to : 2', 'am in : 1', \"'m : 1\", 'do not have : 1', \"do n't have : 1\", 'to have : 1', 'have been : 1']\n",
      "arguments:\n",
      " ['a priority : 3', 'priority : 3', 'access : 3', 'help : 3', 'support : 2', 'a good support system : 1', 'no outside support : 1', 'an apparent unpaid month : 1', 'the help : 1', 'assistance : 1']\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "row_list = []\n",
    "for pattern, values in sorted(verb_argument_fillers.items(),\n",
    "                           key = lambda x: sum([vs for v in x[1].values() for vs in v.values()]),\n",
    "                           reverse = True)[0:100]:\n",
    "    if 'UNKNOWN' not in pattern:\n",
    "        total_occ = sum([vs for v in values.values() for vs in v.values()])\n",
    "        print(pattern, total_occ)\n",
    "        \n",
    "        local_arguments = Counter()\n",
    "        local_verbs = Counter()\n",
    "        \n",
    "        for verb, argument_values in sorted(verb_argument_fillers[pattern].items(),\n",
    "                                   key = lambda x: sum(x[1].values()),\n",
    "                                   reverse = True):\n",
    "#             print(verb, sum(argument_values.values()))\n",
    "            local_verbs[verb] += sum(argument_values.values())\n",
    "#             print(argument_values.most_common(5))\n",
    "            for argument, count in argument_values.most_common():\n",
    "                local_arguments[argument] += count\n",
    "        \n",
    "        verbs = [f\"{k} : {v}\" for k,v in local_verbs.most_common()]\n",
    "        arguments = [f\"{k} : {v}\" for k,v in local_arguments.most_common()]\n",
    "        \n",
    "        print(\"verbs:\\n\", verbs[0:10])\n",
    "        print(\"arguments:\\n\", arguments[0:10])\n",
    "        \n",
    "        row_list.append({\"Generic phrase\": f\"{pattern[0]} - {pattern[1]}\",\n",
    "                         \"# of times occured\": total_occ,\n",
    "                        \"Verb category\": f\"{pattern[0]}\",\n",
    "                         \"Total # of verbs\" : sum(local_verbs.values()),\n",
    "                         \"# of unique verbs\" : len(local_verbs),\n",
    "                        \"Verb values\": \"\\n\".join(verbs[0:10]),\n",
    "                        \"Argument category\": f\"{pattern[1]}\",\n",
    "                        \"Total # of arguments\" : sum(local_arguments.values()),\n",
    "                         \"# of unique arguments\" : len(local_arguments),\n",
    "                        \"Argument values\": \"\\n\".join(arguments[0:10])})\n",
    "        print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(row_list)[0:20].to_csv(os.path.join(DATA_DIR, \"generic_phrase_counts_top_20.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview themes + values assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. MY-SITUATION 3208 43 \n",
      "======\n",
      "HEALTH-PROBLEM 272\n",
      "copd: 42\n",
      "asthma: 20\n",
      "diabetes: 15\n",
      "health problems: 11\n",
      "cancer: 11\n",
      "---\n",
      "INFORMATION 136\n",
      "the list: 13\n",
      "list: 11\n",
      "the form: 6\n",
      "details: 4\n",
      "a number: 3\n",
      "---\n",
      "WORK-MENTION 130\n",
      "work: 42\n",
      "a job: 6\n",
      "an employee: 4\n",
      "job: 4\n",
      "2 jobs: 3\n",
      "---\n",
      "CORRESPONDENCE 93\n",
      "a letter: 48\n",
      "letter: 7\n",
      "letters: 4\n",
      "email: 2\n",
      "letter.no: 1\n",
      "---\n",
      "ELDERLY 93\n",
      "77 years: 8\n",
      "73 years: 8\n",
      "81 years: 5\n",
      "80 years: 5\n",
      "71 years: 5\n",
      "---\n",
      "VULNERABLE 78\n",
      "a vulnerable person: 26\n",
      "extremely vulnerable person: 5\n",
      "the vulnerable list: 4\n",
      "extremely vulnerable group: 4\n",
      "the vulnerable category: 3\n",
      "---\n",
      "NO-ONE 60\n",
      "nothing: 24\n",
      "no one: 16\n",
      "no family: 15\n",
      "nobody shops: 1\n",
      "nothing other: 1\n",
      "---\n",
      "HOME-MENTION 55\n",
      "home: 27\n",
      "housebound: 5\n",
      "house: 5\n",
      "the house: 3\n",
      "home sats: 1\n",
      "---\n",
      "FAMILY 52\n",
      "husband: 4\n",
      "a single parent: 4\n",
      "wife: 3\n",
      "family: 2\n",
      "mother: 2\n",
      "---\n",
      "NO-INCOME 46\n",
      "no income: 21\n",
      "no money: 14\n",
      "no work: 5\n",
      "no wages: 3\n",
      "no money national insurance number: 1\n",
      "---\n",
      "BILLS-TO-PAY 46\n",
      "a mortgage: 4\n",
      "a tax rebate: 4\n",
      "bills: 3\n",
      "debt: 2\n",
      "tax return: 2\n",
      "---\n",
      "COVID-MENTION 44\n",
      "covid-19: 9\n",
      "covid 19: 7\n",
      "the virus: 6\n",
      "covid19: 5\n",
      "coronavirus: 3\n",
      "---\n",
      "SELF-ISOLATION 44\n",
      "isolation: 12\n",
      "self isolation: 10\n",
      "self isolating: 7\n",
      "self isolate: 6\n",
      "lockdown: 3\n",
      "---\n",
      "CHILD 41\n",
      "children: 6\n",
      "daughter: 6\n",
      "son: 5\n",
      "a son: 4\n",
      "grandchildren: 2\n",
      "---\n",
      "KEY-WORKER 39\n",
      "a key worker: 31\n",
      "a keyworker: 4\n",
      "a staff nurse: 1\n",
      "a nurse: 1\n",
      "a key worker son: 1\n",
      "---\n",
      "GOODS 37\n",
      "shopping: 12\n",
      "food: 9\n",
      "no food: 2\n",
      "money no food: 1\n",
      "food items: 1\n",
      "---\n",
      "AT-RISK 36\n",
      "at risk: 12\n",
      "a high risk person: 2\n",
      "a high risk: 2\n",
      "the high risk: 2\n",
      "a high risk group: 2\n",
      "---\n",
      "SUPPORT 35\n",
      "priority: 3\n",
      "a priority: 3\n",
      "access: 3\n",
      "help: 3\n",
      "support: 2\n",
      "---\n",
      "GIVEN-MONEY 33\n",
      "money: 10\n",
      "any money: 8\n",
      "a tax refund: 2\n",
      "the money: 2\n",
      "a refund: 2\n",
      "---\n",
      "UNCERTAINTY 30\n",
      "no idea: 14\n",
      "no way: 4\n",
      "no choice: 4\n",
      "a way: 2\n",
      "a choice: 2\n",
      "---\n",
      "DELIVERY 25\n",
      "deliveries: 2\n",
      "no slots: 2\n",
      "a delivery driver: 2\n",
      "a delivery slot: 2\n",
      "any slots: 1\n",
      "---\n",
      "BENEFIT 23\n",
      "pip: 5\n",
      "ssp: 2\n",
      "any benefit: 2\n",
      "eligible: 1\n",
      "some ssp: 1\n",
      "---\n",
      "CARER 19\n",
      "carer: 7\n",
      "a carer: 6\n",
      "carers: 2\n",
      "husband carer: 1\n",
      "the sole carer: 1\n",
      "---\n",
      "SYMPTOMS 17\n",
      "symptoms: 11\n",
      "any symptoms: 2\n",
      "the symptoms: 1\n",
      "symptoms extreme: 1\n",
      "concerned with the symptoms: 1\n",
      "---\n",
      "NO-INFORMATION 17\n",
      "no information: 4\n",
      "no advice: 2\n",
      "no contact: 2\n",
      "no form: 1\n",
      "no other form: 1\n",
      "---\n",
      "PENSION 15\n",
      "pension: 4\n",
      "a pension payslip: 1\n",
      "a small euro pension: 1\n",
      "a basic state pension: 1\n",
      "a state pension employer: 1\n",
      "---\n",
      "LICENSE 14\n",
      "driving licence: 2\n",
      "licence: 2\n",
      "license: 2\n",
      "a licence: 1\n",
      "an old licence: 1\n",
      "---\n",
      "SCHOOL 13\n",
      "a student: 2\n",
      "student finance: 1\n",
      "student loans: 1\n",
      "the first year student: 1\n",
      "an international student: 1\n",
      "---\n",
      "LAID-OFF 12\n",
      "the furlough scheme: 3\n",
      "furlough: 3\n",
      "80 % pay: 1\n",
      "the current furlough agreement: 1\n",
      "80 % wage: 1\n",
      "---\n",
      "PASSPORT 11\n",
      "a passport: 2\n",
      "no passport: 1\n",
      "an irish passport uc: 1\n",
      "português passport: 1\n",
      "an austrian passport: 1\n",
      "---\n",
      "DATA 11\n",
      "a situation: 3\n",
      "status: 2\n",
      "no immigration status: 1\n",
      "multiple sclerosis the primary progressive type: 1\n",
      "a desperate situation: 1\n",
      "---\n",
      "DISABLED 10\n",
      "a disabled badge: 1\n",
      "class disability: 1\n",
      "a disabled member: 1\n",
      "no disability: 1\n",
      "disability problems sciatica arthritis poly arthritis poly arthralgia: 1\n",
      "---\n",
      "GET-MED 10\n",
      "medication: 6\n",
      "medications: 2\n",
      "prescriptions: 1\n",
      "a prescription: 1\n",
      "---\n",
      "TRAVEL 9\n",
      "a flight: 3\n",
      "flight: 1\n",
      "a return flight: 1\n",
      "five flights: 1\n",
      "no direct commercial flights: 1\n",
      "---\n",
      "NO-CORRESPONDENCE 9\n",
      "no letter: 6\n",
      "no communication: 2\n",
      "no email: 1\n",
      "---\n",
      "NO-SUPPORT 8\n",
      "no help: 4\n",
      "no access: 2\n",
      "no support network: 1\n",
      "no priority: 1\n",
      "---\n",
      "DEATH 5\n",
      "death sentences heads: 1\n",
      "a death sentence: 1\n",
      "deaths hands: 1\n",
      "death hands: 1\n",
      "the deaths: 1\n",
      "---\n",
      "VISA 4\n",
      "a spousal visa: 1\n",
      "a uk settlement visa: 1\n",
      "a settlement visa valid: 1\n",
      "a tourist visa: 1\n",
      "---\n",
      "RULES 2\n",
      "no rights: 1\n",
      "the social distancing rules: 1\n",
      "---\n",
      "NO-SYMPTOMS 2\n",
      "no symptoms: 1\n",
      "with no symptoms: 1\n",
      "---\n",
      "SELF-EMPLOY 2\n",
      "the self employment scheme: 1\n",
      "self employment: 1\n",
      "---\n",
      "SCHEME 1\n",
      "the scheme: 1\n",
      "---\n",
      "\n",
      "2. ACQUIRE-SMTHG 2709 40 \n",
      "======\n",
      "DELIVERY 325\n",
      "a slot: 39\n",
      "a delivery slot: 34\n",
      "a delivery: 21\n",
      "home delivery: 13\n",
      "deliveries: 10\n",
      "---\n",
      "CORRESPONDENCE 298\n",
      "a letter: 122\n",
      "letter: 24\n",
      "an email: 22\n",
      "a text: 13\n",
      "the letter: 11\n",
      "---\n",
      "SUPPORT 220\n",
      "help: 105\n",
      "any help: 20\n",
      "support: 13\n",
      "priority: 12\n",
      "access: 9\n",
      "---\n",
      "INFORMATION 204\n",
      "information: 31\n",
      "an answer: 11\n",
      "advice: 10\n",
      "contact: 8\n",
      "the list: 8\n",
      "---\n",
      "GOODS 149\n",
      "food: 44\n",
      "shopping: 31\n",
      "a food parcel: 9\n",
      "any shopping: 6\n",
      "groceries: 5\n",
      "---\n",
      "GIVEN-MONEY 102\n",
      "money: 29\n",
      "a refund: 10\n",
      "a grant: 8\n",
      "some money: 7\n",
      "any money: 6\n",
      "---\n",
      "BENEFIT 74\n",
      "benefits: 11\n",
      "ssp: 10\n",
      "universal credit: 6\n",
      "esa: 5\n",
      "pip: 4\n",
      "---\n",
      "BILLS-TO-PAY 64\n",
      "tax: 7\n",
      "tax return: 4\n",
      "car tax: 3\n",
      "a vehicle tax reminder: 3\n",
      "insurance: 2\n",
      "---\n",
      "WORK-MENTION 57\n",
      "work: 11\n",
      "employment: 3\n",
      "company: 3\n",
      "a small business grant: 2\n",
      "job: 2\n",
      "---\n",
      "COVID-MENTION 35\n",
      "covid 19: 6\n",
      "coronavirus: 5\n",
      "the virus: 5\n",
      "this virus: 2\n",
      "covid-19: 2\n",
      "---\n",
      "PENSION 29\n",
      "state pension: 7\n",
      "pension: 5\n",
      "a pension forecast: 2\n",
      "pension credit: 2\n",
      "a pension summary: 1\n",
      "---\n",
      "LAID-OFF 28\n",
      "80 %: 11\n",
      "80 % wages: 5\n",
      "the furlough: 2\n",
      "80 % furlough wage: 1\n",
      "80 % pay: 1\n",
      "---\n",
      "CHILD 21\n",
      "daughter: 3\n",
      "son: 3\n",
      "child benefit: 2\n",
      "child: 2\n",
      "child tax: 1\n",
      "---\n",
      "NO-ONE 19\n",
      "nothing: 14\n",
      "a caution nothing the injuries: 1\n",
      "nothing tel 0282766: 1\n",
      "esa nobody: 1\n",
      "nothing question: 1\n",
      "---\n",
      "VULNERABLE 16\n",
      "a vulnerable letter: 4\n",
      "the vulnerable list: 3\n",
      "the vulnerable register: 2\n",
      "information a vulnerable person: 1\n",
      "nhs vulnerable letter: 1\n",
      "---\n",
      "GET-MED 15\n",
      "medication: 5\n",
      "prescription: 3\n",
      "medications: 2\n",
      "repeat prescriptions: 2\n",
      "medicals: 1\n",
      "---\n",
      "LICENSE 15\n",
      "licence: 4\n",
      "drivers licence: 2\n",
      "driving licence: 2\n",
      "the licence: 1\n",
      "driving license: 1\n",
      "---\n",
      "FAMILY 15\n",
      "husband: 3\n",
      "family: 2\n",
      "daily chemotherapy: 1\n",
      "one cause mum: 1\n",
      "ex husband: 1\n",
      "---\n",
      "HOME-MENTION 12\n",
      "home visits: 3\n",
      "house: 3\n",
      "a home kit: 1\n",
      "household shopping: 1\n",
      "the house: 1\n",
      "---\n",
      "NO-SUPPORT 10\n",
      "no help: 6\n",
      "no support: 2\n",
      "no help gp: 1\n",
      "hospital no help: 1\n",
      "---\n",
      "TRAVEL 8\n",
      "a flight home: 3\n",
      "a flight: 2\n",
      "travel mileage: 1\n",
      "date travel information: 1\n",
      "travel alerts: 1\n",
      "---\n",
      "SCHOOL 7\n",
      "student finance: 2\n",
      "school voucher: 1\n",
      "a student loan: 1\n",
      "a school place: 1\n",
      "schools: 1\n",
      "---\n",
      "ELDERLY 6\n",
      "food 91 year: 1\n",
      "help 85 year: 1\n",
      "a letter 90 year: 1\n",
      "87 year: 1\n",
      "70 year: 1\n",
      "---\n",
      "AT-RISK 6\n",
      "at risk: 2\n",
      "the high risk e mail: 1\n",
      "a high risk letter: 1\n",
      "any risks: 1\n",
      "the risk: 1\n",
      "---\n",
      "PASSPORT 5\n",
      "passport: 3\n",
      "a new british passport: 1\n",
      "passport photo: 1\n",
      "---\n",
      "SELF-ISOLATION 5\n",
      "a self isolation note: 2\n",
      "an isolation note employers: 1\n",
      "isolation pay: 1\n",
      "the voluntary isolation: 1\n",
      "---\n",
      "HEALTH-PROBLEM 5\n",
      "this awful disease: 1\n",
      "the same healthcare: 1\n",
      "the disease: 1\n",
      "heart disease medication: 1\n",
      "with health: 1\n",
      "---\n",
      "NO-INFORMATION 5\n",
      "no information: 3\n",
      "no advice: 1\n",
      "no phone number available: 1\n",
      "---\n",
      "NO-CORRESPONDENCE 5\n",
      "no letter: 3\n",
      "no text: 1\n",
      "no email: 1\n",
      "---\n",
      "SYMPTOMS 4\n",
      "any symptoms: 2\n",
      "symptoms: 1\n",
      "some symptoms: 1\n",
      "---\n",
      "NO-INCOME 3\n",
      "no money: 2\n",
      "no work: 1\n",
      "---\n",
      "RULES 2\n",
      "the official rules: 1\n",
      "restrictions: 1\n",
      "---\n",
      "SELF-EMPLOY 2\n",
      "answers self employment grant questions: 1\n",
      "self employment benefit: 1\n",
      "---\n",
      "CARER 2\n",
      "carers: 1\n",
      "carers allowance: 1\n",
      "---\n",
      "DEATH 1\n",
      "a death certificate: 1\n",
      "---\n",
      "DISABLED 1\n",
      "the disability allowance: 1\n",
      "---\n",
      "SCHEME 1\n",
      "this scheme: 1\n",
      "---\n",
      "UNCERTAINTY 1\n",
      "any way: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "some other key workers: 1\n",
      "---\n",
      "\n",
      "3. FIND-SMTHG 2366 39 \n",
      "======\n",
      "INFORMATION 616\n",
      "information: 121\n",
      "advice: 63\n",
      "any information: 24\n",
      "guidance: 24\n",
      "info: 20\n",
      "---\n",
      "SUPPORT 162\n",
      "help: 81\n",
      "support: 18\n",
      "any help: 11\n",
      "assistance: 8\n",
      "some help: 6\n",
      "---\n",
      "WORK-MENTION 69\n",
      "employer: 8\n",
      "work: 5\n",
      "a job: 5\n",
      "employees: 4\n",
      "the job retention scheme: 3\n",
      "---\n",
      "COVID-MENTION 52\n",
      "the virus: 5\n",
      "coronavirus: 3\n",
      "the coronavirus: 2\n",
      "covid-19 guidance: 2\n",
      "the coronavirus job retention scheme: 2\n",
      "---\n",
      "FAMILY 50\n",
      "father: 6\n",
      "mother: 6\n",
      "parents: 5\n",
      "husband: 5\n",
      "dad: 4\n",
      "---\n",
      "CORRESPONDENCE 49\n",
      "a letter: 6\n",
      "an email: 4\n",
      "the letter: 3\n",
      "message: 3\n",
      "letter: 3\n",
      "---\n",
      "BILLS-TO-PAY 47\n",
      "tax code: 5\n",
      "tax rebate: 2\n",
      "a tax rebate: 2\n",
      "tax: 2\n",
      "a tax return: 2\n",
      "---\n",
      "DATA 41\n",
      "the situation: 6\n",
      "data: 3\n",
      "the progress: 3\n",
      "situation: 3\n",
      "status: 3\n",
      "---\n",
      "DELIVERY 41\n",
      "food delivery: 5\n",
      "food deliveries: 4\n",
      "any delivery slots: 3\n",
      "a delivery: 3\n",
      "delivery slots: 3\n",
      "---\n",
      "RULES 40\n",
      "the rules: 12\n",
      "rules: 7\n",
      "rights: 4\n",
      "restrictions: 3\n",
      "the exact rules: 1\n",
      "---\n",
      "UNCERTAINTY 39\n",
      "a way: 28\n",
      "any way: 9\n",
      "no means: 1\n",
      "any means: 1\n",
      "---\n",
      "CHILD 37\n",
      "children: 10\n",
      "son: 8\n",
      "daughter: 4\n",
      "childcare: 1\n",
      "child arrangement orders: 1\n",
      "---\n",
      "LICENSE 26\n",
      "license: 5\n",
      "licence: 4\n",
      "driving licence: 4\n",
      "driving license: 3\n",
      "licence renewal: 2\n",
      "---\n",
      "GIVEN-MONEY 25\n",
      "money: 3\n",
      "funding: 2\n",
      "grant: 2\n",
      "refund: 2\n",
      "a refund: 2\n",
      "---\n",
      "HEALTH-PROBLEM 22\n",
      "conditions: 2\n",
      "illnesses the gov: 1\n",
      "a local mental health support telephone service: 1\n",
      "diabetes advice: 1\n",
      "people diabetes: 1\n",
      "---\n",
      "TRAVEL 22\n",
      "travel: 4\n",
      "a flight: 2\n",
      "travel restrictions: 2\n",
      "flights: 2\n",
      "travel information: 1\n",
      "---\n",
      "BENEFIT 22\n",
      "benefits: 3\n",
      "universal credit: 2\n",
      "benefit: 2\n",
      "sickness benefit claim: 1\n",
      "the attendance allowance rates: 1\n",
      "---\n",
      "LAID-OFF 18\n",
      "furlough: 5\n",
      "80 %: 4\n",
      "the furlough scheme: 2\n",
      "the furlough abuse hotline: 1\n",
      "furlough leave: 1\n",
      "---\n",
      "PENSION 18\n",
      "pension: 6\n",
      "state pension: 3\n",
      "a pension forecast: 1\n",
      "pension credit: 1\n",
      "armed forces pension: 1\n",
      "---\n",
      "GOODS 16\n",
      "food parcels: 4\n",
      "food: 3\n",
      "shopping: 1\n",
      "food supplies: 1\n",
      "supplies: 1\n",
      "---\n",
      "NO-ONE 16\n",
      "nothing: 12\n",
      "nobody: 1\n",
      "day no one doctors: 1\n",
      "no one: 1\n",
      "help wen no one: 1\n",
      "---\n",
      "VULNERABLE 13\n",
      "a vulnerable person: 4\n",
      "the vulnerable person advice re: 1\n",
      "a severe vulnerable disabled person: 1\n",
      "a vulnerable child: 1\n",
      "the vulnerable persons list: 1\n",
      "---\n",
      "HOME-MENTION 9\n",
      "home: 3\n",
      "the home: 1\n",
      "home page: 1\n",
      "household cleaning products: 1\n",
      "a university student home: 1\n",
      "---\n",
      "SELF-ISOLATION 8\n",
      "a isolation note: 1\n",
      "the isolation period: 1\n",
      "self isolation: 1\n",
      "a self isolation note: 1\n",
      "the isolation: 1\n",
      "---\n",
      "NO-INFORMATION 8\n",
      "no information: 4\n",
      "no mention: 2\n",
      "no answers: 1\n",
      "no guidance: 1\n",
      "---\n",
      "DEATH 6\n",
      "the deadline: 1\n",
      "the death toll: 1\n",
      "the death date: 1\n",
      "the daily deaths: 1\n",
      "death: 1\n",
      "---\n",
      "PASSPORT 6\n",
      "passport interviews: 1\n",
      "a urgent passport: 1\n",
      "passport: 1\n",
      "a passport the holder: 1\n",
      "a replacement passport: 1\n",
      "---\n",
      "SCHOOL 6\n",
      "a current student: 1\n",
      "student loan: 1\n",
      "the school: 1\n",
      "schools: 1\n",
      "student loan repayments: 1\n",
      "---\n",
      "CARER 5\n",
      "carers washing: 1\n",
      "home carers: 1\n",
      "a replacement carer: 1\n",
      "carers allowance: 1\n",
      "care homes: 1\n",
      "---\n",
      "ELDERLY 4\n",
      "89 year: 1\n",
      "92 year: 1\n",
      "99 year: 1\n",
      "75 year: 1\n",
      "---\n",
      "SCHEME 4\n",
      "a scheme: 1\n",
      "the scheme instructions: 1\n",
      "youth mobility scheme visa: 1\n",
      "about the national voucher scheme: 1\n",
      "---\n",
      "SYMPTOMS 3\n",
      "symptoms: 1\n",
      "the symptoms: 1\n",
      "of the symptoms: 1\n",
      "---\n",
      "DISABLED 3\n",
      "a disabled person: 2\n",
      "disabled child 24/7: 1\n",
      "---\n",
      "VISA 3\n",
      "visa: 1\n",
      "visa appeal application: 1\n",
      "uk visa: 1\n",
      "---\n",
      "AT-RISK 2\n",
      "the high risk definitions: 1\n",
      "about the high risk group: 1\n",
      "---\n",
      "NO-SUPPORT 1\n",
      "no help: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "a key worker son: 1\n",
      "---\n",
      "GET-MED 1\n",
      "a repeat prescription: 1\n",
      "---\n",
      "\n",
      "4. UNCLEAR-SITUATION 1888 41 \n",
      "======\n",
      "INFORMATION 103\n",
      "a link: 6\n",
      "info: 5\n",
      "information: 5\n",
      "list: 5\n",
      "guidance: 4\n",
      "---\n",
      "CORRESPONDENCE 71\n",
      "a letter: 24\n",
      "a message: 10\n",
      "letter: 7\n",
      "a text: 5\n",
      "a text message: 2\n",
      "---\n",
      "NO-INFORMATION 59\n",
      "no information: 21\n",
      "no guidance: 6\n",
      "no mention: 5\n",
      "no advice: 4\n",
      "no link: 3\n",
      "---\n",
      "HEALTH-PROBLEM 56\n",
      "a stroke: 5\n",
      "an issue: 3\n",
      "type 1 diabetic: 2\n",
      "breast cancer: 2\n",
      "a heart attack: 2\n",
      "---\n",
      "WORK-MENTION 52\n",
      "work: 17\n",
      "employer: 4\n",
      "a care worker: 3\n",
      "a company: 2\n",
      "business: 2\n",
      "---\n",
      "NO-ONE 34\n",
      "nothing: 25\n",
      "no one: 3\n",
      "nobody: 2\n",
      "nothing similar: 1\n",
      "nothing online: 1\n",
      "---\n",
      "UNCERTAINTY 33\n",
      "no way: 18\n",
      "no option: 5\n",
      "any way: 3\n",
      "a way: 3\n",
      "no means: 2\n",
      "---\n",
      "COVID-MENTION 32\n",
      "the virus: 5\n",
      "covid-19: 5\n",
      "this virus: 2\n",
      "covid 19: 2\n",
      "covid 19 positive: 1\n",
      "---\n",
      "SUPPORT 27\n",
      "help: 8\n",
      "any help: 7\n",
      "some help: 2\n",
      "government help: 1\n",
      "any support: 1\n",
      "---\n",
      "BILLS-TO-PAY 25\n",
      "tax: 3\n",
      "rent: 2\n",
      "an apprentice: 1\n",
      "no feed: 1\n",
      "fined: 1\n",
      "---\n",
      "FAMILY 24\n",
      "husband: 2\n",
      "wife: 2\n",
      "impossible at the moment: 2\n",
      "a partner a bigger professional partnership: 1\n",
      "a chemotherapy drug bones: 1\n",
      "---\n",
      "ELDERLY 24\n",
      "82 years: 3\n",
      "90 years: 2\n",
      "81 years: 2\n",
      "80 years: 2\n",
      "78 yrs: 1\n",
      "---\n",
      "AT-RISK 23\n",
      "at risk: 8\n",
      "a risk: 2\n",
      "a high risk area: 1\n",
      "a higher risk: 1\n",
      "an act risk person: 1\n",
      "---\n",
      "VULNERABLE 22\n",
      "a vulnerable person: 3\n",
      "the vulnerable list: 3\n",
      "the vulnerable category: 2\n",
      "a vulnerable adult: 1\n",
      "a vulnerable elderly lady: 1\n",
      "---\n",
      "NO-SUPPORT 14\n",
      "no help: 11\n",
      "no access: 1\n",
      "no assistance: 1\n",
      "no support: 1\n",
      "---\n",
      "CHILD 13\n",
      "son: 5\n",
      "daughter: 2\n",
      "single parent 2 children: 1\n",
      "granddaughter: 1\n",
      "the gov.uk/child-maintenance section: 1\n",
      "---\n",
      "CARER 13\n",
      "carer: 4\n",
      "a carer: 3\n",
      "a care home: 2\n",
      "carer husband: 1\n",
      "a carer dad: 1\n",
      "---\n",
      "SELF-ISOLATION 13\n",
      "lockdown: 5\n",
      "isolation: 2\n",
      "12 week isolation: 1\n",
      "14 days isolation: 1\n",
      "self isolating: 1\n",
      "---\n",
      "HOME-MENTION 12\n",
      "home: 4\n",
      "house: 2\n",
      "staff shortages the homes: 1\n",
      "houses: 1\n",
      "the house: 1\n",
      "---\n",
      "DELIVERY 12\n",
      "deliveries: 3\n",
      "a delivery slot: 1\n",
      "1 delivery: 1\n",
      "food delivery: 1\n",
      "one delivery: 1\n",
      "---\n",
      "GOODS 11\n",
      "food: 4\n",
      "no food: 1\n",
      "a food parcel a week: 1\n",
      "a food parcel: 1\n",
      "food parcel: 1\n",
      "---\n",
      "NO-CORRESPONDENCE 9\n",
      "no letter: 3\n",
      "no communication: 2\n",
      "no email: 1\n",
      "no message: 1\n",
      "no email confirmation: 1\n",
      "---\n",
      "SCHOOL 9\n",
      "students: 2\n",
      "a student radiographer: 1\n",
      "a college student: 1\n",
      "s student: 1\n",
      "a full time student: 1\n",
      "---\n",
      "KEY-WORKER 8\n",
      "a key worker: 6\n",
      "a community nurse: 1\n",
      "the district nurse: 1\n",
      "---\n",
      "BENEFIT 8\n",
      "maternity allowance calculate: 1\n",
      "benefits: 1\n",
      "ssp: 1\n",
      "the pipeline: 1\n",
      "eligible for the one: 1\n",
      "---\n",
      "GIVEN-MONEY 8\n",
      "money: 3\n",
      "a tax refund: 2\n",
      "money gojng: 1\n",
      "tax refund: 1\n",
      "any money: 1\n",
      "---\n",
      "DATA 7\n",
      "situation: 2\n",
      "a ridiculous situation: 1\n",
      "the situation: 1\n",
      "news: 1\n",
      "this situation: 1\n",
      "---\n",
      "SYMPTOMS 5\n",
      "symptoms: 3\n",
      "these symptoms: 1\n",
      "the symptoms: 1\n",
      "---\n",
      "PENSION 4\n",
      "pensioner: 1\n",
      "pension: 1\n",
      "a british state pension: 1\n",
      "the state pension age changes: 1\n",
      "---\n",
      "RULES 4\n",
      "the rules: 1\n",
      "the current self distancing rules: 1\n",
      "those rules: 1\n",
      "the rule: 1\n",
      "---\n",
      "DISABLED 3\n",
      "a disabled 77yrs: 1\n",
      "a disabled person: 1\n",
      "a disabled space: 1\n",
      "---\n",
      "TRAVEL 3\n",
      "the travel restrictions: 1\n",
      "no flights: 1\n",
      "flights: 1\n",
      "---\n",
      "NO-INCOME 3\n",
      "no money: 2\n",
      "to.close shop no income wots: 1\n",
      "---\n",
      "PASSPORT 2\n",
      "uk passport holder: 1\n",
      "passport: 1\n",
      "---\n",
      "LICENSE 2\n",
      "license: 1\n",
      "a licence: 1\n",
      "---\n",
      "VISA 2\n",
      "a spouse settlement visa: 1\n",
      "application documents visa last week: 1\n",
      "---\n",
      "SELF-EMPLOY 1\n",
      "a self employed worker: 1\n",
      "---\n",
      "GET-MED 1\n",
      "medication: 1\n",
      "---\n",
      "LAID-OFF 1\n",
      "80 % wages: 1\n",
      "---\n",
      "NO-SYMPTOMS 1\n",
      "no symptoms: 1\n",
      "---\n",
      "\n",
      "5. OTHERS-SITUATION 1218 42 \n",
      "======\n",
      "HEALTH-PROBLEM 96\n",
      "copd: 17\n",
      "diabetes: 7\n",
      "cancer: 7\n",
      "asthma: 6\n",
      "dementia: 4\n",
      "---\n",
      "INFORMATION 57\n",
      "the list: 6\n",
      "contact: 3\n",
      "information: 3\n",
      "a number: 2\n",
      "list: 2\n",
      "---\n",
      "WORK-MENTION 32\n",
      "work: 6\n",
      "workers: 3\n",
      "business: 2\n",
      "no school work: 1\n",
      "both seasonal workers: 1\n",
      "---\n",
      "HOME-MENTION 26\n",
      "home: 13\n",
      "house: 4\n",
      "home country: 2\n",
      "homeowners: 1\n",
      "home 14 days: 1\n",
      "---\n",
      "SELF-ISOLATION 25\n",
      "lockdown: 8\n",
      "isolation: 4\n",
      "self isolate: 3\n",
      "self isolating: 2\n",
      "self isolation: 2\n",
      "---\n",
      "COVID-MENTION 23\n",
      "covid 19: 3\n",
      "corona virus: 3\n",
      "coronavirus: 2\n",
      "the coronavirus: 2\n",
      "covid: 2\n",
      "---\n",
      "CORRESPONDENCE 22\n",
      "a letter: 5\n",
      "emails: 4\n",
      "letter: 3\n",
      "a message: 1\n",
      "an email help: 1\n",
      "---\n",
      "DELIVERY 19\n",
      "no slots: 7\n",
      "no delivery slots: 3\n",
      "no shopping slots: 1\n",
      "no deliveries: 1\n",
      "food bank delivery: 1\n",
      "---\n",
      "FAMILY 18\n",
      "husband: 3\n",
      "a family: 2\n",
      "family history: 1\n",
      "dad: 1\n",
      "mother: 1\n",
      "---\n",
      "CHILD 16\n",
      "children: 4\n",
      "son: 3\n",
      "daughter: 2\n",
      "four children: 1\n",
      "a young daughter: 1\n",
      "---\n",
      "SUPPORT 16\n",
      "help: 3\n",
      "priority: 2\n",
      "support: 2\n",
      "heart help: 1\n",
      "no internet access: 1\n",
      "---\n",
      "NO-INFORMATION 15\n",
      "no guidance: 2\n",
      "no link: 2\n",
      "no links: 2\n",
      "no information: 1\n",
      "no parliamentary contact details: 1\n",
      "---\n",
      "TRAVEL 15\n",
      "no flights: 2\n",
      "flights: 2\n",
      "a return flight: 1\n",
      "no flights home: 1\n",
      "any repatriation flights: 1\n",
      "---\n",
      "GOODS 14\n",
      "food: 4\n",
      "shopping: 2\n",
      "the food: 1\n",
      "a specialfood diet: 1\n",
      "food harvesting this year: 1\n",
      "---\n",
      "VULNERABLE 13\n",
      "the vulnerable list: 3\n",
      "both extremely vulnerable: 1\n",
      "the vulnerable section: 1\n",
      "the vulnerable category: 1\n",
      "the vulnerable person list: 1\n",
      "---\n",
      "ELDERLY 12\n",
      "70 years: 2\n",
      "93 year: 1\n",
      "85 yr: 1\n",
      "83 years: 1\n",
      "82 years: 1\n",
      "---\n",
      "AT-RISK 11\n",
      "at risk: 3\n",
      "no risk: 1\n",
      "both high risk: 1\n",
      "the high risk: 1\n",
      "the risk group: 1\n",
      "---\n",
      "NO-ONE 10\n",
      "no family: 4\n",
      "nothing: 4\n",
      "no one: 1\n",
      "nobody: 1\n",
      "---\n",
      "BILLS-TO-PAY 9\n",
      "no mortgage: 1\n",
      "no tax: 1\n",
      "bills: 1\n",
      "a renter: 1\n",
      "a new tax year: 1\n",
      "---\n",
      "NO-INCOME 8\n",
      "no work: 3\n",
      "no money: 3\n",
      "no income: 2\n",
      "---\n",
      "SYMPTOMS 6\n",
      "symptoms: 5\n",
      "these symptoms: 1\n",
      "---\n",
      "CARER 5\n",
      "carers: 2\n",
      "no carers: 1\n",
      "a carer: 1\n",
      "a care home: 1\n",
      "---\n",
      "DATA 5\n",
      "the news: 2\n",
      "a difficult situation: 1\n",
      "all my data: 1\n",
      "news: 1\n",
      "---\n",
      "VISA 4\n",
      "6 month visa: 1\n",
      "a residence visa: 1\n",
      "visa: 1\n",
      "visa approval: 1\n",
      "---\n",
      "DEATH 4\n",
      "deaths: 1\n",
      "deadlines: 1\n",
      "these deaths.ĺ: 1\n",
      "death: 1\n",
      "---\n",
      "NO-SYMPTOMS 4\n",
      "no symptoms: 4\n",
      "---\n",
      "SCHOOL 4\n",
      "school refusal: 1\n",
      "those students: 1\n",
      "school each day: 1\n",
      "school: 1\n",
      "---\n",
      "NO-SUPPORT 4\n",
      "no help: 2\n",
      "no access: 1\n",
      "retail there no help: 1\n",
      "---\n",
      "PENSION 4\n",
      "pensioners: 1\n",
      "four pensioners: 1\n",
      "pension credit: 1\n",
      "pension: 1\n",
      "---\n",
      "KEY-WORKER 4\n",
      "keyworkers: 2\n",
      "a key worker: 1\n",
      "nurse: 1\n",
      "---\n",
      "RULES 4\n",
      "rules: 1\n",
      "the rules: 1\n",
      "2 meter rule: 1\n",
      "for restrictions: 1\n",
      "---\n",
      "BENEFIT 4\n",
      "benefits: 1\n",
      "changes pip benefits decbbie: 1\n",
      "allowances: 1\n",
      "on ssp: 1\n",
      "---\n",
      "GIVEN-MONEY 3\n",
      "a refund: 1\n",
      "the grant: 1\n",
      "refund: 1\n",
      "---\n",
      "GET-MED 3\n",
      "medicals: 2\n",
      "prescriptions: 1\n",
      "---\n",
      "LICENSE 3\n",
      "licence: 2\n",
      "a private driving licence plate: 1\n",
      "---\n",
      "DISABLED 2\n",
      "a disability blue badge: 1\n",
      "a disabled son: 1\n",
      "---\n",
      "UNCERTAINTY 2\n",
      "no way: 1\n",
      "no option: 1\n",
      "---\n",
      "LAID-OFF 2\n",
      "80 %: 1\n",
      "furlough payments: 1\n",
      "---\n",
      "SCHEME 2\n",
      "this furlouf scheme: 1\n",
      "schemes: 1\n",
      "---\n",
      "PASSPORT 1\n",
      "no problem scanning passports: 1\n",
      "---\n",
      "NO-CORRESPONDENCE 1\n",
      "no email: 1\n",
      "---\n",
      "\n",
      "6. NEED-SMTHG 917 31 \n",
      "======\n",
      "INFORMATION 166\n",
      "information: 19\n",
      "advice: 17\n",
      "info: 7\n",
      "guidance: 6\n",
      "clarification: 5\n",
      "---\n",
      "SUPPORT 138\n",
      "help: 91\n",
      "some help: 14\n",
      "support: 8\n",
      "access: 5\n",
      "priority: 2\n",
      "---\n",
      "GOODS 53\n",
      "food: 23\n",
      "shopping: 6\n",
      "a food parcel: 4\n",
      "groceries: 4\n",
      "a free food parcel: 3\n",
      "---\n",
      "DELIVERY 31\n",
      "home delivery: 3\n",
      "home deliveries: 2\n",
      "slots: 2\n",
      "a supermarket delivery slot: 2\n",
      "a food delivery: 2\n",
      "---\n",
      "GIVEN-MONEY 25\n",
      "money: 10\n",
      "the money: 4\n",
      "a refund: 3\n",
      "this money: 2\n",
      "that money: 2\n",
      "---\n",
      "CORRESPONDENCE 22\n",
      "a letter: 6\n",
      "the letter: 2\n",
      "the letter files: 1\n",
      "letter employers: 1\n",
      "the text book van: 1\n",
      "---\n",
      "BILLS-TO-PAY 20\n",
      "a tax return: 2\n",
      "a budget loan: 1\n",
      "feed: 1\n",
      "tax tables b: 1\n",
      "insurance: 1\n",
      "---\n",
      "WORK-MENTION 16\n",
      "work: 6\n",
      "employees: 2\n",
      "a shielding note employers: 1\n",
      "new one works dbs check: 1\n",
      "the work: 1\n",
      "---\n",
      "LICENSE 15\n",
      "license: 3\n",
      "licence: 3\n",
      "an import license: 1\n",
      "a uk licence: 1\n",
      "license asap: 1\n",
      "---\n",
      "FAMILY 10\n",
      "2020 partnership tax return: 1\n",
      "partner: 1\n",
      "wife: 1\n",
      "mother: 1\n",
      "the resident parent: 1\n",
      "---\n",
      "COVID-MENTION 8\n",
      "the coronavirus act: 1\n",
      "covid19: 1\n",
      "covid-19 free: 1\n",
      "covid -19: 1\n",
      "covid 19: 1\n",
      "---\n",
      "HOME-MENTION 6\n",
      "home: 4\n",
      "a home shop: 1\n",
      "the house: 1\n",
      "---\n",
      "DATA 4\n",
      "the stats: 1\n",
      "the daily stats: 1\n",
      "the news station: 1\n",
      "this pandemic situation: 1\n",
      "---\n",
      "CHILD 3\n",
      "daughter: 1\n",
      "children: 1\n",
      "child maintenance: 1\n",
      "---\n",
      "SELF-ISOLATION 3\n",
      "an isolation note: 2\n",
      "a self isolation note: 1\n",
      "---\n",
      "BENEFIT 3\n",
      "proof pip: 1\n",
      "the benefit: 1\n",
      "a review pip assessment: 1\n",
      "---\n",
      "PASSPORT 2\n",
      "passport: 1\n",
      "a paper passport renewal application: 1\n",
      "---\n",
      "TRAVEL 2\n",
      "flight: 1\n",
      "travel updates: 1\n",
      "---\n",
      "NO-ONE 2\n",
      "nothing: 1\n",
      "no family: 1\n",
      "---\n",
      "LAID-OFF 2\n",
      "80 %: 1\n",
      "furloughed: 1\n",
      "---\n",
      "VISA 2\n",
      "visa: 1\n",
      "visa application gwf055610021: 1\n",
      "---\n",
      "GET-MED 1\n",
      "prescription collecting: 1\n",
      "---\n",
      "CARER 1\n",
      "a carer: 1\n",
      "---\n",
      "NO-INFORMATION 1\n",
      "a complaint there no email address: 1\n",
      "---\n",
      "AT-RISK 1\n",
      "the risk: 1\n",
      "---\n",
      "PENSION 1\n",
      "a pension: 1\n",
      "---\n",
      "SCHOOL 1\n",
      "student loan: 1\n",
      "---\n",
      "UNCERTAINTY 1\n",
      "a idea: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "a key worker: 1\n",
      "---\n",
      "VULNERABLE 1\n",
      "vulnerable: 1\n",
      "---\n",
      "\n",
      "7. APPLY-SMTHG 732 36 \n",
      "======\n",
      "VULNERABLE 90\n",
      "a vulnerable person: 50\n",
      "extremely vulnerable person: 10\n",
      "a vulnerable elderly person: 2\n",
      "vulnerable: 2\n",
      "the vulnerable list: 2\n",
      "---\n",
      "FAMILY 41\n",
      "husband: 9\n",
      "father: 7\n",
      "mother: 6\n",
      "wife: 6\n",
      "parents: 4\n",
      "---\n",
      "DELIVERY 40\n",
      "home delivery: 10\n",
      "home deliveries: 4\n",
      "a home delivery: 2\n",
      "deliveries least 3: 1\n",
      "deliveries: 1\n",
      "---\n",
      "SUPPORT 30\n",
      "help: 16\n",
      "support: 3\n",
      "assistance: 2\n",
      "this income support scheme: 1\n",
      "priority: 1\n",
      "---\n",
      "INFORMATION 27\n",
      "nhs number: 2\n",
      "the form: 2\n",
      "insurance number: 1\n",
      "self assessment income form: 1\n",
      "updates: 1\n",
      "---\n",
      "WORK-MENTION 25\n",
      "job seekers: 3\n",
      "company: 2\n",
      "jobs: 2\n",
      "employees: 2\n",
      "work: 2\n",
      "---\n",
      "BENEFIT 21\n",
      "universal credit: 7\n",
      "ssp: 3\n",
      "marriage allowance: 2\n",
      "esa: 2\n",
      "benefits: 2\n",
      "---\n",
      "GOODS 17\n",
      "line shopping: 4\n",
      "food: 2\n",
      "food parcel: 2\n",
      "food parcels: 2\n",
      "a food parcel: 1\n",
      "---\n",
      "BILLS-TO-PAY 13\n",
      "a loan: 2\n",
      "20 tax return: 1\n",
      "tax reture: 1\n",
      "the loan: 1\n",
      "budget loan: 1\n",
      "---\n",
      "LICENSE 11\n",
      "licence: 4\n",
      "driving licence: 2\n",
      "driving licence 3 month reduction time: 1\n",
      "a provisional license: 1\n",
      "license: 1\n",
      "---\n",
      "CHILD 10\n",
      "son: 2\n",
      "child benefit: 1\n",
      "sons provisional licence 3 4 weeks: 1\n",
      "daughter: 1\n",
      "daughters: 1\n",
      "---\n",
      "GIVEN-MONEY 10\n",
      "government grant: 2\n",
      "the grant: 2\n",
      "an advanced grant: 1\n",
      "grant: 1\n",
      "some money: 1\n",
      "---\n",
      "ELDERLY 10\n",
      "90 year: 2\n",
      "92 year: 1\n",
      "98 year: 1\n",
      "88 year: 1\n",
      "93 year: 1\n",
      "---\n",
      "LAID-OFF 8\n",
      "80 % wages: 2\n",
      "the furlough scheme: 2\n",
      "80 %: 2\n",
      "80 % grant: 1\n",
      "80 % wages thanks: 1\n",
      "---\n",
      "COVID-MENTION 8\n",
      "coronavirus extremely- vunerable: 1\n",
      "www.gov.uk/corona virus: 1\n",
      "a covid-19 support webinar: 1\n",
      "the covid alerts: 1\n",
      "rotavirus: 1\n",
      "---\n",
      "SCHEME 5\n",
      "the retention scheme: 1\n",
      "the scheme: 1\n",
      "any scheme: 1\n",
      "the new retention scheme: 1\n",
      "eu settlement scheme: 1\n",
      "---\n",
      "HOME-MENTION 5\n",
      "home shopping: 2\n",
      "a light home: 1\n",
      "the warm home grant: 1\n",
      "home grocery benefit: 1\n",
      "---\n",
      "DEATH 4\n",
      "a death: 3\n",
      "sister death: 1\n",
      "---\n",
      "DATA 4\n",
      "status: 3\n",
      "the settled status: 1\n",
      "---\n",
      "HEALTH-PROBLEM 4\n",
      "health issues: 1\n",
      "the allied health professions: 1\n",
      "copd: 1\n",
      "with serious medical conditions: 1\n",
      "---\n",
      "SELF-EMPLOY 4\n",
      "self employment: 2\n",
      "a self employment grant: 1\n",
      "self employment grant: 1\n",
      "---\n",
      "SCHOOL 3\n",
      "freedom school meals: 1\n",
      "school: 1\n",
      "student suport: 1\n",
      "---\n",
      "TRAVEL 3\n",
      "a flight: 1\n",
      "travel updates: 1\n",
      "an emergency travel document 7 years: 1\n",
      "---\n",
      "AT-RISK 3\n",
      "the high risk register: 1\n",
      "a high risk patient: 1\n",
      "at risk: 1\n",
      "---\n",
      "VISA 3\n",
      "visit visa: 1\n",
      "a visa: 1\n",
      "visa: 1\n",
      "---\n",
      "PENSION 3\n",
      "pension credits: 1\n",
      "pensioners free food box: 1\n",
      "state pension: 1\n",
      "---\n",
      "CORRESPONDENCE 2\n",
      "a vunerabje adult the 1on the letter: 1\n",
      "the sms text support service: 1\n",
      "---\n",
      "PASSPORT 2\n",
      "passport: 1\n",
      "a new british passport: 1\n",
      "---\n",
      "KEY-WORKER 2\n",
      "nurse: 2\n",
      "---\n",
      "NO-ONE 2\n",
      "no one: 1\n",
      "a complain nothing: 1\n",
      "---\n",
      "SELF-ISOLATION 1\n",
      "self isolation: 1\n",
      "---\n",
      "DISABLED 1\n",
      "an elderly disabled pensioner: 1\n",
      "---\n",
      "CARER 1\n",
      "carers uk: 1\n",
      "---\n",
      "RULES 1\n",
      "2 meter rule: 1\n",
      "---\n",
      "NO-SUPPORT 1\n",
      "no help: 1\n",
      "---\n",
      "\n",
      "8. ACCESS-SMTHG 614 31 \n",
      "======\n",
      "INFORMATION 84\n",
      "information: 6\n",
      "details: 5\n",
      "the form: 5\n",
      "advice: 4\n",
      "updates: 3\n",
      "---\n",
      "DELIVERY 56\n",
      "a slot: 12\n",
      "a delivery slot: 6\n",
      "home delivery: 4\n",
      "food deliveries: 3\n",
      "delivery: 2\n",
      "---\n",
      "BILLS-TO-PAY 42\n",
      "the tax: 4\n",
      "tax code: 3\n",
      "car insurance: 3\n",
      "tax return: 3\n",
      "car tax: 2\n",
      "---\n",
      "DATA 24\n",
      "progress: 3\n",
      "the situation: 2\n",
      "the progress: 2\n",
      "status: 2\n",
      "cases: 2\n",
      "---\n",
      "COVID-MENTION 22\n",
      "coronavirus: 3\n",
      "the virus: 3\n",
      "coronavirus statistics: 2\n",
      "covid-19: 2\n",
      "the covid: 1\n",
      "---\n",
      "GOODS 17\n",
      "food: 5\n",
      "food parcel: 3\n",
      "any essential groceries: 1\n",
      "the online food services: 1\n",
      "food the stores: 1\n",
      "---\n",
      "WORK-MENTION 14\n",
      "work: 2\n",
      "the job retention: 1\n",
      "the job retention scheme: 1\n",
      "work place: 1\n",
      "the governments job retention scheme: 1\n",
      "---\n",
      "PENSION 14\n",
      "pension status: 3\n",
      "state pension: 3\n",
      "pension: 3\n",
      "state pension date: 1\n",
      "pension benefits: 1\n",
      "---\n",
      "TRAVEL 11\n",
      "travel advice: 4\n",
      "the travel advice pages: 1\n",
      "5 flights: 1\n",
      "flight: 1\n",
      "travel: 1\n",
      "---\n",
      "SUPPORT 9\n",
      "help: 2\n",
      "gov support: 1\n",
      "the support: 1\n",
      "any financial support situation: 1\n",
      "support: 1\n",
      "---\n",
      "RULES 8\n",
      "the rules: 3\n",
      "restrictions: 2\n",
      "the lockdown rules: 1\n",
      "garden fire rules: 1\n",
      "exercise rules: 1\n",
      "---\n",
      "LICENSE 6\n",
      "renew driving license: 1\n",
      "driving licence: 1\n",
      "atv licence: 1\n",
      "licence application progress: 1\n",
      "license renewal: 1\n",
      "---\n",
      "FAMILY 5\n",
      "wife: 2\n",
      "ex partners car rax: 1\n",
      "father career niw: 1\n",
      "mums weekly: 1\n",
      "---\n",
      "CORRESPONDENCE 4\n",
      "the gov.uk messages every day: 1\n",
      "date email subscriptions: 1\n",
      "a message: 1\n",
      "email: 1\n",
      "---\n",
      "SELF-ISOLATION 3\n",
      "the lockdown: 1\n",
      "isolation note: 1\n",
      "5 weeks self isolation: 1\n",
      "---\n",
      "CHILD 3\n",
      "childcare account: 1\n",
      "the paye login sons company: 1\n",
      "daughter application: 1\n",
      "---\n",
      "VULNERABLE 2\n",
      "the vulnerable persons list: 1\n",
      "extremely vulnerable persons: 1\n",
      "---\n",
      "HEALTH-PROBLEM 2\n",
      "the public health england: 1\n",
      "these conditions: 1\n",
      "---\n",
      "HOME-MENTION 2\n",
      "home: 1\n",
      "housemate: 1\n",
      "---\n",
      "BENEFIT 2\n",
      "pip entitlement: 1\n",
      "ssp: 1\n",
      "---\n",
      "DEATH 2\n",
      "deaths: 1\n",
      "death register: 1\n",
      "---\n",
      "LAID-OFF 2\n",
      "the furlough scheme: 1\n",
      "80 % grant: 1\n",
      "---\n",
      "GIVEN-MONEY 2\n",
      "funds: 1\n",
      "grant: 1\n",
      "---\n",
      "SYMPTOMS 1\n",
      "symptoms: 1\n",
      "---\n",
      "SCHEME 1\n",
      "rural payments agency basic payments scheme 2020: 1\n",
      "---\n",
      "UNCERTAINTY 1\n",
      "any way: 1\n",
      "---\n",
      "CARER 1\n",
      "carer: 1\n",
      "---\n",
      "VISA 1\n",
      "the visa: 1\n",
      "---\n",
      "AT-RISK 1\n",
      "at risk: 1\n",
      "---\n",
      "NO-INFORMATION 1\n",
      "own with no family contact: 1\n",
      "---\n",
      "\n",
      "9. DO-SMTHNG 569 32 \n",
      "======\n",
      "INFORMATION 44\n",
      "nhs number: 5\n",
      "contact: 4\n",
      "list: 3\n",
      "form: 2\n",
      "the list: 2\n",
      "---\n",
      "WORK-MENTION 33\n",
      "job: 5\n",
      "work: 4\n",
      "employees: 3\n",
      "a good job: 2\n",
      "business: 2\n",
      "---\n",
      "GOODS 28\n",
      "shopping: 14\n",
      "food: 5\n",
      "food shopping: 2\n",
      "any shopping: 2\n",
      "line shopping: 2\n",
      "---\n",
      "BILLS-TO-PAY 13\n",
      "car tax: 2\n",
      "a personal tax account: 1\n",
      "advances budget loan: 1\n",
      "tax assessment: 1\n",
      "tax returns: 1\n",
      "---\n",
      "HEALTH-PROBLEM 10\n",
      "the specific conditions: 1\n",
      "the health executives: 1\n",
      "this horrible disease: 1\n",
      "the current health emergency: 1\n",
      "health isssues: 1\n",
      "---\n",
      "BENEFIT 8\n",
      "a universal credit application: 2\n",
      "a benefit claim: 2\n",
      "a universal credit claim: 2\n",
      "a new universal credit claim: 1\n",
      "the heating allowance: 1\n",
      "---\n",
      "NO-ONE 8\n",
      "nothing: 6\n",
      "everything online no one: 1\n",
      "no one: 1\n",
      "---\n",
      "COVID-MENTION 8\n",
      "covid 19: 1\n",
      "coronavirus: 1\n",
      "the virus: 1\n",
      "the cornovirus: 1\n",
      "covid-19: 1\n",
      "---\n",
      "CORRESPONDENCE 8\n",
      "letters: 1\n",
      "the letters: 1\n",
      "a letter: 1\n",
      "this automated email: 1\n",
      "the letter gp: 1\n",
      "---\n",
      "CHILD 6\n",
      "daughter: 2\n",
      "children: 1\n",
      "daughters: 1\n",
      "son: 1\n",
      "sons previous emoloyer: 1\n",
      "---\n",
      "FAMILY 5\n",
      "mother ashes: 1\n",
      "parents: 1\n",
      "husband: 1\n",
      "dads house: 1\n",
      "at the moment: 1\n",
      "---\n",
      "DATA 5\n",
      "this situation: 2\n",
      "any progress: 1\n",
      "situation: 1\n",
      "the database: 1\n",
      "---\n",
      "DELIVERY 4\n",
      "deliveries: 2\n",
      "a tesco delivery: 1\n",
      "online shopping: 1\n",
      "---\n",
      "VULNERABLE 4\n",
      "the vulnerable category: 1\n",
      "the vulnerable: 1\n",
      "extremely vulnerable: 1\n",
      "severely vulnerable guideline: 1\n",
      "---\n",
      "SUPPORT 3\n",
      "any help: 1\n",
      "some help: 1\n",
      "help: 1\n",
      "---\n",
      "HOME-MENTION 3\n",
      "home work: 1\n",
      "one household member: 1\n",
      "home: 1\n",
      "---\n",
      "PASSPORT 2\n",
      "photo passport: 1\n",
      "uk passport: 1\n",
      "---\n",
      "GET-MED 2\n",
      "medicals: 2\n",
      "---\n",
      "LICENSE 2\n",
      "licence renewal: 1\n",
      "the license: 1\n",
      "---\n",
      "SELF-ISOLATION 2\n",
      "14 days isolation: 1\n",
      "the lockdown: 1\n",
      "---\n",
      "AT-RISK 2\n",
      "the high risk categories: 1\n",
      "at risk: 1\n",
      "---\n",
      "NO-SUPPORT 1\n",
      "no help: 1\n",
      "---\n",
      "NO-INFORMATION 1\n",
      "no mention: 1\n",
      "---\n",
      "RULES 1\n",
      "the restrictions: 1\n",
      "---\n",
      "UNCERTAINTY 1\n",
      "any ideas: 1\n",
      "---\n",
      "PENSION 1\n",
      "pension: 1\n",
      "---\n",
      "SCHOOL 1\n",
      "school closure: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "a key worker: 1\n",
      "---\n",
      "SYMPTOMS 1\n",
      "any symptoms: 1\n",
      "---\n",
      "LAID-OFF 1\n",
      "the furlough form: 1\n",
      "---\n",
      "GIVEN-MONEY 1\n",
      "any money: 1\n",
      "---\n",
      "\n",
      "10. WORK-SMWHR 407 23 \n",
      "======\n",
      "HOME-MENTION 37\n",
      "home: 29\n",
      "a private nursing home: 1\n",
      "a nursing home: 1\n",
      "a food factory working home: 1\n",
      "a rest home: 1\n",
      "---\n",
      "WORK-MENTION 34\n",
      "a company: 4\n",
      "another employer: 2\n",
      "2 jobs: 2\n",
      "the business: 2\n",
      "a small company: 1\n",
      "---\n",
      "COVID-MENTION 20\n",
      "covid 19: 5\n",
      "the corona virus: 3\n",
      "the coronavirus: 2\n",
      "the virus: 1\n",
      "coronavirus: 1\n",
      "---\n",
      "FAMILY 10\n",
      "the moment: 5\n",
      "the nhs mother: 1\n",
      "mum being: 1\n",
      "wife: 1\n",
      "3 weeks partner dosnt: 1\n",
      "---\n",
      "CARER 9\n",
      "a care home: 6\n",
      "the care home: 1\n",
      "a carer: 1\n",
      "a community carer: 1\n",
      "---\n",
      "BILLS-TO-PAY 8\n",
      "tax: 3\n",
      "tax credits: 2\n",
      "the airport feeling: 1\n",
      "tax credit: 1\n",
      "tax deductions: 1\n",
      "---\n",
      "HEALTH-PROBLEM 7\n",
      "the private healthcare organisations: 1\n",
      "health know: 1\n",
      "healthcare: 1\n",
      "health: 1\n",
      "a health: 1\n",
      "---\n",
      "GOODS 5\n",
      "a food distribution centre: 1\n",
      "food retail: 1\n",
      "24/7 food production site: 1\n",
      "food factory(ready meals: 1\n",
      "food factory: 1\n",
      "---\n",
      "SCHOOL 5\n",
      "school: 2\n",
      "different school 1: 1\n",
      "2 schools: 1\n",
      "the second school: 1\n",
      "---\n",
      "SUPPORT 5\n",
      "choice support: 1\n",
      "a support worker: 1\n",
      "a barmaid: 1\n",
      "supermarket support: 1\n",
      "help: 1\n",
      "---\n",
      "INFORMATION 5\n",
      "number: 1\n",
      "id number: 1\n",
      "details: 1\n",
      "the fco any advice: 1\n",
      "for any advice: 1\n",
      "---\n",
      "SELF-ISOLATION 4\n",
      "lockdown: 1\n",
      "the lockdown: 1\n",
      "this lockdown: 1\n",
      "isolation: 1\n",
      "---\n",
      "CORRESPONDENCE 2\n",
      "notice period: 2\n",
      "---\n",
      "AT-RISK 1\n",
      "a high risk job: 1\n",
      "---\n",
      "RULES 1\n",
      "rules: 1\n",
      "---\n",
      "DATA 1\n",
      "a newspaper: 1\n",
      "---\n",
      "GIVEN-MONEY 1\n",
      "grant scheme: 1\n",
      "---\n",
      "LAID-OFF 1\n",
      "furlough: 1\n",
      "---\n",
      "NO-INFORMATION 1\n",
      "no information: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "a nurse: 1\n",
      "---\n",
      "NO-ONE 1\n",
      "nothing: 1\n",
      "---\n",
      "VULNERABLE 1\n",
      "a vulnerable elderly person: 1\n",
      "---\n",
      "\n",
      "11. CHANGE-SMTHG 396 19 \n",
      "======\n",
      "LICENSE 111\n",
      "licence: 36\n",
      "driving licence: 26\n",
      "license: 11\n",
      "driving license: 8\n",
      "hgv licence: 5\n",
      "---\n",
      "INFORMATION 89\n",
      "address: 37\n",
      "the address: 5\n",
      "bank details: 5\n",
      "email address: 3\n",
      "details: 3\n",
      "---\n",
      "BILLS-TO-PAY 36\n",
      "car tax: 12\n",
      "tax: 6\n",
      "vehicle tax: 4\n",
      "tax code: 3\n",
      "vehicle road tax: 2\n",
      "---\n",
      "WORK-MENTION 12\n",
      "jobs: 7\n",
      "job: 1\n",
      "employer: 1\n",
      "job search: 1\n",
      "employers: 1\n",
      "---\n",
      "PASSPORT 8\n",
      "passport: 4\n",
      "a uk passport: 1\n",
      "a passport: 1\n",
      "brand new passport: 1\n",
      "the passport: 1\n",
      "---\n",
      "FAMILY 4\n",
      "fathers blue badge: 1\n",
      "the way grandmother: 1\n",
      "husbands: 1\n",
      "the name husband: 1\n",
      "---\n",
      "BENEFIT 3\n",
      "marriage allowance: 2\n",
      "tax free allowance: 1\n",
      "---\n",
      "DATA 3\n",
      "status: 2\n",
      "ref the corona situation: 1\n",
      "---\n",
      "CHILD 3\n",
      "son undergraduate student loan: 1\n",
      "child maintenance: 1\n",
      "child services: 1\n",
      "---\n",
      "COVID-MENTION 3\n",
      "covid-19: 2\n",
      "coronavirus: 1\n",
      "---\n",
      "CORRESPONDENCE 2\n",
      "country alert emails: 1\n",
      "e - mail: 1\n",
      "---\n",
      "DELIVERY 1\n",
      "delivery: 1\n",
      "---\n",
      "HEALTH-PROBLEM 1\n",
      "passport that day issues: 1\n",
      "---\n",
      "SUPPORT 1\n",
      "hearing aid batteries: 1\n",
      "---\n",
      "TRAVEL 1\n",
      "travel advice: 1\n",
      "---\n",
      "DEATH 1\n",
      "the death: 1\n",
      "---\n",
      "NO-INFORMATION 1\n",
      "no phone number: 1\n",
      "---\n",
      "SELF-EMPLOY 1\n",
      "self employed: 1\n",
      "---\n",
      "\n",
      "12. PAY-SMTHG 347 21 \n",
      "======\n",
      "BILLS-TO-PAY 157\n",
      "rent: 24\n",
      "tax: 20\n",
      "bills: 17\n",
      "car tax: 10\n",
      "road tax: 9\n",
      "---\n",
      "WORK-MENTION 13\n",
      "business rates: 4\n",
      "employees: 2\n",
      "the rent company: 1\n",
      "agency workers: 1\n",
      "jobworths: 1\n",
      "---\n",
      "CHILD 7\n",
      "child maintenance: 2\n",
      "daughter: 1\n",
      "child minder: 1\n",
      "daughters settlement visa: 1\n",
      "a child: 1\n",
      "---\n",
      "LAID-OFF 5\n",
      "80 %: 2\n",
      "others 80 %: 1\n",
      "80 % salary: 1\n",
      "the furlough: 1\n",
      "---\n",
      "GIVEN-MONEY 5\n",
      "any money: 3\n",
      "money: 1\n",
      "income tax refund: 1\n",
      "---\n",
      "BENEFIT 5\n",
      "ssp: 4\n",
      "the benefit: 1\n",
      "---\n",
      "SUPPORT 3\n",
      "child support agency: 1\n",
      "the state aid support package: 1\n",
      "help: 1\n",
      "---\n",
      "PENSION 3\n",
      "people pensions: 1\n",
      "pensions: 1\n",
      "tax nhs pension: 1\n",
      "---\n",
      "COVID-MENTION 3\n",
      "corona virus: 1\n",
      "covid19 problem: 1\n",
      "80 % covid19 retention scheme: 1\n",
      "---\n",
      "PASSPORT 2\n",
      "the new passport: 1\n",
      "for passport: 1\n",
      "---\n",
      "SCHOOL 2\n",
      "student loan: 2\n",
      "---\n",
      "HOME-MENTION 1\n",
      "household bills: 1\n",
      "---\n",
      "LICENSE 1\n",
      "road fund licence: 1\n",
      "---\n",
      "INFORMATION 1\n",
      "e - mail contact: 1\n",
      "---\n",
      "FAMILY 1\n",
      "mothers pension: 1\n",
      "---\n",
      "VISA 1\n",
      "the visa: 1\n",
      "---\n",
      "NO-INCOME 1\n",
      "no income.also food: 1\n",
      "---\n",
      "SCHEME 1\n",
      "the paye scheme: 1\n",
      "---\n",
      "TRAVEL 1\n",
      "flights: 1\n",
      "---\n",
      "GOODS 1\n",
      "food utility bills: 1\n",
      "---\n",
      "\n",
      "13. LIVING 331 23 \n",
      "======\n",
      "HOME-MENTION 78\n",
      "home: 61\n",
      "house: 2\n",
      "the same home: 1\n",
      "the same house: 1\n",
      "a different house: 1\n",
      "---\n",
      "FAMILY 11\n",
      "a mother: 1\n",
      "parents: 1\n",
      "husband: 1\n",
      "mum: 1\n",
      "parent: 1\n",
      "---\n",
      "INFORMATION 10\n",
      "contact: 2\n",
      "home advice: 1\n",
      "spain list: 1\n",
      "address: 1\n",
      "the wrong address: 1\n",
      "---\n",
      "WORK-MENTION 10\n",
      "work: 10\n",
      "---\n",
      "GOODS 6\n",
      "food: 2\n",
      "any shopping 🛒: 1\n",
      "any shopping: 1\n",
      "any food: 1\n",
      "emergency food package: 1\n",
      "---\n",
      "NO-ONE 4\n",
      "no family: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing: 1\n",
      "alone with no one: 1\n",
      "---\n",
      "VULNERABLE 3\n",
      "a vulnerable person: 3\n",
      "---\n",
      "ELDERLY 3\n",
      "85 year: 1\n",
      "78 year: 1\n",
      "93 year: 1\n",
      "---\n",
      "HEALTH-PROBLEM 3\n",
      "asthma: 1\n",
      "no underlying health problems: 1\n",
      "health reasons: 1\n",
      "---\n",
      "GET-MED 3\n",
      "medication: 1\n",
      "meds: 1\n",
      "husbands prescription: 1\n",
      "---\n",
      "DELIVERY 2\n",
      "slot: 1\n",
      "slots: 1\n",
      "---\n",
      "SUPPORT 2\n",
      "some support thk: 1\n",
      "any support: 1\n",
      "---\n",
      "BENEFIT 2\n",
      "ssp: 2\n",
      "---\n",
      "UNCERTAINTY 1\n",
      "a way: 1\n",
      "---\n",
      "AT-RISK 1\n",
      "a high risk person: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "dad not a key worker: 1\n",
      "---\n",
      "CHILD 1\n",
      "daughter: 1\n",
      "---\n",
      "BILLS-TO-PAY 1\n",
      "feet: 1\n",
      "---\n",
      "GIVEN-MONEY 1\n",
      "no funds: 1\n",
      "---\n",
      "CORRESPONDENCE 1\n",
      "letter: 1\n",
      "---\n",
      "SELF-ISOLATION 1\n",
      "isolation: 1\n",
      "---\n",
      "SCHOOL 1\n",
      "all students: 1\n",
      "---\n",
      "\n",
      "14. CONTACT-SMTHG 237 18 \n",
      "======\n",
      "WORK-MENTION 9\n",
      "employer: 3\n",
      "work: 2\n",
      "a company: 1\n",
      "business open: 1\n",
      "the jobcentre: 1\n",
      "---\n",
      "DEATH 9\n",
      "a death: 5\n",
      "the death: 2\n",
      "a death bereavement: 1\n",
      "death: 1\n",
      "---\n",
      "CHILD 6\n",
      "son: 2\n",
      "child maintenance: 2\n",
      "the child maintenance service: 1\n",
      "child benefit department: 1\n",
      "---\n",
      "FAMILY 5\n",
      "fathers deah: 1\n",
      "mum death: 1\n",
      "the other parent: 1\n",
      "a parent: 1\n",
      "a change mothers circumstances: 1\n",
      "---\n",
      "INFORMATION 5\n",
      "the telephone number: 1\n",
      "the contact centres: 1\n",
      "a change details: 1\n",
      "new e - mail address:-: 1\n",
      "details: 1\n",
      "---\n",
      "BENEFIT 5\n",
      "maternity allowance: 1\n",
      "the esa team: 1\n",
      "esa a few weeks: 1\n",
      "universal credit: 1\n",
      "the pip service: 1\n",
      "---\n",
      "DATA 3\n",
      "mse news department: 1\n",
      "the situation: 1\n",
      "cases: 1\n",
      "---\n",
      "CORRESPONDENCE 3\n",
      "hmrc email scam: 1\n",
      "a tv scam email: 1\n",
      "email: 1\n",
      "---\n",
      "COVID-MENTION 2\n",
      "covid19 lockdown breach: 1\n",
      "covid 19: 1\n",
      "---\n",
      "HEALTH-PROBLEM 2\n",
      "a medical condition: 1\n",
      "an issue: 1\n",
      "---\n",
      "BILLS-TO-PAY 2\n",
      "the tax office: 1\n",
      "the tax: 1\n",
      "---\n",
      "SCHOOL 2\n",
      "student finance wales: 1\n",
      "school 4 times: 1\n",
      "---\n",
      "HOME-MENTION 2\n",
      "home office: 1\n",
      "the home office: 1\n",
      "---\n",
      "SYMPTOMS 1\n",
      "symptoms: 1\n",
      "---\n",
      "LICENSE 1\n",
      "driving licence: 1\n",
      "---\n",
      "GET-MED 1\n",
      "medical practice: 1\n",
      "---\n",
      "PASSPORT 1\n",
      "passport: 1\n",
      "---\n",
      "\n",
      "15. GO-SMWHR 223 21 \n",
      "======\n",
      "WORK-MENTION 45\n",
      "work: 41\n",
      "job centre: 1\n",
      "another employer: 1\n",
      "any officine job center: 1\n",
      "work place: 1\n",
      "---\n",
      "GOODS 15\n",
      "shopping: 7\n",
      "food: 5\n",
      "food shopping: 2\n",
      "foodstuffs: 1\n",
      "---\n",
      "FAMILY 7\n",
      "dads: 2\n",
      "girlfriends family house: 1\n",
      "family members: 1\n",
      "shopping husband: 1\n",
      "girlfriends dads house: 1\n",
      "---\n",
      "INFORMATION 5\n",
      "the link: 3\n",
      "a secure link: 1\n",
      "number: 1\n",
      "---\n",
      "COVID-MENTION 5\n",
      "covid 19: 2\n",
      "the corona virus restrictions: 1\n",
      "the corona virus: 1\n",
      "work covid 19: 1\n",
      "---\n",
      "HOME-MENTION 3\n",
      "clients house: 1\n",
      "house: 1\n",
      "of your house: 1\n",
      "---\n",
      "SUPPORT 3\n",
      "the accessibility: 1\n",
      "help: 1\n",
      "some help: 1\n",
      "---\n",
      "VULNERABLE 3\n",
      "a vulnerable list: 1\n",
      "a vulnerable person: 1\n",
      "extremely vulnerable list: 1\n",
      "---\n",
      "CORRESPONDENCE 3\n",
      "text: 1\n",
      "a letter: 1\n",
      "the letter: 1\n",
      "---\n",
      "SCHOOL 2\n",
      "school: 2\n",
      "---\n",
      "BILLS-TO-PAY 2\n",
      "insurance incase: 1\n",
      "debt: 1\n",
      "---\n",
      "SELF-ISOLATION 2\n",
      "lockdown: 1\n",
      "isolation: 1\n",
      "---\n",
      "WORK 1\n",
      "work invade: 1\n",
      "---\n",
      "LAID-OFF 1\n",
      "the furlough job retention scheme: 1\n",
      "---\n",
      "DATA 1\n",
      "this situation: 1\n",
      "---\n",
      "HEALTH-PROBLEM 1\n",
      "the asthma page: 1\n",
      "---\n",
      "CHILD 1\n",
      "daughter: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "the contribution key workers: 1\n",
      "---\n",
      "CARER 1\n",
      "a care home: 1\n",
      "---\n",
      "AT-RISK 1\n",
      "at risk: 1\n",
      "---\n",
      "\n",
      "16. HELP 155 26 \n",
      "======\n",
      "CHILD 12\n",
      "daughter: 1\n",
      "children free school: 1\n",
      "sons application: 1\n",
      "daughter application: 1\n",
      "daughter student loan application: 1\n",
      "---\n",
      "FAMILY 10\n",
      "husband: 3\n",
      "family: 3\n",
      "mother: 1\n",
      "dad: 1\n",
      "wife: 1\n",
      "---\n",
      "GOODS 8\n",
      "shopping: 6\n",
      "food shoppin: 1\n",
      "a food parcel: 1\n",
      "---\n",
      "WORK-MENTION 7\n",
      "employees: 2\n",
      "company owners: 1\n",
      "business: 1\n",
      "the brunei workforce: 1\n",
      "company car allowance: 1\n",
      "---\n",
      "BILLS-TO-PAY 6\n",
      "bills: 2\n",
      "rent: 1\n",
      "tax services: 1\n",
      "the current status: 1\n",
      "the annual tax return line two years: 1\n",
      "---\n",
      "VULNERABLE 5\n",
      "a vulnerable person: 1\n",
      "the vulnerable: 1\n",
      "the vulnerable communities: 1\n",
      "the vulnerable people letter: 1\n",
      "the vulnerable people: 1\n",
      "---\n",
      "INFORMATION 4\n",
      "advice: 1\n",
      "the form: 1\n",
      "the government information: 1\n",
      "number: 1\n",
      "---\n",
      "SCHOOL 3\n",
      "students: 2\n",
      "a student finance application: 1\n",
      "---\n",
      "HOME-MENTION 3\n",
      "home: 2\n",
      "the house: 1\n",
      "---\n",
      "COVID-MENTION 3\n",
      "covid: 1\n",
      "the coronavirus: 1\n",
      "the corona virus: 1\n",
      "---\n",
      "ELDERLY 2\n",
      "89 year: 1\n",
      "86 year: 1\n",
      "---\n",
      "BENEFIT 2\n",
      "esa: 1\n",
      "benefit: 1\n",
      "---\n",
      "SCHEME 2\n",
      "scheme: 1\n",
      "this scheme: 1\n",
      "---\n",
      "HEALTH-PROBLEM 2\n",
      "illnesses: 1\n",
      "illness manageable: 1\n",
      "---\n",
      "NO-SUPPORT 1\n",
      "no web site no help: 1\n",
      "---\n",
      "DISABLED 1\n",
      "a disabled friend: 1\n",
      "---\n",
      "GIVEN-MONEY 1\n",
      "money: 1\n",
      "---\n",
      "NO-ONE 1\n",
      "money nothing: 1\n",
      "---\n",
      "DELIVERY 1\n",
      "food deliveries: 1\n",
      "---\n",
      "DATA 1\n",
      "statistics: 1\n",
      "---\n",
      "PENSION 1\n",
      "pension: 1\n",
      "---\n",
      "SELF-EMPLOY 1\n",
      "self employment payments: 1\n",
      "---\n",
      "SELF-ISOLATION 1\n",
      "self isolated problems: 1\n",
      "---\n",
      "TRAVEL 1\n",
      "travel: 1\n",
      "---\n",
      "KEY-WORKER 1\n",
      "keyworkers: 1\n",
      "---\n",
      "\n",
      "17. GIVE-SMTHNG 95 12 \n",
      "======\n",
      "INFORMATION 27\n",
      "details: 6\n",
      "information: 4\n",
      "a link: 2\n",
      "any relevant information: 1\n",
      "shielding advice: 1\n",
      "---\n",
      "SUPPORT 4\n",
      "support: 2\n",
      "priority: 1\n",
      "access: 1\n",
      "---\n",
      "WORK-MENTION 3\n",
      "the job: 1\n",
      "employer: 1\n",
      "work: 1\n",
      "---\n",
      "CORRESPONDENCE 2\n",
      "notice: 2\n",
      "---\n",
      "GOODS 2\n",
      "the public food service: 1\n",
      "shopping: 1\n",
      "---\n",
      "NO-INFORMATION 2\n",
      "no information: 1\n",
      "no guidance: 1\n",
      "---\n",
      "BILLS-TO-PAY 2\n",
      "the current crisis: 1\n",
      "feedback: 1\n",
      "---\n",
      "FAMILY 2\n",
      "husband: 1\n",
      "the moment: 1\n",
      "---\n",
      "CHILD 1\n",
      "hours childcare: 1\n",
      "---\n",
      "DELIVERY 1\n",
      "delivery slots: 1\n",
      "---\n",
      "PASSPORT 1\n",
      "the passport office reference: 1\n",
      "---\n",
      "\n",
      "18. TRAVEL 54 12 \n",
      "======\n",
      "INFORMATION 3\n",
      "update: 2\n",
      "info: 1\n",
      "---\n",
      "SUPPORT 2\n",
      "assistance: 1\n",
      "maidstone: 1\n",
      "---\n",
      "HOME-MENTION 2\n",
      "house: 1\n",
      "a homes: 1\n",
      "---\n",
      "FAMILY 1\n",
      "documents mothers funeral: 1\n",
      "---\n",
      "WORK-MENTION 1\n",
      "company: 1\n",
      "---\n",
      "COVID-MENTION 1\n",
      "the coronavirus pandemic: 1\n",
      "---\n",
      "RULES 1\n",
      "the cv19 restrictions: 1\n",
      "---\n",
      "PENSION 1\n",
      "pension: 1\n",
      "---\n",
      "PASSPORT 1\n",
      "nz passport: 1\n",
      "---\n",
      "CHILD 1\n",
      "daughter: 1\n",
      "---\n",
      "SCHOOL 1\n",
      "school holiday period: 1\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (key,value) in enumerate(sorted([(k,v) for k,v in verb_argument_themes.items() if k != \"UNKNOWN\"],\n",
    "                                       key = lambda x: sum([sum(counter.values()) for counter in x[1].values()]),\n",
    "                                      reverse=True),1):\n",
    "\n",
    "    print(f\"{i}. {key} {sum([sum(counter.values()) for counter in value.values()])} {len(value)} \\n======\")\n",
    "    for j, (argument, counter) in enumerate(sorted([(k,v) for k,v in value.items() if k != \"UNKNOWN\"],\n",
    "                                                   key = lambda x: sum(x[1].values()),\n",
    "                                                   reverse=True\n",
    "                                                  )\n",
    "                                            , 1):\n",
    "\n",
    "        print(f\"{argument} {sum(counter.values())}\")\n",
    "        for l, (arg_theme, vals) in enumerate(counter.most_common(5)):\n",
    "            print(f\"{arg_theme}: {vals}\")\n",
    "        print(\"---\")\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign themes to actions and things people are talking about \n",
    "### Tag response comments (Q3) with appropriate themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felisialoukou/.virtualenvs/corona/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320f51d93e7c4bd1893c9133b2f6cb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-193b37f868ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphrase_mentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mphrase_mentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcombo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompute_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-aeeb53118efb>\u001b[0m in \u001b[0;36mextract_phrase\u001b[0;34m(sentences, merge_inplace)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmerge_inplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmerge_adjacent_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-aeeb53118efb>\u001b[0m in \u001b[0;36mchunk_text\u001b[0;34m(tagged)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchunk_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/site-packages/nltk/chunk/regexp.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m                 \u001b[0mchunk_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/site-packages/nltk/chunk/regexp.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunkstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notrace_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunkstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Use the chunkstring to create a chunk structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/site-packages/nltk/chunk/regexp.py\u001b[0m in \u001b[0;36m_notrace_apply\u001b[0;34m(self, chunkstr)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunkstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/site-packages/nltk/chunk/regexp.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, chunkstr)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0minvalid\u001b[0m \u001b[0mchunkstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mchunkstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/site-packages/nltk/chunk/regexp.py\u001b[0m in \u001b[0;36mxform\u001b[0;34m(self, regexp, repl)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \"\"\"\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Do the actual substitution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# The substitution might have generated \"empty chunks\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/corona/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "phrase_mentions = []\n",
    "for vals in tqdm_notebook(df.pos_tag.values):\n",
    "    sents = extract_phrase(vals, True)\n",
    "    phrase_mentions.append([])\n",
    "    for combo in compute_combinations(sents, 2):\n",
    "        key = (combo[0].label, combo[1].label)\n",
    "        arg1 = combo[0].text.lower()\n",
    "        arg2 = combo[1].text.lower()\n",
    "        \n",
    "        if key in [('verb', 'noun'), ('verb', 'prep_noun'), \n",
    "                   ('verb', 'noun_verb'), ('noun','prep_noun'),\n",
    "                  ('prep_noun','noun'), ('prep_noun','prep_noun')]:\n",
    "            mention_theme = f\"{regex_group_verbs(arg1)} - {regex_for_theme(arg2)}\"\n",
    "            \n",
    "            arg1 = re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", arg1)\n",
    "            arg2 = re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", arg2)\n",
    "            phrase = f\"{arg1} {arg2}\"\n",
    "            phrase_mentions[-1].append((key, phrase, mention_theme, (arg1,arg2)))\n",
    "            \n",
    "df['theme_mentions'] = phrase_mentions       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['theme_mentions'].str.len()>0].iloc[100].theme_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['theme_mentions_list'] = df['theme_mentions'].map(lambda x: [mention for key,_,mention,_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_group(arg1, arg2):\n",
    "    if re.search(r\"((('|’|^(a)?)m)|(have been)|(feel))$\", arg1):\n",
    "        return re.sub(r\"^((the)|a)\\s\",\"\", arg2)\n",
    "    return \"\"\n",
    "\n",
    "def resolve_function(x):\n",
    "    res = [get_user_group(*args) for theme,_,_,args in x if \"verb\" in theme[0]]\n",
    "    return [r for r in res if r != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [[('verb', 'noun'),None,None,('feel', 'the key-worker')]]\n",
    "resolve_function(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['theme_mentions_user'] = df['theme_mentions'].map(resolve_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = Counter()\n",
    "for vals in df[df['theme_mentions_user'].str.len()>0].theme_mentions_user.values:\n",
    "    for val in vals:\n",
    "        user_groups[val] +=1\n",
    "user_groups.most_common(10), \"housebound\" in user_groups, len(user_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "from difflib import SequenceMatcher as SM\n",
    "from nltk.util import ngrams\n",
    "import codecs\n",
    "\n",
    "needle = \"told register as a vulnerable person\"\n",
    "hay    = \"told to register as a vulnerable person for delivery service for on line shopping\"\n",
    "\n",
    "def find_needle(needle, hay):\n",
    "    needle_length  = len(needle.split())\n",
    "    max_sim_val    = 0\n",
    "    max_sim_string = u\"\"\n",
    "#     print(needle)\n",
    "    for ngram in ngrams(hay.split(), needle_length + int(.65*needle_length)):\n",
    "        hay_ngram = u\" \".join(ngram)\n",
    "        similarity = SM(None, hay_ngram, needle).ratio() \n",
    "        if similarity > max_sim_val:\n",
    "            max_sim_val = similarity\n",
    "            max_sim_string = hay_ngram\n",
    "    \n",
    "    if max_sim_string == \"\":\n",
    "        max_sim_string = hay\n",
    "\n",
    "    tokens = needle.split(\" \")\n",
    "    if len(tokens) == 1:\n",
    "        expression = tokens[0]\n",
    "    else:\n",
    "        expression = f\"({tokens[0]}).*({tokens[-1]})\"\n",
    "    result = regex.search(expression, max_sim_string)\n",
    "    \n",
    "    if result is not None:\n",
    "        pattern = result.group()\n",
    "        \n",
    "        return {needle: pattern}\n",
    "    return {needle:None}\n",
    "\n",
    "print(find_needle(needle, hay))\n",
    "print(find_needle(\"housebound\", \"i am housebound\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['theme_mentions', \"Q3_pii_removed\"]].iloc[142].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove special characters\n",
    "df[\"Q3_pii_removed\"] = df[\"Q3_pii_removed\"].replace(np.nan, '', regex=True)\n",
    "df[\"Q3_pii_removed\"] = df[\"Q3_pii_removed\"].progress_map(lambda x: ' '.join(\n",
    "                                    re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", x).split()))\n",
    "\n",
    "df[\"Q3_x_edit\"] = df[\"Q3_x\"].replace(np.nan, '', regex=True)\n",
    "df[\"Q3_x_edit\"] = df[\"Q3_x_edit\"].progress_map(lambda x: ' '.join(re.sub(r\"\\(|\\)|\\[|\\]|\\+\", \"\", x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns for `phrases` and `user_groups`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['theme_mentions', \"Q3_x_edit\"]].iloc[6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phrases_dict'] = df[['theme_mentions', \"Q3_x_edit\"]][:].\\\n",
    "            progress_apply(lambda x: [find_needle(phrase, x[1].lower()) for _,phrase,_,_  in x[0]], axis=1)\n",
    "df['phrases_list'] = df['phrases_dict'].progress_map(lambda x: [value for phrase_dict in x \n",
    "                                                                 for value in phrase_dict.values() \n",
    "                                                                 if value is not None]\n",
    "                                                if not isinstance(x, float) else [])\n",
    "df['phrases'] = df['phrases_list'].progress_map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_counts = Counter()\n",
    "for phrase_list in df.phrases_list.values:\n",
    "    for phrase in phrase_list:\n",
    "        phrase_counts[phrase]+=1\n",
    "phrase_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['phrases']!=''][['phrases', 'Q3_x_edit']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_phrases_dict'] = df[['theme_mentions_user', \"Q3_x_edit\"]][:].\\\n",
    "            progress_apply(lambda x: [find_needle(phrase, x[1].lower()) for phrase  in x[0]], axis=1)\n",
    "df['user_phrases_list'] = df['user_phrases_dict'].progress_map(lambda x: [value for phrase_dict in x \n",
    "                                                                 for value in phrase_dict.values() \n",
    "                                                                 if value is not None]\n",
    "                                                if not isinstance(x, float) else [])\n",
    "\n",
    "df['user_phrases'] = df['user_phrases_list'].progress_map(lambda x: \", \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_groups = Counter()\n",
    "for vals in df[df['user_phrases_list'].str.len()>0].user_phrases_list.values:\n",
    "    for val in vals:\n",
    "        user_groups[val] +=1\n",
    "user_groups.most_common(10), \"housebound\" in user_groups, len(user_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = 0\n",
    "for phrase_list, comment in df[~df['phrases_dict'].isna()][['phrases_dict', 'Q3_x_edit']].values:\n",
    "    for phrase_dict in phrase_list:\n",
    "        for key,value in phrase_dict.items():\n",
    "            if str(value) not in comment.lower():\n",
    "                missing+=1\n",
    "missing       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results for tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[['primary_key', 'intents_clientID', 'visitId', 'fullVisitorId',\n",
    "       'hits_pagePath', 'Started', 'Ended', 'Q1_x', 'Q2_x', 'Q3_x_edit', 'Q4_x',\n",
    "       'Q5_x', 'Q6_x', 'Q7_x', 'Q8_x', 'session_id', 'dayofweek', 'isWeekend',\n",
    "       'hour', 'country', 'country_grouping', 'UK_region', 'UK_metro_area',\n",
    "       'channelGrouping', 'deviceCategory',\n",
    "       'total_seconds_in_session_across_days',\n",
    "       'total_pageviews_in_session_across_days', 'finding_count',\n",
    "       'updates_and_alerts_count', 'news_count', 'decisions_count',\n",
    "       'speeches_and_statements_count', 'transactions_count',\n",
    "       'regulation_count', 'guidance_count', 'business_support_count',\n",
    "       'policy_count', 'consultations_count', 'research_count',\n",
    "       'statistics_count', 'transparency_data_count',\n",
    "       'freedom_of_information_releases_count', 'incidents_count',\n",
    "       'done_page_flag', 'count_client_error', 'count_server_error',\n",
    "       'ga_visit_start_timestamp', 'ga_visit_end_timestamp',\n",
    "       'intents_started_date', 'events_sequence', 'search_terms_sequence',\n",
    "       'cleaned_search_terms_sequence', 'top_level_taxons_sequence',\n",
    "       'page_format_sequence', 'Sequence', 'PageSequence', 'flag_for_criteria',\n",
    "       'full_url_in_session_flag', 'UserID', 'UserNo', 'Name', 'Email',\n",
    "       'IP Address', 'Unique ID', 'Tracking Link', 'clientID', 'Page Path',\n",
    "       'Q1_y', 'Q2_y', 'Q3_y', 'Q4_y', 'Q5_y', 'Q6_y', 'Q7_y', 'Q8_y',\n",
    "       'Started_Date', 'Ended_Date', 'Started_Date_sub_12h', 'phrases', 'user_phrases']]\n",
    "\n",
    "df_sub.rename(columns={'Q3_x_edit':'Q3_x'}, inplace=True)\n",
    "df_sub.to_csv(os.path.join(DATA_DIR, 'uis_20200401_20200409_phrases_user_groups.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
